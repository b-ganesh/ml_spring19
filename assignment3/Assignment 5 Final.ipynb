{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import assignment3_functions as library\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import (svm, ensemble, tree,\n",
    "                     linear_model, neighbors, naive_bayes, dummy)\n",
    "pd.options.display.max_columns = 999\n",
    "import warnings \n",
    "warnings.simplefilter('ignore')\n",
    "from datetime import date, datetime, timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First, I load the data from Donors Choose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "donors_df = library.file_to_dataframe(\"projects_2012_2013.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next, I create the target variable. I previously had done it backwards (labeling projects that did get funded within 60 days 1, and those that did not get funded 0, so here I have fixed that, because the prediction task is to determine the likelihood that a project will not be funded within 60 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>projectid</th>\n",
       "      <th>teacher_acctid</th>\n",
       "      <th>schoolid</th>\n",
       "      <th>school_ncesid</th>\n",
       "      <th>school_latitude</th>\n",
       "      <th>school_longitude</th>\n",
       "      <th>school_city</th>\n",
       "      <th>school_state</th>\n",
       "      <th>school_metro</th>\n",
       "      <th>school_district</th>\n",
       "      <th>school_county</th>\n",
       "      <th>school_charter</th>\n",
       "      <th>school_magnet</th>\n",
       "      <th>teacher_prefix</th>\n",
       "      <th>primary_focus_subject</th>\n",
       "      <th>primary_focus_area</th>\n",
       "      <th>secondary_focus_subject</th>\n",
       "      <th>secondary_focus_area</th>\n",
       "      <th>resource_type</th>\n",
       "      <th>poverty_level</th>\n",
       "      <th>grade_level</th>\n",
       "      <th>total_price_including_optional_support</th>\n",
       "      <th>students_reached</th>\n",
       "      <th>eligible_double_your_impact_match</th>\n",
       "      <th>date_posted</th>\n",
       "      <th>datefullyfunded</th>\n",
       "      <th>60_days_fullyfunded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001ccc0e81598c4bd86bacb94d7acb</td>\n",
       "      <td>96963218e74e10c3764a5cfb153e6fea</td>\n",
       "      <td>9f3f9f2c2da7edda5648ccd10554ed8c</td>\n",
       "      <td>1.709930e+11</td>\n",
       "      <td>41.807654</td>\n",
       "      <td>-87.673257</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>IL</td>\n",
       "      <td>urban</td>\n",
       "      <td>Pershing Elem Network</td>\n",
       "      <td>Cook</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>Mrs.</td>\n",
       "      <td>Mathematics</td>\n",
       "      <td>Math &amp; Science</td>\n",
       "      <td>Visual Arts</td>\n",
       "      <td>Music &amp; The Arts</td>\n",
       "      <td>Supplies</td>\n",
       "      <td>highest poverty</td>\n",
       "      <td>Grades PreK-2</td>\n",
       "      <td>1498.61</td>\n",
       "      <td>31.0</td>\n",
       "      <td>f</td>\n",
       "      <td>2013-04-14</td>\n",
       "      <td>2013-05-02</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000fa3aa8f6649abab23615b546016d</td>\n",
       "      <td>2a578595fe351e7fce057e048c409b18</td>\n",
       "      <td>3432ed3d4466fac2f2ead83ab354e333</td>\n",
       "      <td>6.409801e+10</td>\n",
       "      <td>34.296596</td>\n",
       "      <td>-119.296596</td>\n",
       "      <td>Ventura</td>\n",
       "      <td>CA</td>\n",
       "      <td>urban</td>\n",
       "      <td>Ventura Unif School District</td>\n",
       "      <td>Ventura</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>Mrs.</td>\n",
       "      <td>Civics &amp; Government</td>\n",
       "      <td>History &amp; Civics</td>\n",
       "      <td>Literature &amp; Writing</td>\n",
       "      <td>Literacy &amp; Language</td>\n",
       "      <td>Books</td>\n",
       "      <td>highest poverty</td>\n",
       "      <td>Grades 3-5</td>\n",
       "      <td>282.47</td>\n",
       "      <td>28.0</td>\n",
       "      <td>t</td>\n",
       "      <td>2012-04-07</td>\n",
       "      <td>2012-04-18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000134f07d4b30140d63262c871748ff</td>\n",
       "      <td>26bd60377bdbffb53a644a16c5308e82</td>\n",
       "      <td>dc8dcb501c3b2bb0b10e9c6ee2cd8afd</td>\n",
       "      <td>6.227100e+10</td>\n",
       "      <td>34.078625</td>\n",
       "      <td>-118.257834</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>CA</td>\n",
       "      <td>urban</td>\n",
       "      <td>Los Angeles Unif Sch Dist</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>Ms.</td>\n",
       "      <td>Literacy</td>\n",
       "      <td>Literacy &amp; Language</td>\n",
       "      <td>Social Sciences</td>\n",
       "      <td>History &amp; Civics</td>\n",
       "      <td>Technology</td>\n",
       "      <td>high poverty</td>\n",
       "      <td>Grades 3-5</td>\n",
       "      <td>1012.38</td>\n",
       "      <td>56.0</td>\n",
       "      <td>f</td>\n",
       "      <td>2012-01-30</td>\n",
       "      <td>2012-04-15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001f2d0b3827bba67cdbeaa248b832d</td>\n",
       "      <td>15d900805d9d716c051c671827109f45</td>\n",
       "      <td>8bea7e8c6e4279fca6276128db89292e</td>\n",
       "      <td>3.600090e+11</td>\n",
       "      <td>40.687286</td>\n",
       "      <td>-73.988217</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>NY</td>\n",
       "      <td>urban</td>\n",
       "      <td>New York City Dept Of Ed</td>\n",
       "      <td>Kings (Brooklyn)</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>Ms.</td>\n",
       "      <td>Literacy</td>\n",
       "      <td>Literacy &amp; Language</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Books</td>\n",
       "      <td>high poverty</td>\n",
       "      <td>Grades PreK-2</td>\n",
       "      <td>175.33</td>\n",
       "      <td>23.0</td>\n",
       "      <td>f</td>\n",
       "      <td>2012-10-11</td>\n",
       "      <td>2012-12-05</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0004536db996ba697ca72c9e058bfe69</td>\n",
       "      <td>400f8b82bb0143f6a40b217a517fe311</td>\n",
       "      <td>fbdefab6fe41e12c55886c610c110753</td>\n",
       "      <td>3.606870e+11</td>\n",
       "      <td>40.793018</td>\n",
       "      <td>-73.205635</td>\n",
       "      <td>Central Islip</td>\n",
       "      <td>NY</td>\n",
       "      <td>suburban</td>\n",
       "      <td>Central Islip Union Free SD</td>\n",
       "      <td>Suffolk</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>Mrs.</td>\n",
       "      <td>Literacy</td>\n",
       "      <td>Literacy &amp; Language</td>\n",
       "      <td>Literature &amp; Writing</td>\n",
       "      <td>Literacy &amp; Language</td>\n",
       "      <td>Technology</td>\n",
       "      <td>high poverty</td>\n",
       "      <td>Grades PreK-2</td>\n",
       "      <td>3591.11</td>\n",
       "      <td>150.0</td>\n",
       "      <td>f</td>\n",
       "      <td>2013-01-08</td>\n",
       "      <td>2013-03-25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          projectid                    teacher_acctid  \\\n",
       "0  00001ccc0e81598c4bd86bacb94d7acb  96963218e74e10c3764a5cfb153e6fea   \n",
       "1  0000fa3aa8f6649abab23615b546016d  2a578595fe351e7fce057e048c409b18   \n",
       "2  000134f07d4b30140d63262c871748ff  26bd60377bdbffb53a644a16c5308e82   \n",
       "3  0001f2d0b3827bba67cdbeaa248b832d  15d900805d9d716c051c671827109f45   \n",
       "4  0004536db996ba697ca72c9e058bfe69  400f8b82bb0143f6a40b217a517fe311   \n",
       "\n",
       "                           schoolid  school_ncesid  school_latitude  \\\n",
       "0  9f3f9f2c2da7edda5648ccd10554ed8c   1.709930e+11        41.807654   \n",
       "1  3432ed3d4466fac2f2ead83ab354e333   6.409801e+10        34.296596   \n",
       "2  dc8dcb501c3b2bb0b10e9c6ee2cd8afd   6.227100e+10        34.078625   \n",
       "3  8bea7e8c6e4279fca6276128db89292e   3.600090e+11        40.687286   \n",
       "4  fbdefab6fe41e12c55886c610c110753   3.606870e+11        40.793018   \n",
       "\n",
       "   school_longitude    school_city school_state school_metro  \\\n",
       "0        -87.673257        Chicago           IL        urban   \n",
       "1       -119.296596        Ventura           CA        urban   \n",
       "2       -118.257834    Los Angeles           CA        urban   \n",
       "3        -73.988217       Brooklyn           NY        urban   \n",
       "4        -73.205635  Central Islip           NY     suburban   \n",
       "\n",
       "                school_district     school_county school_charter  \\\n",
       "0         Pershing Elem Network              Cook              f   \n",
       "1  Ventura Unif School District           Ventura              f   \n",
       "2     Los Angeles Unif Sch Dist       Los Angeles              f   \n",
       "3      New York City Dept Of Ed  Kings (Brooklyn)              f   \n",
       "4   Central Islip Union Free SD           Suffolk              f   \n",
       "\n",
       "  school_magnet teacher_prefix primary_focus_subject   primary_focus_area  \\\n",
       "0             f           Mrs.           Mathematics       Math & Science   \n",
       "1             f           Mrs.   Civics & Government     History & Civics   \n",
       "2             f            Ms.              Literacy  Literacy & Language   \n",
       "3             t            Ms.              Literacy  Literacy & Language   \n",
       "4             f           Mrs.              Literacy  Literacy & Language   \n",
       "\n",
       "  secondary_focus_subject secondary_focus_area resource_type    poverty_level  \\\n",
       "0             Visual Arts     Music & The Arts      Supplies  highest poverty   \n",
       "1    Literature & Writing  Literacy & Language         Books  highest poverty   \n",
       "2         Social Sciences     History & Civics    Technology     high poverty   \n",
       "3                     NaN                  NaN         Books     high poverty   \n",
       "4    Literature & Writing  Literacy & Language    Technology     high poverty   \n",
       "\n",
       "     grade_level  total_price_including_optional_support  students_reached  \\\n",
       "0  Grades PreK-2                                 1498.61              31.0   \n",
       "1     Grades 3-5                                  282.47              28.0   \n",
       "2     Grades 3-5                                 1012.38              56.0   \n",
       "3  Grades PreK-2                                  175.33              23.0   \n",
       "4  Grades PreK-2                                 3591.11             150.0   \n",
       "\n",
       "  eligible_double_your_impact_match date_posted datefullyfunded  \\\n",
       "0                                 f  2013-04-14      2013-05-02   \n",
       "1                                 t  2012-04-07      2012-04-18   \n",
       "2                                 f  2012-01-30      2012-04-15   \n",
       "3                                 f  2012-10-11      2012-12-05   \n",
       "4                                 f  2013-01-08      2013-03-25   \n",
       "\n",
       "   60_days_fullyfunded  \n",
       "0                    0  \n",
       "1                    0  \n",
       "2                    1  \n",
       "3                    0  \n",
       "4                    1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "donors_df['date_posted'] = pd.to_datetime(donors_df['date_posted'], format='%m/%d/%y')\n",
    "donors_df['datefullyfunded'] = pd.to_datetime(donors_df['datefullyfunded'], format='%m/%d/%y')\n",
    "donors_df['60_days_fullyfunded'] = np.where(donors_df['datefullyfunded'] - donors_df['date_posted'] <= pd.to_timedelta(60, unit='days'), 0, 1)\n",
    "donors_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next, I look at my data to see which columns have NAs, and decide how to impute these values. In this case, I choose to just impute the continuous variable of students reached, during the pre-processing step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "projectid                                     0\n",
       "teacher_acctid                                0\n",
       "schoolid                                      0\n",
       "school_ncesid                              9233\n",
       "school_latitude                               0\n",
       "school_longitude                              0\n",
       "school_city                                   0\n",
       "school_state                                  0\n",
       "school_metro                              15224\n",
       "school_district                             172\n",
       "school_county                                 0\n",
       "school_charter                                0\n",
       "school_magnet                                 0\n",
       "teacher_prefix                                0\n",
       "primary_focus_subject                        15\n",
       "primary_focus_area                           15\n",
       "secondary_focus_subject                   40556\n",
       "secondary_focus_area                      40556\n",
       "resource_type                                17\n",
       "poverty_level                                 0\n",
       "grade_level                                   3\n",
       "total_price_including_optional_support        0\n",
       "students_reached                             59\n",
       "eligible_double_your_impact_match             0\n",
       "date_posted                                   0\n",
       "datefullyfunded                               0\n",
       "60_days_fullyfunded                           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "library.na_summary(donors_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instead of hardcoding/dropping variables in place, I created a pre_processing function that takes lists of columns as its input, and then performs the necessary operations (imputing, dropping, etc). The parameters for that function are listed below. In constrast to my previous pipeline, the pre-processing step now occurs after the train, test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_dummy_list = ['school_magnet', 'school_charter', 'eligible_double_your_impact_match']\n",
    "categorical_list = ['teacher_prefix', 'primary_focus_subject', 'primary_focus_area', 'resource_type', 'poverty_level', 'grade_level', 'school_district', 'secondary_focus_subject', 'secondary_focus_area', 'school_state', 'school_city', 'school_metro', 'school_county']\n",
    "continuous_impute_list = ['students_reached']\n",
    "vars_to_drop_all = ['projectid', 'teacher_acctid', 'schoolid', 'school_ncesid', 'school_longitude', 'school_latitude']\n",
    "vars_to_drop_dates = ['date_posted', 'datefullyfunded', '60_days_fullyfunded']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temporal Validation Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Below, I fixed the function that determines the dates for the 3 train, test sets. I introduced a grace period that can be specified (60 days in this case), so that 60 days can be used to evaluate the impact of the intervention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[datetime.datetime(2012, 1, 1, 0, 0),\n",
       "  datetime.datetime(2012, 4, 30, 0, 0),\n",
       "  datetime.datetime(2012, 7, 1, 0, 0),\n",
       "  datetime.datetime(2012, 10, 31, 0, 0),\n",
       "  6],\n",
       " [datetime.datetime(2012, 1, 1, 0, 0),\n",
       "  datetime.datetime(2012, 10, 31, 0, 0),\n",
       "  datetime.datetime(2013, 1, 1, 0, 0),\n",
       "  datetime.datetime(2013, 4, 30, 0, 0),\n",
       "  6],\n",
       " [datetime.datetime(2012, 1, 1, 0, 0),\n",
       "  datetime.datetime(2013, 4, 30, 0, 0),\n",
       "  datetime.datetime(2013, 7, 1, 0, 0),\n",
       "  datetime.datetime(2013, 10, 31, 0, 0),\n",
       "  6]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_time_6mo = '2012-01-01'\n",
    "end_time_6mo = '2013-12-31'\n",
    "prediction_windows = [6]\n",
    "temp_split_6mo = library.temporal_dates(start_time_6mo, end_time_6mo, prediction_windows, 60)\n",
    "temp_split_6mo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Below, I use the same parameter grid as before. I added in the Gradient Boost and Bagging Models, based on comments on my previous pipeline. I also found a way to make the training process go faster (introducing the n_jobs parameter), so I was able to run the analysis on the entire span of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_to_run = ['RF', 'AB', 'LR', 'KNN', 'SVM', 'DT', 'GB', 'BG']\n",
    " \n",
    "classifiers = {'RF': ensemble.RandomForestClassifier(n_estimators=50, n_jobs=-1),\n",
    "    'LR': linear_model.LogisticRegression(penalty='l1', C=1e5, n_jobs=-1),\n",
    "    'SVM': svm.LinearSVC(tol= 1e-5, random_state=0),\n",
    "    'AB': ensemble.AdaBoostClassifier(tree.DecisionTreeClassifier(max_depth=1), algorithm=\"SAMME\", n_estimators=200),\n",
    "    'DT': tree.DecisionTreeClassifier(),\n",
    "    'KNN': neighbors.KNeighborsClassifier(n_neighbors=10, n_jobs=-1),\n",
    "    'GB': ensemble.GradientBoostingClassifier(learning_rate=0.05, subsample=0.5, max_depth=6, n_estimators=10),\n",
    "    'BG': ensemble.BaggingClassifier(linear_model.LogisticRegression(penalty='l1', C=1e5, n_jobs=-1))\n",
    "        }\n",
    "\n",
    "parameters = { \n",
    "    'RF':{'n_estimators': [10,100], 'max_depth': [5, 20, 100], 'max_features': ['sqrt','log2'],'min_samples_split': [2,10], 'n_jobs': [-1]},\n",
    "    'LR': { 'penalty': ['l1','l2'], 'C': [0.001,0.1,1,10]},\n",
    "    'AB': { 'algorithm': ['SAMME'], 'n_estimators': [1]},\n",
    "    'DT': {'criterion': ['gini', 'entropy'], 'max_depth': [1,10,20,100],'min_samples_split': [2,5,10]},\n",
    "    'SVM': {'C': [0.01]},\n",
    "    'KNN': {'n_neighbors': [25],'weights': ['uniform','distance'],'algorithm': ['ball_tree']},\n",
    "    'GB': {'n_estimators': [10], 'learning_rate': [0.1,0.5], 'subsample': [0.1,0.5], 'max_depth': [5]},\n",
    "    'BG': {'n_estimators': [10], 'max_samples': [.5]}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I create a list of thresholds to loop over instead of hardcoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_list = [1.0, 2.0, 5.0, 10.0, 20.0, 30.0, 50.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running through model RF...\n",
      "Running through model AB...\n",
      "Running through model LR...\n",
      "Running through model KNN...\n",
      "Running through model SVM...\n",
      "Running through model DT...\n",
      "Running through model GB...\n",
      "Running through model BG...\n",
      "Running through model RF...\n",
      "Running through model AB...\n",
      "Running through model LR...\n",
      "Running through model KNN...\n",
      "Running through model SVM...\n",
      "Running through model DT...\n",
      "Running through model GB...\n",
      "Running through model BG...\n",
      "Running through model RF...\n",
      "Running through model AB...\n",
      "Running through model LR...\n",
      "Running through model KNN...\n",
      "Running through model SVM...\n",
      "Running through model DT...\n",
      "Running through model GB...\n",
      "Running through model BG...\n"
     ]
    }
   ],
   "source": [
    "results_df, params = library.run_models(models_to_run, classifiers, parameters, donors_df, '60_days_fullyfunded', temp_split_6mo, 'date_posted', categorical_list, to_dummy_list, continuous_impute_list, vars_to_drop_all, vars_to_drop_dates, k_list, 'table_test_30.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### After running through all the models, I produce a grid below that compares each model across various evaluation metrics (auc-roc, precision, recall, etc.) I added in f1 score, because it had been pointed out that I was missing that in my previous pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_start</th>\n",
       "      <th>train_end</th>\n",
       "      <th>test_start</th>\n",
       "      <th>test_end</th>\n",
       "      <th>model_type</th>\n",
       "      <th>classifier</th>\n",
       "      <th>train_size</th>\n",
       "      <th>test_size</th>\n",
       "      <th>auc-roc</th>\n",
       "      <th>p_at_1</th>\n",
       "      <th>a_at_1</th>\n",
       "      <th>r_at_1</th>\n",
       "      <th>f1_at_1</th>\n",
       "      <th>p_at_2</th>\n",
       "      <th>a_at_2</th>\n",
       "      <th>r_at_2</th>\n",
       "      <th>f1_at_2</th>\n",
       "      <th>p_at_5</th>\n",
       "      <th>a_at_5</th>\n",
       "      <th>r_at_5</th>\n",
       "      <th>f1_at_5</th>\n",
       "      <th>p_at_10</th>\n",
       "      <th>a_at_10</th>\n",
       "      <th>r_at_10</th>\n",
       "      <th>f1_at_10</th>\n",
       "      <th>p_at_20</th>\n",
       "      <th>a_at_20</th>\n",
       "      <th>r_at_20</th>\n",
       "      <th>f1_at_20</th>\n",
       "      <th>p_at_30</th>\n",
       "      <th>a_at_30</th>\n",
       "      <th>r_at_30</th>\n",
       "      <th>f1_at_30</th>\n",
       "      <th>p_at_50</th>\n",
       "      <th>a_at_50</th>\n",
       "      <th>r_at_50</th>\n",
       "      <th>f1_at_50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2012-04-30</td>\n",
       "      <td>2012-07-01</td>\n",
       "      <td>2012-10-31</td>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>21180</td>\n",
       "      <td>23294</td>\n",
       "      <td>0.497928</td>\n",
       "      <td>0.387931</td>\n",
       "      <td>0.748862</td>\n",
       "      <td>0.0155226</td>\n",
       "      <td>0.0298507</td>\n",
       "      <td>0.339785</td>\n",
       "      <td>0.744698</td>\n",
       "      <td>0.0272508</td>\n",
       "      <td>0.0504551</td>\n",
       "      <td>0.402921</td>\n",
       "      <td>0.741393</td>\n",
       "      <td>0.08089</td>\n",
       "      <td>0.134731</td>\n",
       "      <td>0.354229</td>\n",
       "      <td>0.721946</td>\n",
       "      <td>0.14229</td>\n",
       "      <td>0.203027</td>\n",
       "      <td>0.331473</td>\n",
       "      <td>0.683695</td>\n",
       "      <td>0.266299</td>\n",
       "      <td>0.295333</td>\n",
       "      <td>0.361906</td>\n",
       "      <td>0.668241</td>\n",
       "      <td>0.436185</td>\n",
       "      <td>0.395589</td>\n",
       "      <td>0.339572</td>\n",
       "      <td>0.590667</td>\n",
       "      <td>0.682132</td>\n",
       "      <td>0.453425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2012-04-30</td>\n",
       "      <td>2012-07-01</td>\n",
       "      <td>2012-10-31</td>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>21180</td>\n",
       "      <td>23294</td>\n",
       "      <td>0.499727</td>\n",
       "      <td>0.392241</td>\n",
       "      <td>0.748948</td>\n",
       "      <td>0.0156951</td>\n",
       "      <td>0.0301824</td>\n",
       "      <td>0.380645</td>\n",
       "      <td>0.74633</td>\n",
       "      <td>0.0305278</td>\n",
       "      <td>0.0565224</td>\n",
       "      <td>0.364261</td>\n",
       "      <td>0.737529</td>\n",
       "      <td>0.0731287</td>\n",
       "      <td>0.121804</td>\n",
       "      <td>0.373551</td>\n",
       "      <td>0.725809</td>\n",
       "      <td>0.150052</td>\n",
       "      <td>0.214101</td>\n",
       "      <td>0.364534</td>\n",
       "      <td>0.696918</td>\n",
       "      <td>0.29286</td>\n",
       "      <td>0.32479</td>\n",
       "      <td>0.349027</td>\n",
       "      <td>0.660513</td>\n",
       "      <td>0.420662</td>\n",
       "      <td>0.381511</td>\n",
       "      <td>0.325234</td>\n",
       "      <td>0.576329</td>\n",
       "      <td>0.653329</td>\n",
       "      <td>0.434279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2012-04-30</td>\n",
       "      <td>2012-07-01</td>\n",
       "      <td>2012-10-31</td>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>21180</td>\n",
       "      <td>23294</td>\n",
       "      <td>0.495292</td>\n",
       "      <td>0.344828</td>\n",
       "      <td>0.748004</td>\n",
       "      <td>0.0137979</td>\n",
       "      <td>0.026534</td>\n",
       "      <td>0.348387</td>\n",
       "      <td>0.745042</td>\n",
       "      <td>0.0279407</td>\n",
       "      <td>0.0517324</td>\n",
       "      <td>0.398625</td>\n",
       "      <td>0.740963</td>\n",
       "      <td>0.0800276</td>\n",
       "      <td>0.133295</td>\n",
       "      <td>0.372692</td>\n",
       "      <td>0.725638</td>\n",
       "      <td>0.149707</td>\n",
       "      <td>0.213609</td>\n",
       "      <td>0.395019</td>\n",
       "      <td>0.70911</td>\n",
       "      <td>0.317351</td>\n",
       "      <td>0.351951</td>\n",
       "      <td>0.379365</td>\n",
       "      <td>0.678716</td>\n",
       "      <td>0.457227</td>\n",
       "      <td>0.414672</td>\n",
       "      <td>0.326093</td>\n",
       "      <td>0.577187</td>\n",
       "      <td>0.655053</td>\n",
       "      <td>0.435426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2012-04-30</td>\n",
       "      <td>2012-07-01</td>\n",
       "      <td>2012-10-31</td>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>21180</td>\n",
       "      <td>23294</td>\n",
       "      <td>0.509430</td>\n",
       "      <td>0.465517</td>\n",
       "      <td>0.750408</td>\n",
       "      <td>0.0186271</td>\n",
       "      <td>0.0358209</td>\n",
       "      <td>0.421505</td>\n",
       "      <td>0.747961</td>\n",
       "      <td>0.0338048</td>\n",
       "      <td>0.0625898</td>\n",
       "      <td>0.411512</td>\n",
       "      <td>0.742251</td>\n",
       "      <td>0.0826147</td>\n",
       "      <td>0.137604</td>\n",
       "      <td>0.383856</td>\n",
       "      <td>0.72787</td>\n",
       "      <td>0.154191</td>\n",
       "      <td>0.220007</td>\n",
       "      <td>0.36754</td>\n",
       "      <td>0.69812</td>\n",
       "      <td>0.295274</td>\n",
       "      <td>0.327467</td>\n",
       "      <td>0.346737</td>\n",
       "      <td>0.65914</td>\n",
       "      <td>0.417903</td>\n",
       "      <td>0.379008</td>\n",
       "      <td>0.319567</td>\n",
       "      <td>0.570662</td>\n",
       "      <td>0.641945</td>\n",
       "      <td>0.426713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2012-04-30</td>\n",
       "      <td>2012-07-01</td>\n",
       "      <td>2012-10-31</td>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>21180</td>\n",
       "      <td>23294</td>\n",
       "      <td>0.508002</td>\n",
       "      <td>0.25431</td>\n",
       "      <td>0.746201</td>\n",
       "      <td>0.0101759</td>\n",
       "      <td>0.0195688</td>\n",
       "      <td>0.337634</td>\n",
       "      <td>0.744612</td>\n",
       "      <td>0.0270783</td>\n",
       "      <td>0.0501357</td>\n",
       "      <td>0.341924</td>\n",
       "      <td>0.735297</td>\n",
       "      <td>0.0686444</td>\n",
       "      <td>0.114335</td>\n",
       "      <td>0.349077</td>\n",
       "      <td>0.720915</td>\n",
       "      <td>0.140221</td>\n",
       "      <td>0.200074</td>\n",
       "      <td>0.336625</td>\n",
       "      <td>0.685756</td>\n",
       "      <td>0.270438</td>\n",
       "      <td>0.299923</td>\n",
       "      <td>0.439325</td>\n",
       "      <td>0.71469</td>\n",
       "      <td>0.529493</td>\n",
       "      <td>0.480213</td>\n",
       "      <td>0.288315</td>\n",
       "      <td>0.539409</td>\n",
       "      <td>0.579165</td>\n",
       "      <td>0.384981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2012-04-30</td>\n",
       "      <td>2012-07-01</td>\n",
       "      <td>2012-10-31</td>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>21180</td>\n",
       "      <td>23294</td>\n",
       "      <td>0.499413</td>\n",
       "      <td>0.349138</td>\n",
       "      <td>0.74809</td>\n",
       "      <td>0.0139703</td>\n",
       "      <td>0.0268657</td>\n",
       "      <td>0.365591</td>\n",
       "      <td>0.745729</td>\n",
       "      <td>0.0293205</td>\n",
       "      <td>0.0542871</td>\n",
       "      <td>0.347938</td>\n",
       "      <td>0.735898</td>\n",
       "      <td>0.0698517</td>\n",
       "      <td>0.116346</td>\n",
       "      <td>0.343924</td>\n",
       "      <td>0.719885</td>\n",
       "      <td>0.138151</td>\n",
       "      <td>0.197121</td>\n",
       "      <td>0.337913</td>\n",
       "      <td>0.686271</td>\n",
       "      <td>0.271473</td>\n",
       "      <td>0.301071</td>\n",
       "      <td>0.331139</td>\n",
       "      <td>0.649781</td>\n",
       "      <td>0.399103</td>\n",
       "      <td>0.361958</td>\n",
       "      <td>0.309865</td>\n",
       "      <td>0.56096</td>\n",
       "      <td>0.622456</td>\n",
       "      <td>0.413758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2012-04-30</td>\n",
       "      <td>2012-07-01</td>\n",
       "      <td>2012-10-31</td>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>21180</td>\n",
       "      <td>23294</td>\n",
       "      <td>0.495908</td>\n",
       "      <td>0.262931</td>\n",
       "      <td>0.746372</td>\n",
       "      <td>0.0105209</td>\n",
       "      <td>0.0202322</td>\n",
       "      <td>0.277419</td>\n",
       "      <td>0.742208</td>\n",
       "      <td>0.0222491</td>\n",
       "      <td>0.0411943</td>\n",
       "      <td>0.380584</td>\n",
       "      <td>0.73916</td>\n",
       "      <td>0.0764057</td>\n",
       "      <td>0.127262</td>\n",
       "      <td>0.298411</td>\n",
       "      <td>0.710784</td>\n",
       "      <td>0.119869</td>\n",
       "      <td>0.171035</td>\n",
       "      <td>0.361314</td>\n",
       "      <td>0.69563</td>\n",
       "      <td>0.290273</td>\n",
       "      <td>0.32192</td>\n",
       "      <td>0.324699</td>\n",
       "      <td>0.645917</td>\n",
       "      <td>0.391342</td>\n",
       "      <td>0.354919</td>\n",
       "      <td>0.364214</td>\n",
       "      <td>0.615309</td>\n",
       "      <td>0.731632</td>\n",
       "      <td>0.486328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2012-04-30</td>\n",
       "      <td>2012-07-01</td>\n",
       "      <td>2012-10-31</td>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>21180</td>\n",
       "      <td>23294</td>\n",
       "      <td>0.500862</td>\n",
       "      <td>0.318966</td>\n",
       "      <td>0.747489</td>\n",
       "      <td>0.012763</td>\n",
       "      <td>0.0245439</td>\n",
       "      <td>0.309677</td>\n",
       "      <td>0.743496</td>\n",
       "      <td>0.0248362</td>\n",
       "      <td>0.0459844</td>\n",
       "      <td>0.300687</td>\n",
       "      <td>0.731175</td>\n",
       "      <td>0.0603656</td>\n",
       "      <td>0.100546</td>\n",
       "      <td>0.300129</td>\n",
       "      <td>0.711127</td>\n",
       "      <td>0.120559</td>\n",
       "      <td>0.172019</td>\n",
       "      <td>0.314513</td>\n",
       "      <td>0.676913</td>\n",
       "      <td>0.252673</td>\n",
       "      <td>0.280222</td>\n",
       "      <td>0.315684</td>\n",
       "      <td>0.640508</td>\n",
       "      <td>0.380476</td>\n",
       "      <td>0.345065</td>\n",
       "      <td>0.294582</td>\n",
       "      <td>0.545677</td>\n",
       "      <td>0.591756</td>\n",
       "      <td>0.393351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2012-04-30</td>\n",
       "      <td>2012-07-01</td>\n",
       "      <td>2012-10-31</td>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>21180</td>\n",
       "      <td>23294</td>\n",
       "      <td>0.503076</td>\n",
       "      <td>0.37069</td>\n",
       "      <td>0.748519</td>\n",
       "      <td>0.0148327</td>\n",
       "      <td>0.028524</td>\n",
       "      <td>0.397849</td>\n",
       "      <td>0.747016</td>\n",
       "      <td>0.0319076</td>\n",
       "      <td>0.0590771</td>\n",
       "      <td>0.387457</td>\n",
       "      <td>0.739847</td>\n",
       "      <td>0.0777854</td>\n",
       "      <td>0.12956</td>\n",
       "      <td>0.36067</td>\n",
       "      <td>0.723233</td>\n",
       "      <td>0.144878</td>\n",
       "      <td>0.206718</td>\n",
       "      <td>0.339201</td>\n",
       "      <td>0.686786</td>\n",
       "      <td>0.272508</td>\n",
       "      <td>0.302219</td>\n",
       "      <td>0.326703</td>\n",
       "      <td>0.647119</td>\n",
       "      <td>0.393756</td>\n",
       "      <td>0.357109</td>\n",
       "      <td>0.310981</td>\n",
       "      <td>0.562076</td>\n",
       "      <td>0.624698</td>\n",
       "      <td>0.415248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2012-04-30</td>\n",
       "      <td>2012-07-01</td>\n",
       "      <td>2012-10-31</td>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>21180</td>\n",
       "      <td>23294</td>\n",
       "      <td>0.502870</td>\n",
       "      <td>0.340517</td>\n",
       "      <td>0.747918</td>\n",
       "      <td>0.0136254</td>\n",
       "      <td>0.0262023</td>\n",
       "      <td>0.372043</td>\n",
       "      <td>0.745986</td>\n",
       "      <td>0.0298379</td>\n",
       "      <td>0.0552451</td>\n",
       "      <td>0.385739</td>\n",
       "      <td>0.739675</td>\n",
       "      <td>0.0774405</td>\n",
       "      <td>0.128986</td>\n",
       "      <td>0.392872</td>\n",
       "      <td>0.729673</td>\n",
       "      <td>0.157813</td>\n",
       "      <td>0.225175</td>\n",
       "      <td>0.366681</td>\n",
       "      <td>0.697776</td>\n",
       "      <td>0.294584</td>\n",
       "      <td>0.326702</td>\n",
       "      <td>0.350458</td>\n",
       "      <td>0.661372</td>\n",
       "      <td>0.422387</td>\n",
       "      <td>0.383075</td>\n",
       "      <td>0.329441</td>\n",
       "      <td>0.580536</td>\n",
       "      <td>0.66178</td>\n",
       "      <td>0.439897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2012-04-30</td>\n",
       "      <td>2012-07-01</td>\n",
       "      <td>2012-10-31</td>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>21180</td>\n",
       "      <td>23294</td>\n",
       "      <td>0.492633</td>\n",
       "      <td>0.37069</td>\n",
       "      <td>0.748519</td>\n",
       "      <td>0.0148327</td>\n",
       "      <td>0.028524</td>\n",
       "      <td>0.35914</td>\n",
       "      <td>0.745471</td>\n",
       "      <td>0.028803</td>\n",
       "      <td>0.0533291</td>\n",
       "      <td>0.359107</td>\n",
       "      <td>0.737014</td>\n",
       "      <td>0.0720938</td>\n",
       "      <td>0.12008</td>\n",
       "      <td>0.359382</td>\n",
       "      <td>0.722976</td>\n",
       "      <td>0.14436</td>\n",
       "      <td>0.20598</td>\n",
       "      <td>0.352512</td>\n",
       "      <td>0.69211</td>\n",
       "      <td>0.283201</td>\n",
       "      <td>0.314078</td>\n",
       "      <td>0.340298</td>\n",
       "      <td>0.655276</td>\n",
       "      <td>0.410141</td>\n",
       "      <td>0.371969</td>\n",
       "      <td>0.314502</td>\n",
       "      <td>0.565596</td>\n",
       "      <td>0.63177</td>\n",
       "      <td>0.419948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2012-04-30</td>\n",
       "      <td>2012-07-01</td>\n",
       "      <td>2012-10-31</td>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>21180</td>\n",
       "      <td>23294</td>\n",
       "      <td>0.502461</td>\n",
       "      <td>0.327586</td>\n",
       "      <td>0.74766</td>\n",
       "      <td>0.013108</td>\n",
       "      <td>0.0252073</td>\n",
       "      <td>0.36129</td>\n",
       "      <td>0.745557</td>\n",
       "      <td>0.0289755</td>\n",
       "      <td>0.0536484</td>\n",
       "      <td>0.384021</td>\n",
       "      <td>0.739504</td>\n",
       "      <td>0.0770956</td>\n",
       "      <td>0.128411</td>\n",
       "      <td>0.383426</td>\n",
       "      <td>0.727784</td>\n",
       "      <td>0.154019</td>\n",
       "      <td>0.219761</td>\n",
       "      <td>0.368184</td>\n",
       "      <td>0.698377</td>\n",
       "      <td>0.295792</td>\n",
       "      <td>0.328041</td>\n",
       "      <td>0.353034</td>\n",
       "      <td>0.662917</td>\n",
       "      <td>0.425492</td>\n",
       "      <td>0.385891</td>\n",
       "      <td>0.324805</td>\n",
       "      <td>0.575899</td>\n",
       "      <td>0.652466</td>\n",
       "      <td>0.433706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2012-04-30</td>\n",
       "      <td>2012-07-01</td>\n",
       "      <td>2012-10-31</td>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>21180</td>\n",
       "      <td>23294</td>\n",
       "      <td>0.497806</td>\n",
       "      <td>0.366379</td>\n",
       "      <td>0.748433</td>\n",
       "      <td>0.0146602</td>\n",
       "      <td>0.0281924</td>\n",
       "      <td>0.369892</td>\n",
       "      <td>0.7459</td>\n",
       "      <td>0.0296654</td>\n",
       "      <td>0.0549258</td>\n",
       "      <td>0.292955</td>\n",
       "      <td>0.730403</td>\n",
       "      <td>0.0588134</td>\n",
       "      <td>0.0979604</td>\n",
       "      <td>0.32632</td>\n",
       "      <td>0.716365</td>\n",
       "      <td>0.13108</td>\n",
       "      <td>0.187031</td>\n",
       "      <td>0.347359</td>\n",
       "      <td>0.690049</td>\n",
       "      <td>0.279062</td>\n",
       "      <td>0.309487</td>\n",
       "      <td>0.34273</td>\n",
       "      <td>0.656736</td>\n",
       "      <td>0.413073</td>\n",
       "      <td>0.374628</td>\n",
       "      <td>0.316219</td>\n",
       "      <td>0.567313</td>\n",
       "      <td>0.635219</td>\n",
       "      <td>0.422241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2012-04-30</td>\n",
       "      <td>2012-07-01</td>\n",
       "      <td>2012-10-31</td>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>21180</td>\n",
       "      <td>23294</td>\n",
       "      <td>0.500940</td>\n",
       "      <td>0.422414</td>\n",
       "      <td>0.749549</td>\n",
       "      <td>0.0169024</td>\n",
       "      <td>0.0325041</td>\n",
       "      <td>0.382796</td>\n",
       "      <td>0.746415</td>\n",
       "      <td>0.0307002</td>\n",
       "      <td>0.0568418</td>\n",
       "      <td>0.344502</td>\n",
       "      <td>0.735554</td>\n",
       "      <td>0.0691618</td>\n",
       "      <td>0.115197</td>\n",
       "      <td>0.335337</td>\n",
       "      <td>0.718168</td>\n",
       "      <td>0.134702</td>\n",
       "      <td>0.192199</td>\n",
       "      <td>0.335337</td>\n",
       "      <td>0.685241</td>\n",
       "      <td>0.269403</td>\n",
       "      <td>0.298776</td>\n",
       "      <td>0.327275</td>\n",
       "      <td>0.647463</td>\n",
       "      <td>0.394446</td>\n",
       "      <td>0.357735</td>\n",
       "      <td>0.31433</td>\n",
       "      <td>0.565425</td>\n",
       "      <td>0.631425</td>\n",
       "      <td>0.419719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2012-04-30</td>\n",
       "      <td>2012-07-01</td>\n",
       "      <td>2012-10-31</td>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>21180</td>\n",
       "      <td>23294</td>\n",
       "      <td>0.501001</td>\n",
       "      <td>0.306034</td>\n",
       "      <td>0.747231</td>\n",
       "      <td>0.0122456</td>\n",
       "      <td>0.0235489</td>\n",
       "      <td>0.352688</td>\n",
       "      <td>0.745213</td>\n",
       "      <td>0.0282856</td>\n",
       "      <td>0.0523711</td>\n",
       "      <td>0.294674</td>\n",
       "      <td>0.730574</td>\n",
       "      <td>0.0591583</td>\n",
       "      <td>0.0985349</td>\n",
       "      <td>0.288536</td>\n",
       "      <td>0.708809</td>\n",
       "      <td>0.115902</td>\n",
       "      <td>0.165375</td>\n",
       "      <td>0.290468</td>\n",
       "      <td>0.667296</td>\n",
       "      <td>0.233356</td>\n",
       "      <td>0.258799</td>\n",
       "      <td>0.294934</td>\n",
       "      <td>0.628059</td>\n",
       "      <td>0.355467</td>\n",
       "      <td>0.322384</td>\n",
       "      <td>0.287198</td>\n",
       "      <td>0.538293</td>\n",
       "      <td>0.576923</td>\n",
       "      <td>0.383491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2012-04-30</td>\n",
       "      <td>2012-07-01</td>\n",
       "      <td>2012-10-31</td>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>21180</td>\n",
       "      <td>23294</td>\n",
       "      <td>0.497550</td>\n",
       "      <td>0.344828</td>\n",
       "      <td>0.748004</td>\n",
       "      <td>0.0137979</td>\n",
       "      <td>0.026534</td>\n",
       "      <td>0.331183</td>\n",
       "      <td>0.744355</td>\n",
       "      <td>0.0265609</td>\n",
       "      <td>0.0491777</td>\n",
       "      <td>0.340206</td>\n",
       "      <td>0.735125</td>\n",
       "      <td>0.0682994</td>\n",
       "      <td>0.11376</td>\n",
       "      <td>0.344783</td>\n",
       "      <td>0.720057</td>\n",
       "      <td>0.138496</td>\n",
       "      <td>0.197613</td>\n",
       "      <td>0.341348</td>\n",
       "      <td>0.687645</td>\n",
       "      <td>0.274232</td>\n",
       "      <td>0.304132</td>\n",
       "      <td>0.329565</td>\n",
       "      <td>0.648837</td>\n",
       "      <td>0.397206</td>\n",
       "      <td>0.360238</td>\n",
       "      <td>0.306173</td>\n",
       "      <td>0.557268</td>\n",
       "      <td>0.61504</td>\n",
       "      <td>0.408828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2012-04-30</td>\n",
       "      <td>2012-07-01</td>\n",
       "      <td>2012-10-31</td>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>21180</td>\n",
       "      <td>23294</td>\n",
       "      <td>0.505538</td>\n",
       "      <td>0.383621</td>\n",
       "      <td>0.748777</td>\n",
       "      <td>0.0153501</td>\n",
       "      <td>0.0295191</td>\n",
       "      <td>0.356989</td>\n",
       "      <td>0.745385</td>\n",
       "      <td>0.0286306</td>\n",
       "      <td>0.0530097</td>\n",
       "      <td>0.380584</td>\n",
       "      <td>0.73916</td>\n",
       "      <td>0.0764057</td>\n",
       "      <td>0.127262</td>\n",
       "      <td>0.351653</td>\n",
       "      <td>0.72143</td>\n",
       "      <td>0.141256</td>\n",
       "      <td>0.20155</td>\n",
       "      <td>0.342207</td>\n",
       "      <td>0.687988</td>\n",
       "      <td>0.274922</td>\n",
       "      <td>0.304897</td>\n",
       "      <td>0.327991</td>\n",
       "      <td>0.647892</td>\n",
       "      <td>0.395309</td>\n",
       "      <td>0.358517</td>\n",
       "      <td>0.309779</td>\n",
       "      <td>0.560874</td>\n",
       "      <td>0.622284</td>\n",
       "      <td>0.413643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2012-04-30</td>\n",
       "      <td>2012-07-01</td>\n",
       "      <td>2012-10-31</td>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>21180</td>\n",
       "      <td>23294</td>\n",
       "      <td>0.503301</td>\n",
       "      <td>0.336207</td>\n",
       "      <td>0.747832</td>\n",
       "      <td>0.0134529</td>\n",
       "      <td>0.0258706</td>\n",
       "      <td>0.378495</td>\n",
       "      <td>0.746244</td>\n",
       "      <td>0.0303553</td>\n",
       "      <td>0.0562031</td>\n",
       "      <td>0.387457</td>\n",
       "      <td>0.739847</td>\n",
       "      <td>0.0777854</td>\n",
       "      <td>0.12956</td>\n",
       "      <td>0.393302</td>\n",
       "      <td>0.729759</td>\n",
       "      <td>0.157986</td>\n",
       "      <td>0.225421</td>\n",
       "      <td>0.367969</td>\n",
       "      <td>0.698291</td>\n",
       "      <td>0.295619</td>\n",
       "      <td>0.32785</td>\n",
       "      <td>0.350172</td>\n",
       "      <td>0.6612</td>\n",
       "      <td>0.422042</td>\n",
       "      <td>0.382762</td>\n",
       "      <td>0.323431</td>\n",
       "      <td>0.574526</td>\n",
       "      <td>0.649707</td>\n",
       "      <td>0.431872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2012-04-30</td>\n",
       "      <td>2012-07-01</td>\n",
       "      <td>2012-10-31</td>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>21180</td>\n",
       "      <td>23294</td>\n",
       "      <td>0.509482</td>\n",
       "      <td>0.37931</td>\n",
       "      <td>0.748691</td>\n",
       "      <td>0.0151776</td>\n",
       "      <td>0.0291874</td>\n",
       "      <td>0.372043</td>\n",
       "      <td>0.745986</td>\n",
       "      <td>0.0298379</td>\n",
       "      <td>0.0552451</td>\n",
       "      <td>0.384021</td>\n",
       "      <td>0.739504</td>\n",
       "      <td>0.0770956</td>\n",
       "      <td>0.128411</td>\n",
       "      <td>0.362817</td>\n",
       "      <td>0.723663</td>\n",
       "      <td>0.14574</td>\n",
       "      <td>0.207949</td>\n",
       "      <td>0.352082</td>\n",
       "      <td>0.691938</td>\n",
       "      <td>0.282856</td>\n",
       "      <td>0.313695</td>\n",
       "      <td>0.338294</td>\n",
       "      <td>0.654074</td>\n",
       "      <td>0.407727</td>\n",
       "      <td>0.369779</td>\n",
       "      <td>0.310466</td>\n",
       "      <td>0.561561</td>\n",
       "      <td>0.623663</td>\n",
       "      <td>0.41456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2012-04-30</td>\n",
       "      <td>2012-07-01</td>\n",
       "      <td>2012-10-31</td>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>21180</td>\n",
       "      <td>23294</td>\n",
       "      <td>0.500902</td>\n",
       "      <td>0.362069</td>\n",
       "      <td>0.748347</td>\n",
       "      <td>0.0144878</td>\n",
       "      <td>0.0278607</td>\n",
       "      <td>0.384946</td>\n",
       "      <td>0.746501</td>\n",
       "      <td>0.0308727</td>\n",
       "      <td>0.0571611</td>\n",
       "      <td>0.39433</td>\n",
       "      <td>0.740534</td>\n",
       "      <td>0.0791652</td>\n",
       "      <td>0.131859</td>\n",
       "      <td>0.392872</td>\n",
       "      <td>0.729673</td>\n",
       "      <td>0.157813</td>\n",
       "      <td>0.225175</td>\n",
       "      <td>0.37398</td>\n",
       "      <td>0.700695</td>\n",
       "      <td>0.300448</td>\n",
       "      <td>0.333206</td>\n",
       "      <td>0.353749</td>\n",
       "      <td>0.663347</td>\n",
       "      <td>0.426354</td>\n",
       "      <td>0.386673</td>\n",
       "      <td>0.326694</td>\n",
       "      <td>0.577788</td>\n",
       "      <td>0.656261</td>\n",
       "      <td>0.436228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2012-04-30</td>\n",
       "      <td>2012-07-01</td>\n",
       "      <td>2012-10-31</td>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>21180</td>\n",
       "      <td>23294</td>\n",
       "      <td>0.506724</td>\n",
       "      <td>0.366379</td>\n",
       "      <td>0.748433</td>\n",
       "      <td>0.0146602</td>\n",
       "      <td>0.0281924</td>\n",
       "      <td>0.329032</td>\n",
       "      <td>0.744269</td>\n",
       "      <td>0.0263884</td>\n",
       "      <td>0.0488584</td>\n",
       "      <td>0.324742</td>\n",
       "      <td>0.733579</td>\n",
       "      <td>0.0651949</td>\n",
       "      <td>0.108589</td>\n",
       "      <td>0.314298</td>\n",
       "      <td>0.713961</td>\n",
       "      <td>0.12625</td>\n",
       "      <td>0.18014</td>\n",
       "      <td>0.309575</td>\n",
       "      <td>0.674938</td>\n",
       "      <td>0.248706</td>\n",
       "      <td>0.275822</td>\n",
       "      <td>0.303377</td>\n",
       "      <td>0.633124</td>\n",
       "      <td>0.365643</td>\n",
       "      <td>0.331613</td>\n",
       "      <td>0.289087</td>\n",
       "      <td>0.540182</td>\n",
       "      <td>0.580717</td>\n",
       "      <td>0.386013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2012-04-30</td>\n",
       "      <td>2012-07-01</td>\n",
       "      <td>2012-10-31</td>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>21180</td>\n",
       "      <td>23294</td>\n",
       "      <td>0.497796</td>\n",
       "      <td>0.366379</td>\n",
       "      <td>0.748433</td>\n",
       "      <td>0.0146602</td>\n",
       "      <td>0.0281924</td>\n",
       "      <td>0.372043</td>\n",
       "      <td>0.745986</td>\n",
       "      <td>0.0298379</td>\n",
       "      <td>0.0552451</td>\n",
       "      <td>0.351375</td>\n",
       "      <td>0.736241</td>\n",
       "      <td>0.0705416</td>\n",
       "      <td>0.117495</td>\n",
       "      <td>0.351653</td>\n",
       "      <td>0.72143</td>\n",
       "      <td>0.141256</td>\n",
       "      <td>0.20155</td>\n",
       "      <td>0.334908</td>\n",
       "      <td>0.685069</td>\n",
       "      <td>0.269058</td>\n",
       "      <td>0.298393</td>\n",
       "      <td>0.32842</td>\n",
       "      <td>0.64815</td>\n",
       "      <td>0.395826</td>\n",
       "      <td>0.358986</td>\n",
       "      <td>0.314845</td>\n",
       "      <td>0.56594</td>\n",
       "      <td>0.632459</td>\n",
       "      <td>0.420407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2012-04-30</td>\n",
       "      <td>2012-07-01</td>\n",
       "      <td>2012-10-31</td>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>21180</td>\n",
       "      <td>23294</td>\n",
       "      <td>0.491997</td>\n",
       "      <td>0.37931</td>\n",
       "      <td>0.748691</td>\n",
       "      <td>0.0151776</td>\n",
       "      <td>0.0291874</td>\n",
       "      <td>0.402151</td>\n",
       "      <td>0.747188</td>\n",
       "      <td>0.0322525</td>\n",
       "      <td>0.0597158</td>\n",
       "      <td>0.349656</td>\n",
       "      <td>0.736069</td>\n",
       "      <td>0.0701966</td>\n",
       "      <td>0.11692</td>\n",
       "      <td>0.337913</td>\n",
       "      <td>0.718683</td>\n",
       "      <td>0.135736</td>\n",
       "      <td>0.193675</td>\n",
       "      <td>0.330399</td>\n",
       "      <td>0.683266</td>\n",
       "      <td>0.265436</td>\n",
       "      <td>0.294376</td>\n",
       "      <td>0.319118</td>\n",
       "      <td>0.642569</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.348819</td>\n",
       "      <td>0.301279</td>\n",
       "      <td>0.552374</td>\n",
       "      <td>0.605209</td>\n",
       "      <td>0.402293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2012-04-30</td>\n",
       "      <td>2012-07-01</td>\n",
       "      <td>2012-10-31</td>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>21180</td>\n",
       "      <td>23294</td>\n",
       "      <td>0.495912</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.748605</td>\n",
       "      <td>0.0150052</td>\n",
       "      <td>0.0288557</td>\n",
       "      <td>0.387097</td>\n",
       "      <td>0.746587</td>\n",
       "      <td>0.0310452</td>\n",
       "      <td>0.0574804</td>\n",
       "      <td>0.362543</td>\n",
       "      <td>0.737357</td>\n",
       "      <td>0.0727837</td>\n",
       "      <td>0.12123</td>\n",
       "      <td>0.364964</td>\n",
       "      <td>0.724092</td>\n",
       "      <td>0.146602</td>\n",
       "      <td>0.209179</td>\n",
       "      <td>0.353585</td>\n",
       "      <td>0.692539</td>\n",
       "      <td>0.284063</td>\n",
       "      <td>0.315034</td>\n",
       "      <td>0.347167</td>\n",
       "      <td>0.659397</td>\n",
       "      <td>0.41842</td>\n",
       "      <td>0.379478</td>\n",
       "      <td>0.321113</td>\n",
       "      <td>0.572207</td>\n",
       "      <td>0.64505</td>\n",
       "      <td>0.428776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2012-04-30</td>\n",
       "      <td>2012-07-01</td>\n",
       "      <td>2012-10-31</td>\n",
       "      <td>AB</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>21180</td>\n",
       "      <td>23294</td>\n",
       "      <td>0.501167</td>\n",
       "      <td>1</td>\n",
       "      <td>0.761054</td>\n",
       "      <td>0.0400138</td>\n",
       "      <td>0.0769486</td>\n",
       "      <td>1</td>\n",
       "      <td>0.771057</td>\n",
       "      <td>0.0802001</td>\n",
       "      <td>0.148491</td>\n",
       "      <td>1</td>\n",
       "      <td>0.801065</td>\n",
       "      <td>0.200759</td>\n",
       "      <td>0.334387</td>\n",
       "      <td>1</td>\n",
       "      <td>0.851078</td>\n",
       "      <td>0.40169</td>\n",
       "      <td>0.573151</td>\n",
       "      <td>0.935809</td>\n",
       "      <td>0.925389</td>\n",
       "      <td>0.751811</td>\n",
       "      <td>0.83378</td>\n",
       "      <td>0.623784</td>\n",
       "      <td>0.825363</td>\n",
       "      <td>0.751811</td>\n",
       "      <td>0.68184</td>\n",
       "      <td>0.374259</td>\n",
       "      <td>0.625354</td>\n",
       "      <td>0.751811</td>\n",
       "      <td>0.499742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2012-04-30</td>\n",
       "      <td>2012-07-01</td>\n",
       "      <td>2012-10-31</td>\n",
       "      <td>LR</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>21180</td>\n",
       "      <td>23294</td>\n",
       "      <td>0.500288</td>\n",
       "      <td>0.443966</td>\n",
       "      <td>0.749979</td>\n",
       "      <td>0.0177647</td>\n",
       "      <td>0.0341625</td>\n",
       "      <td>0.365591</td>\n",
       "      <td>0.745729</td>\n",
       "      <td>0.0293205</td>\n",
       "      <td>0.0542871</td>\n",
       "      <td>0.377148</td>\n",
       "      <td>0.738817</td>\n",
       "      <td>0.0757158</td>\n",
       "      <td>0.126113</td>\n",
       "      <td>0.371833</td>\n",
       "      <td>0.725466</td>\n",
       "      <td>0.149362</td>\n",
       "      <td>0.213117</td>\n",
       "      <td>0.340704</td>\n",
       "      <td>0.687387</td>\n",
       "      <td>0.273715</td>\n",
       "      <td>0.303558</td>\n",
       "      <td>0.320406</td>\n",
       "      <td>0.643342</td>\n",
       "      <td>0.386168</td>\n",
       "      <td>0.350227</td>\n",
       "      <td>0.278183</td>\n",
       "      <td>0.529278</td>\n",
       "      <td>0.558813</td>\n",
       "      <td>0.371453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2012-04-30</td>\n",
       "      <td>2012-07-01</td>\n",
       "      <td>2012-10-31</td>\n",
       "      <td>LR</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>21180</td>\n",
       "      <td>23294</td>\n",
       "      <td>0.501577</td>\n",
       "      <td>0.452586</td>\n",
       "      <td>0.75015</td>\n",
       "      <td>0.0181097</td>\n",
       "      <td>0.0348259</td>\n",
       "      <td>0.408602</td>\n",
       "      <td>0.747446</td>\n",
       "      <td>0.0327699</td>\n",
       "      <td>0.0606738</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.742766</td>\n",
       "      <td>0.0836495</td>\n",
       "      <td>0.139328</td>\n",
       "      <td>0.408759</td>\n",
       "      <td>0.73285</td>\n",
       "      <td>0.164195</td>\n",
       "      <td>0.234281</td>\n",
       "      <td>0.369257</td>\n",
       "      <td>0.698807</td>\n",
       "      <td>0.296654</td>\n",
       "      <td>0.328998</td>\n",
       "      <td>0.349027</td>\n",
       "      <td>0.660513</td>\n",
       "      <td>0.420662</td>\n",
       "      <td>0.381511</td>\n",
       "      <td>0.315017</td>\n",
       "      <td>0.566111</td>\n",
       "      <td>0.632804</td>\n",
       "      <td>0.420636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2012-04-30</td>\n",
       "      <td>2012-07-01</td>\n",
       "      <td>2012-10-31</td>\n",
       "      <td>LR</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>21180</td>\n",
       "      <td>23294</td>\n",
       "      <td>0.502403</td>\n",
       "      <td>0.474138</td>\n",
       "      <td>0.75058</td>\n",
       "      <td>0.0189721</td>\n",
       "      <td>0.0364842</td>\n",
       "      <td>0.464516</td>\n",
       "      <td>0.749678</td>\n",
       "      <td>0.0372542</td>\n",
       "      <td>0.0689765</td>\n",
       "      <td>0.449313</td>\n",
       "      <td>0.746029</td>\n",
       "      <td>0.0902035</td>\n",
       "      <td>0.150244</td>\n",
       "      <td>0.430657</td>\n",
       "      <td>0.737228</td>\n",
       "      <td>0.172991</td>\n",
       "      <td>0.246832</td>\n",
       "      <td>0.386861</td>\n",
       "      <td>0.705847</td>\n",
       "      <td>0.310797</td>\n",
       "      <td>0.344682</td>\n",
       "      <td>0.356611</td>\n",
       "      <td>0.665064</td>\n",
       "      <td>0.429803</td>\n",
       "      <td>0.389801</td>\n",
       "      <td>0.315532</td>\n",
       "      <td>0.566627</td>\n",
       "      <td>0.633839</td>\n",
       "      <td>0.421324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2012-04-30</td>\n",
       "      <td>2012-07-01</td>\n",
       "      <td>2012-10-31</td>\n",
       "      <td>LR</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>21180</td>\n",
       "      <td>23294</td>\n",
       "      <td>0.502290</td>\n",
       "      <td>0.491379</td>\n",
       "      <td>0.750923</td>\n",
       "      <td>0.019662</td>\n",
       "      <td>0.0378109</td>\n",
       "      <td>0.458065</td>\n",
       "      <td>0.74942</td>\n",
       "      <td>0.0367368</td>\n",
       "      <td>0.0680185</td>\n",
       "      <td>0.439003</td>\n",
       "      <td>0.744999</td>\n",
       "      <td>0.0881338</td>\n",
       "      <td>0.146797</td>\n",
       "      <td>0.410906</td>\n",
       "      <td>0.733279</td>\n",
       "      <td>0.165057</td>\n",
       "      <td>0.235511</td>\n",
       "      <td>0.374839</td>\n",
       "      <td>0.701039</td>\n",
       "      <td>0.301138</td>\n",
       "      <td>0.333971</td>\n",
       "      <td>0.350458</td>\n",
       "      <td>0.661372</td>\n",
       "      <td>0.422387</td>\n",
       "      <td>0.383075</td>\n",
       "      <td>0.315188</td>\n",
       "      <td>0.566283</td>\n",
       "      <td>0.633149</td>\n",
       "      <td>0.420866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2012-04-30</td>\n",
       "      <td>2012-07-01</td>\n",
       "      <td>2012-10-31</td>\n",
       "      <td>LR</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>21180</td>\n",
       "      <td>23294</td>\n",
       "      <td>0.493619</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.751095</td>\n",
       "      <td>0.0200069</td>\n",
       "      <td>0.0384743</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.749764</td>\n",
       "      <td>0.0374267</td>\n",
       "      <td>0.0692959</td>\n",
       "      <td>0.420103</td>\n",
       "      <td>0.74311</td>\n",
       "      <td>0.0843394</td>\n",
       "      <td>0.140477</td>\n",
       "      <td>0.397166</td>\n",
       "      <td>0.730531</td>\n",
       "      <td>0.159538</td>\n",
       "      <td>0.227636</td>\n",
       "      <td>0.374624</td>\n",
       "      <td>0.700953</td>\n",
       "      <td>0.300966</td>\n",
       "      <td>0.33378</td>\n",
       "      <td>0.345879</td>\n",
       "      <td>0.658625</td>\n",
       "      <td>0.416868</td>\n",
       "      <td>0.37807</td>\n",
       "      <td>0.309007</td>\n",
       "      <td>0.560101</td>\n",
       "      <td>0.620731</td>\n",
       "      <td>0.412611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-04-30</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>2013-10-31</td>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>74241</td>\n",
       "      <td>31563</td>\n",
       "      <td>0.497006</td>\n",
       "      <td>1</td>\n",
       "      <td>0.74299</td>\n",
       "      <td>0.0373799</td>\n",
       "      <td>0.0720659</td>\n",
       "      <td>1</td>\n",
       "      <td>0.753002</td>\n",
       "      <td>0.0748784</td>\n",
       "      <td>0.139324</td>\n",
       "      <td>1</td>\n",
       "      <td>0.783005</td>\n",
       "      <td>0.187255</td>\n",
       "      <td>0.315442</td>\n",
       "      <td>1</td>\n",
       "      <td>0.833001</td>\n",
       "      <td>0.374511</td>\n",
       "      <td>0.544937</td>\n",
       "      <td>1</td>\n",
       "      <td>0.932991</td>\n",
       "      <td>0.749021</td>\n",
       "      <td>0.856503</td>\n",
       "      <td>0.745353</td>\n",
       "      <td>0.880208</td>\n",
       "      <td>0.837427</td>\n",
       "      <td>0.788712</td>\n",
       "      <td>0.447183</td>\n",
       "      <td>0.680195</td>\n",
       "      <td>0.837427</td>\n",
       "      <td>0.58303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-04-30</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>2013-10-31</td>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>74241</td>\n",
       "      <td>31563</td>\n",
       "      <td>0.497006</td>\n",
       "      <td>1</td>\n",
       "      <td>0.74299</td>\n",
       "      <td>0.0373799</td>\n",
       "      <td>0.0720659</td>\n",
       "      <td>1</td>\n",
       "      <td>0.753002</td>\n",
       "      <td>0.0748784</td>\n",
       "      <td>0.139324</td>\n",
       "      <td>1</td>\n",
       "      <td>0.783005</td>\n",
       "      <td>0.187255</td>\n",
       "      <td>0.315442</td>\n",
       "      <td>1</td>\n",
       "      <td>0.833001</td>\n",
       "      <td>0.374511</td>\n",
       "      <td>0.544937</td>\n",
       "      <td>1</td>\n",
       "      <td>0.932991</td>\n",
       "      <td>0.749021</td>\n",
       "      <td>0.856503</td>\n",
       "      <td>0.745353</td>\n",
       "      <td>0.880208</td>\n",
       "      <td>0.837427</td>\n",
       "      <td>0.788712</td>\n",
       "      <td>0.447183</td>\n",
       "      <td>0.680195</td>\n",
       "      <td>0.837427</td>\n",
       "      <td>0.58303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-04-30</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>2013-10-31</td>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>74241</td>\n",
       "      <td>31563</td>\n",
       "      <td>0.497006</td>\n",
       "      <td>1</td>\n",
       "      <td>0.74299</td>\n",
       "      <td>0.0373799</td>\n",
       "      <td>0.0720659</td>\n",
       "      <td>1</td>\n",
       "      <td>0.753002</td>\n",
       "      <td>0.0748784</td>\n",
       "      <td>0.139324</td>\n",
       "      <td>1</td>\n",
       "      <td>0.783005</td>\n",
       "      <td>0.187255</td>\n",
       "      <td>0.315442</td>\n",
       "      <td>1</td>\n",
       "      <td>0.833001</td>\n",
       "      <td>0.374511</td>\n",
       "      <td>0.544937</td>\n",
       "      <td>1</td>\n",
       "      <td>0.932991</td>\n",
       "      <td>0.749021</td>\n",
       "      <td>0.856503</td>\n",
       "      <td>0.745353</td>\n",
       "      <td>0.880208</td>\n",
       "      <td>0.837427</td>\n",
       "      <td>0.788712</td>\n",
       "      <td>0.447183</td>\n",
       "      <td>0.680195</td>\n",
       "      <td>0.837427</td>\n",
       "      <td>0.58303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-04-30</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>2013-10-31</td>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>74241</td>\n",
       "      <td>31563</td>\n",
       "      <td>0.496615</td>\n",
       "      <td>0.384127</td>\n",
       "      <td>0.730697</td>\n",
       "      <td>0.0143586</td>\n",
       "      <td>0.0276825</td>\n",
       "      <td>0.440571</td>\n",
       "      <td>0.730634</td>\n",
       "      <td>0.0329892</td>\n",
       "      <td>0.0613822</td>\n",
       "      <td>0.581749</td>\n",
       "      <td>0.741184</td>\n",
       "      <td>0.108936</td>\n",
       "      <td>0.183508</td>\n",
       "      <td>0.450887</td>\n",
       "      <td>0.723189</td>\n",
       "      <td>0.168862</td>\n",
       "      <td>0.245705</td>\n",
       "      <td>0.414766</td>\n",
       "      <td>0.69892</td>\n",
       "      <td>0.310668</td>\n",
       "      <td>0.355248</td>\n",
       "      <td>0.399768</td>\n",
       "      <td>0.672876</td>\n",
       "      <td>0.449152</td>\n",
       "      <td>0.423023</td>\n",
       "      <td>0.356188</td>\n",
       "      <td>0.589203</td>\n",
       "      <td>0.667023</td>\n",
       "      <td>0.464392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-04-30</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>2013-10-31</td>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>74241</td>\n",
       "      <td>31563</td>\n",
       "      <td>0.500203</td>\n",
       "      <td>0.393651</td>\n",
       "      <td>0.730887</td>\n",
       "      <td>0.0147146</td>\n",
       "      <td>0.0283688</td>\n",
       "      <td>0.438986</td>\n",
       "      <td>0.730571</td>\n",
       "      <td>0.0328705</td>\n",
       "      <td>0.0611614</td>\n",
       "      <td>0.591255</td>\n",
       "      <td>0.742135</td>\n",
       "      <td>0.110716</td>\n",
       "      <td>0.186507</td>\n",
       "      <td>0.451521</td>\n",
       "      <td>0.723315</td>\n",
       "      <td>0.169099</td>\n",
       "      <td>0.24605</td>\n",
       "      <td>0.415082</td>\n",
       "      <td>0.699046</td>\n",
       "      <td>0.310905</td>\n",
       "      <td>0.355519</td>\n",
       "      <td>0.40019</td>\n",
       "      <td>0.67313</td>\n",
       "      <td>0.449626</td>\n",
       "      <td>0.42347</td>\n",
       "      <td>0.356505</td>\n",
       "      <td>0.589519</td>\n",
       "      <td>0.667616</td>\n",
       "      <td>0.464805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-04-30</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>2013-10-31</td>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>74241</td>\n",
       "      <td>31563</td>\n",
       "      <td>0.498367</td>\n",
       "      <td>0.384127</td>\n",
       "      <td>0.730697</td>\n",
       "      <td>0.0143586</td>\n",
       "      <td>0.0276825</td>\n",
       "      <td>0.437401</td>\n",
       "      <td>0.730507</td>\n",
       "      <td>0.0327519</td>\n",
       "      <td>0.0609406</td>\n",
       "      <td>0.590621</td>\n",
       "      <td>0.742071</td>\n",
       "      <td>0.110597</td>\n",
       "      <td>0.186307</td>\n",
       "      <td>0.450887</td>\n",
       "      <td>0.723189</td>\n",
       "      <td>0.168862</td>\n",
       "      <td>0.245705</td>\n",
       "      <td>0.414766</td>\n",
       "      <td>0.69892</td>\n",
       "      <td>0.310668</td>\n",
       "      <td>0.355248</td>\n",
       "      <td>0.399662</td>\n",
       "      <td>0.672813</td>\n",
       "      <td>0.449033</td>\n",
       "      <td>0.422911</td>\n",
       "      <td>0.356505</td>\n",
       "      <td>0.589519</td>\n",
       "      <td>0.667616</td>\n",
       "      <td>0.464805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-04-30</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>2013-10-31</td>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>74241</td>\n",
       "      <td>31563</td>\n",
       "      <td>0.497705</td>\n",
       "      <td>1</td>\n",
       "      <td>0.74299</td>\n",
       "      <td>0.0373799</td>\n",
       "      <td>0.0720659</td>\n",
       "      <td>1</td>\n",
       "      <td>0.753002</td>\n",
       "      <td>0.0748784</td>\n",
       "      <td>0.139324</td>\n",
       "      <td>0.472117</td>\n",
       "      <td>0.730222</td>\n",
       "      <td>0.0884063</td>\n",
       "      <td>0.148926</td>\n",
       "      <td>0.363118</td>\n",
       "      <td>0.705636</td>\n",
       "      <td>0.135991</td>\n",
       "      <td>0.197876</td>\n",
       "      <td>0.412389</td>\n",
       "      <td>0.697969</td>\n",
       "      <td>0.308888</td>\n",
       "      <td>0.353213</td>\n",
       "      <td>0.389945</td>\n",
       "      <td>0.666983</td>\n",
       "      <td>0.438116</td>\n",
       "      <td>0.412629</td>\n",
       "      <td>0.352196</td>\n",
       "      <td>0.585211</td>\n",
       "      <td>0.659547</td>\n",
       "      <td>0.459187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-04-30</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>2013-10-31</td>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>74241</td>\n",
       "      <td>31563</td>\n",
       "      <td>0.501450</td>\n",
       "      <td>1</td>\n",
       "      <td>0.74299</td>\n",
       "      <td>0.0373799</td>\n",
       "      <td>0.0720659</td>\n",
       "      <td>1</td>\n",
       "      <td>0.753002</td>\n",
       "      <td>0.0748784</td>\n",
       "      <td>0.139324</td>\n",
       "      <td>0.448669</td>\n",
       "      <td>0.727878</td>\n",
       "      <td>0.0840157</td>\n",
       "      <td>0.141529</td>\n",
       "      <td>0.370089</td>\n",
       "      <td>0.70703</td>\n",
       "      <td>0.138602</td>\n",
       "      <td>0.201675</td>\n",
       "      <td>0.411914</td>\n",
       "      <td>0.697779</td>\n",
       "      <td>0.308532</td>\n",
       "      <td>0.352805</td>\n",
       "      <td>0.391001</td>\n",
       "      <td>0.667617</td>\n",
       "      <td>0.439302</td>\n",
       "      <td>0.413747</td>\n",
       "      <td>0.358406</td>\n",
       "      <td>0.59142</td>\n",
       "      <td>0.671176</td>\n",
       "      <td>0.467284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-04-30</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>2013-10-31</td>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>74241</td>\n",
       "      <td>31563</td>\n",
       "      <td>0.495548</td>\n",
       "      <td>1</td>\n",
       "      <td>0.74299</td>\n",
       "      <td>0.0373799</td>\n",
       "      <td>0.0720659</td>\n",
       "      <td>0.857369</td>\n",
       "      <td>0.747299</td>\n",
       "      <td>0.0641984</td>\n",
       "      <td>0.119452</td>\n",
       "      <td>0.369455</td>\n",
       "      <td>0.719957</td>\n",
       "      <td>0.0691824</td>\n",
       "      <td>0.116542</td>\n",
       "      <td>0.37199</td>\n",
       "      <td>0.707411</td>\n",
       "      <td>0.139314</td>\n",
       "      <td>0.202711</td>\n",
       "      <td>0.402567</td>\n",
       "      <td>0.69404</td>\n",
       "      <td>0.301531</td>\n",
       "      <td>0.3448</td>\n",
       "      <td>0.393642</td>\n",
       "      <td>0.669201</td>\n",
       "      <td>0.442269</td>\n",
       "      <td>0.416541</td>\n",
       "      <td>0.363095</td>\n",
       "      <td>0.596109</td>\n",
       "      <td>0.679957</td>\n",
       "      <td>0.473397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-04-30</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>2013-10-31</td>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>74241</td>\n",
       "      <td>31563</td>\n",
       "      <td>0.500567</td>\n",
       "      <td>1</td>\n",
       "      <td>0.74299</td>\n",
       "      <td>0.0373799</td>\n",
       "      <td>0.0720659</td>\n",
       "      <td>1</td>\n",
       "      <td>0.753002</td>\n",
       "      <td>0.0748784</td>\n",
       "      <td>0.139324</td>\n",
       "      <td>1</td>\n",
       "      <td>0.783005</td>\n",
       "      <td>0.187255</td>\n",
       "      <td>0.315442</td>\n",
       "      <td>0.950253</td>\n",
       "      <td>0.823052</td>\n",
       "      <td>0.35588</td>\n",
       "      <td>0.517828</td>\n",
       "      <td>0.475127</td>\n",
       "      <td>0.723062</td>\n",
       "      <td>0.35588</td>\n",
       "      <td>0.406948</td>\n",
       "      <td>0.343684</td>\n",
       "      <td>0.639229</td>\n",
       "      <td>0.38614</td>\n",
       "      <td>0.363677</td>\n",
       "      <td>0.533997</td>\n",
       "      <td>0.767006</td>\n",
       "      <td>1</td>\n",
       "      <td>0.696216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-04-30</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>2013-10-31</td>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>74241</td>\n",
       "      <td>31563</td>\n",
       "      <td>0.500874</td>\n",
       "      <td>1</td>\n",
       "      <td>0.74299</td>\n",
       "      <td>0.0373799</td>\n",
       "      <td>0.0720659</td>\n",
       "      <td>1</td>\n",
       "      <td>0.753002</td>\n",
       "      <td>0.0748784</td>\n",
       "      <td>0.139324</td>\n",
       "      <td>1</td>\n",
       "      <td>0.783005</td>\n",
       "      <td>0.187255</td>\n",
       "      <td>0.315442</td>\n",
       "      <td>0.834918</td>\n",
       "      <td>0.799987</td>\n",
       "      <td>0.312685</td>\n",
       "      <td>0.454977</td>\n",
       "      <td>0.417459</td>\n",
       "      <td>0.699997</td>\n",
       "      <td>0.312685</td>\n",
       "      <td>0.357555</td>\n",
       "      <td>0.361005</td>\n",
       "      <td>0.649621</td>\n",
       "      <td>0.405601</td>\n",
       "      <td>0.382006</td>\n",
       "      <td>0.533997</td>\n",
       "      <td>0.767006</td>\n",
       "      <td>1</td>\n",
       "      <td>0.696216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-04-30</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>2013-10-31</td>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>74241</td>\n",
       "      <td>31563</td>\n",
       "      <td>0.497346</td>\n",
       "      <td>1</td>\n",
       "      <td>0.74299</td>\n",
       "      <td>0.0373799</td>\n",
       "      <td>0.0720659</td>\n",
       "      <td>1</td>\n",
       "      <td>0.753002</td>\n",
       "      <td>0.0748784</td>\n",
       "      <td>0.139324</td>\n",
       "      <td>1</td>\n",
       "      <td>0.783005</td>\n",
       "      <td>0.187255</td>\n",
       "      <td>0.315442</td>\n",
       "      <td>0.624842</td>\n",
       "      <td>0.757976</td>\n",
       "      <td>0.23401</td>\n",
       "      <td>0.340499</td>\n",
       "      <td>0.378961</td>\n",
       "      <td>0.684599</td>\n",
       "      <td>0.28385</td>\n",
       "      <td>0.324581</td>\n",
       "      <td>0.364913</td>\n",
       "      <td>0.651966</td>\n",
       "      <td>0.409992</td>\n",
       "      <td>0.386141</td>\n",
       "      <td>0.468982</td>\n",
       "      <td>0.701993</td>\n",
       "      <td>0.878248</td>\n",
       "      <td>0.611451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-04-30</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>2013-10-31</td>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>74241</td>\n",
       "      <td>31563</td>\n",
       "      <td>0.499567</td>\n",
       "      <td>1</td>\n",
       "      <td>0.74299</td>\n",
       "      <td>0.0373799</td>\n",
       "      <td>0.0720659</td>\n",
       "      <td>1</td>\n",
       "      <td>0.753002</td>\n",
       "      <td>0.0748784</td>\n",
       "      <td>0.139324</td>\n",
       "      <td>1</td>\n",
       "      <td>0.783005</td>\n",
       "      <td>0.187255</td>\n",
       "      <td>0.315442</td>\n",
       "      <td>1</td>\n",
       "      <td>0.833001</td>\n",
       "      <td>0.374511</td>\n",
       "      <td>0.544937</td>\n",
       "      <td>1</td>\n",
       "      <td>0.932991</td>\n",
       "      <td>0.749021</td>\n",
       "      <td>0.856503</td>\n",
       "      <td>0.770384</td>\n",
       "      <td>0.895225</td>\n",
       "      <td>0.865551</td>\n",
       "      <td>0.8152</td>\n",
       "      <td>0.462201</td>\n",
       "      <td>0.695213</td>\n",
       "      <td>0.865551</td>\n",
       "      <td>0.602611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-04-30</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>2013-10-31</td>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>74241</td>\n",
       "      <td>31563</td>\n",
       "      <td>0.499567</td>\n",
       "      <td>1</td>\n",
       "      <td>0.74299</td>\n",
       "      <td>0.0373799</td>\n",
       "      <td>0.0720659</td>\n",
       "      <td>1</td>\n",
       "      <td>0.753002</td>\n",
       "      <td>0.0748784</td>\n",
       "      <td>0.139324</td>\n",
       "      <td>1</td>\n",
       "      <td>0.783005</td>\n",
       "      <td>0.187255</td>\n",
       "      <td>0.315442</td>\n",
       "      <td>1</td>\n",
       "      <td>0.833001</td>\n",
       "      <td>0.374511</td>\n",
       "      <td>0.544937</td>\n",
       "      <td>1</td>\n",
       "      <td>0.932991</td>\n",
       "      <td>0.749021</td>\n",
       "      <td>0.856503</td>\n",
       "      <td>0.770384</td>\n",
       "      <td>0.895225</td>\n",
       "      <td>0.865551</td>\n",
       "      <td>0.8152</td>\n",
       "      <td>0.462201</td>\n",
       "      <td>0.695213</td>\n",
       "      <td>0.865551</td>\n",
       "      <td>0.602611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-04-30</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>2013-10-31</td>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>74241</td>\n",
       "      <td>31563</td>\n",
       "      <td>0.499567</td>\n",
       "      <td>1</td>\n",
       "      <td>0.74299</td>\n",
       "      <td>0.0373799</td>\n",
       "      <td>0.0720659</td>\n",
       "      <td>1</td>\n",
       "      <td>0.753002</td>\n",
       "      <td>0.0748784</td>\n",
       "      <td>0.139324</td>\n",
       "      <td>1</td>\n",
       "      <td>0.783005</td>\n",
       "      <td>0.187255</td>\n",
       "      <td>0.315442</td>\n",
       "      <td>1</td>\n",
       "      <td>0.833001</td>\n",
       "      <td>0.374511</td>\n",
       "      <td>0.544937</td>\n",
       "      <td>1</td>\n",
       "      <td>0.932991</td>\n",
       "      <td>0.749021</td>\n",
       "      <td>0.856503</td>\n",
       "      <td>0.770384</td>\n",
       "      <td>0.895225</td>\n",
       "      <td>0.865551</td>\n",
       "      <td>0.8152</td>\n",
       "      <td>0.462201</td>\n",
       "      <td>0.695213</td>\n",
       "      <td>0.865551</td>\n",
       "      <td>0.602611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-04-30</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>2013-10-31</td>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>74241</td>\n",
       "      <td>31563</td>\n",
       "      <td>0.499479</td>\n",
       "      <td>0.387302</td>\n",
       "      <td>0.730761</td>\n",
       "      <td>0.0144773</td>\n",
       "      <td>0.0279112</td>\n",
       "      <td>0.353407</td>\n",
       "      <td>0.727149</td>\n",
       "      <td>0.0264626</td>\n",
       "      <td>0.0492382</td>\n",
       "      <td>0.54436</td>\n",
       "      <td>0.737446</td>\n",
       "      <td>0.101934</td>\n",
       "      <td>0.171714</td>\n",
       "      <td>0.492712</td>\n",
       "      <td>0.731553</td>\n",
       "      <td>0.184526</td>\n",
       "      <td>0.268497</td>\n",
       "      <td>0.445976</td>\n",
       "      <td>0.711403</td>\n",
       "      <td>0.334045</td>\n",
       "      <td>0.38198</td>\n",
       "      <td>0.410646</td>\n",
       "      <td>0.679403</td>\n",
       "      <td>0.461374</td>\n",
       "      <td>0.434535</td>\n",
       "      <td>0.359673</td>\n",
       "      <td>0.592688</td>\n",
       "      <td>0.673549</td>\n",
       "      <td>0.468936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-04-30</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>2013-10-31</td>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>74241</td>\n",
       "      <td>31563</td>\n",
       "      <td>0.496617</td>\n",
       "      <td>0.365079</td>\n",
       "      <td>0.730317</td>\n",
       "      <td>0.0136466</td>\n",
       "      <td>0.0263098</td>\n",
       "      <td>0.354992</td>\n",
       "      <td>0.727212</td>\n",
       "      <td>0.0265812</td>\n",
       "      <td>0.049459</td>\n",
       "      <td>0.533587</td>\n",
       "      <td>0.736369</td>\n",
       "      <td>0.0999169</td>\n",
       "      <td>0.168316</td>\n",
       "      <td>0.493029</td>\n",
       "      <td>0.731616</td>\n",
       "      <td>0.184645</td>\n",
       "      <td>0.26867</td>\n",
       "      <td>0.443599</td>\n",
       "      <td>0.710452</td>\n",
       "      <td>0.332265</td>\n",
       "      <td>0.379944</td>\n",
       "      <td>0.409062</td>\n",
       "      <td>0.678453</td>\n",
       "      <td>0.459594</td>\n",
       "      <td>0.432858</td>\n",
       "      <td>0.358723</td>\n",
       "      <td>0.591737</td>\n",
       "      <td>0.671769</td>\n",
       "      <td>0.467697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-04-30</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>2013-10-31</td>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>74241</td>\n",
       "      <td>31563</td>\n",
       "      <td>0.496847</td>\n",
       "      <td>0.387302</td>\n",
       "      <td>0.730761</td>\n",
       "      <td>0.0144773</td>\n",
       "      <td>0.0279112</td>\n",
       "      <td>0.353407</td>\n",
       "      <td>0.727149</td>\n",
       "      <td>0.0264626</td>\n",
       "      <td>0.0492382</td>\n",
       "      <td>0.541825</td>\n",
       "      <td>0.737192</td>\n",
       "      <td>0.10146</td>\n",
       "      <td>0.170915</td>\n",
       "      <td>0.492395</td>\n",
       "      <td>0.731489</td>\n",
       "      <td>0.184407</td>\n",
       "      <td>0.268324</td>\n",
       "      <td>0.440589</td>\n",
       "      <td>0.709248</td>\n",
       "      <td>0.330011</td>\n",
       "      <td>0.377366</td>\n",
       "      <td>0.40695</td>\n",
       "      <td>0.677185</td>\n",
       "      <td>0.457221</td>\n",
       "      <td>0.430623</td>\n",
       "      <td>0.357455</td>\n",
       "      <td>0.59047</td>\n",
       "      <td>0.669396</td>\n",
       "      <td>0.466044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-04-30</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>2013-10-31</td>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>74241</td>\n",
       "      <td>31563</td>\n",
       "      <td>0.502508</td>\n",
       "      <td>1</td>\n",
       "      <td>0.74299</td>\n",
       "      <td>0.0373799</td>\n",
       "      <td>0.0720659</td>\n",
       "      <td>0.767036</td>\n",
       "      <td>0.743687</td>\n",
       "      <td>0.0574344</td>\n",
       "      <td>0.106867</td>\n",
       "      <td>0.312421</td>\n",
       "      <td>0.714254</td>\n",
       "      <td>0.0585024</td>\n",
       "      <td>0.0985507</td>\n",
       "      <td>0.382446</td>\n",
       "      <td>0.709502</td>\n",
       "      <td>0.14323</td>\n",
       "      <td>0.208409</td>\n",
       "      <td>0.403042</td>\n",
       "      <td>0.694231</td>\n",
       "      <td>0.301887</td>\n",
       "      <td>0.345207</td>\n",
       "      <td>0.38646</td>\n",
       "      <td>0.664892</td>\n",
       "      <td>0.4342</td>\n",
       "      <td>0.408941</td>\n",
       "      <td>0.360624</td>\n",
       "      <td>0.593638</td>\n",
       "      <td>0.675329</td>\n",
       "      <td>0.470175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-04-30</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>2013-10-31</td>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>74241</td>\n",
       "      <td>31563</td>\n",
       "      <td>0.500499</td>\n",
       "      <td>1</td>\n",
       "      <td>0.74299</td>\n",
       "      <td>0.0373799</td>\n",
       "      <td>0.0720659</td>\n",
       "      <td>0.743265</td>\n",
       "      <td>0.742737</td>\n",
       "      <td>0.0556544</td>\n",
       "      <td>0.103555</td>\n",
       "      <td>0.329531</td>\n",
       "      <td>0.715965</td>\n",
       "      <td>0.0617064</td>\n",
       "      <td>0.103948</td>\n",
       "      <td>0.375475</td>\n",
       "      <td>0.708108</td>\n",
       "      <td>0.140619</td>\n",
       "      <td>0.20461</td>\n",
       "      <td>0.394487</td>\n",
       "      <td>0.690809</td>\n",
       "      <td>0.295479</td>\n",
       "      <td>0.337879</td>\n",
       "      <td>0.384347</td>\n",
       "      <td>0.663625</td>\n",
       "      <td>0.431826</td>\n",
       "      <td>0.406706</td>\n",
       "      <td>0.358723</td>\n",
       "      <td>0.591737</td>\n",
       "      <td>0.671769</td>\n",
       "      <td>0.467697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-04-30</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>2013-10-31</td>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>74241</td>\n",
       "      <td>31563</td>\n",
       "      <td>0.500441</td>\n",
       "      <td>1</td>\n",
       "      <td>0.74299</td>\n",
       "      <td>0.0373799</td>\n",
       "      <td>0.0720659</td>\n",
       "      <td>0.564184</td>\n",
       "      <td>0.735576</td>\n",
       "      <td>0.0422452</td>\n",
       "      <td>0.0786045</td>\n",
       "      <td>0.334601</td>\n",
       "      <td>0.716472</td>\n",
       "      <td>0.0626557</td>\n",
       "      <td>0.105547</td>\n",
       "      <td>0.374525</td>\n",
       "      <td>0.707917</td>\n",
       "      <td>0.140263</td>\n",
       "      <td>0.204092</td>\n",
       "      <td>0.400982</td>\n",
       "      <td>0.693407</td>\n",
       "      <td>0.300344</td>\n",
       "      <td>0.343443</td>\n",
       "      <td>0.384242</td>\n",
       "      <td>0.663562</td>\n",
       "      <td>0.431708</td>\n",
       "      <td>0.406594</td>\n",
       "      <td>0.352006</td>\n",
       "      <td>0.58502</td>\n",
       "      <td>0.659191</td>\n",
       "      <td>0.458939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-04-30</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>2013-10-31</td>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>74241</td>\n",
       "      <td>31563</td>\n",
       "      <td>0.500957</td>\n",
       "      <td>1</td>\n",
       "      <td>0.74299</td>\n",
       "      <td>0.0373799</td>\n",
       "      <td>0.0720659</td>\n",
       "      <td>1</td>\n",
       "      <td>0.753002</td>\n",
       "      <td>0.0748784</td>\n",
       "      <td>0.139324</td>\n",
       "      <td>1</td>\n",
       "      <td>0.783005</td>\n",
       "      <td>0.187255</td>\n",
       "      <td>0.315442</td>\n",
       "      <td>0.970215</td>\n",
       "      <td>0.827044</td>\n",
       "      <td>0.363356</td>\n",
       "      <td>0.528706</td>\n",
       "      <td>0.485108</td>\n",
       "      <td>0.727054</td>\n",
       "      <td>0.363356</td>\n",
       "      <td>0.415496</td>\n",
       "      <td>0.368716</td>\n",
       "      <td>0.654247</td>\n",
       "      <td>0.414264</td>\n",
       "      <td>0.390165</td>\n",
       "      <td>0.533997</td>\n",
       "      <td>0.767006</td>\n",
       "      <td>1</td>\n",
       "      <td>0.696216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-04-30</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>2013-10-31</td>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>74241</td>\n",
       "      <td>31563</td>\n",
       "      <td>0.498948</td>\n",
       "      <td>1</td>\n",
       "      <td>0.74299</td>\n",
       "      <td>0.0373799</td>\n",
       "      <td>0.0720659</td>\n",
       "      <td>1</td>\n",
       "      <td>0.753002</td>\n",
       "      <td>0.0748784</td>\n",
       "      <td>0.139324</td>\n",
       "      <td>1</td>\n",
       "      <td>0.783005</td>\n",
       "      <td>0.187255</td>\n",
       "      <td>0.315442</td>\n",
       "      <td>0.887516</td>\n",
       "      <td>0.810506</td>\n",
       "      <td>0.332384</td>\n",
       "      <td>0.48364</td>\n",
       "      <td>0.443758</td>\n",
       "      <td>0.710515</td>\n",
       "      <td>0.332384</td>\n",
       "      <td>0.38008</td>\n",
       "      <td>0.348542</td>\n",
       "      <td>0.642144</td>\n",
       "      <td>0.391598</td>\n",
       "      <td>0.368818</td>\n",
       "      <td>0.533997</td>\n",
       "      <td>0.767006</td>\n",
       "      <td>1</td>\n",
       "      <td>0.696216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-04-30</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>2013-10-31</td>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>74241</td>\n",
       "      <td>31563</td>\n",
       "      <td>0.494531</td>\n",
       "      <td>1</td>\n",
       "      <td>0.74299</td>\n",
       "      <td>0.0373799</td>\n",
       "      <td>0.0720659</td>\n",
       "      <td>1</td>\n",
       "      <td>0.753002</td>\n",
       "      <td>0.0748784</td>\n",
       "      <td>0.139324</td>\n",
       "      <td>1</td>\n",
       "      <td>0.783005</td>\n",
       "      <td>0.187255</td>\n",
       "      <td>0.315442</td>\n",
       "      <td>0.63815</td>\n",
       "      <td>0.760637</td>\n",
       "      <td>0.238994</td>\n",
       "      <td>0.347751</td>\n",
       "      <td>0.370722</td>\n",
       "      <td>0.681304</td>\n",
       "      <td>0.277679</td>\n",
       "      <td>0.317525</td>\n",
       "      <td>0.350127</td>\n",
       "      <td>0.643095</td>\n",
       "      <td>0.393378</td>\n",
       "      <td>0.370495</td>\n",
       "      <td>0.482796</td>\n",
       "      <td>0.715806</td>\n",
       "      <td>0.904118</td>\n",
       "      <td>0.629461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-04-30</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>2013-10-31</td>\n",
       "      <td>GB</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>74241</td>\n",
       "      <td>31563</td>\n",
       "      <td>0.496968</td>\n",
       "      <td>0.485714</td>\n",
       "      <td>0.732725</td>\n",
       "      <td>0.0181559</td>\n",
       "      <td>0.0350034</td>\n",
       "      <td>0.432647</td>\n",
       "      <td>0.730317</td>\n",
       "      <td>0.0323959</td>\n",
       "      <td>0.0602782</td>\n",
       "      <td>0.427757</td>\n",
       "      <td>0.725787</td>\n",
       "      <td>0.0800997</td>\n",
       "      <td>0.134933</td>\n",
       "      <td>0.414132</td>\n",
       "      <td>0.715838</td>\n",
       "      <td>0.155097</td>\n",
       "      <td>0.225676</td>\n",
       "      <td>0.405101</td>\n",
       "      <td>0.695054</td>\n",
       "      <td>0.303429</td>\n",
       "      <td>0.346971</td>\n",
       "      <td>0.383397</td>\n",
       "      <td>0.663055</td>\n",
       "      <td>0.430758</td>\n",
       "      <td>0.4057</td>\n",
       "      <td>0.355237</td>\n",
       "      <td>0.588252</td>\n",
       "      <td>0.665243</td>\n",
       "      <td>0.463153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-04-30</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>2013-10-31</td>\n",
       "      <td>GB</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>74241</td>\n",
       "      <td>31563</td>\n",
       "      <td>0.497954</td>\n",
       "      <td>0.447619</td>\n",
       "      <td>0.731965</td>\n",
       "      <td>0.0167319</td>\n",
       "      <td>0.0322581</td>\n",
       "      <td>0.458003</td>\n",
       "      <td>0.731331</td>\n",
       "      <td>0.0342945</td>\n",
       "      <td>0.063811</td>\n",
       "      <td>0.565906</td>\n",
       "      <td>0.7396</td>\n",
       "      <td>0.105969</td>\n",
       "      <td>0.178511</td>\n",
       "      <td>0.448669</td>\n",
       "      <td>0.722745</td>\n",
       "      <td>0.168031</td>\n",
       "      <td>0.244496</td>\n",
       "      <td>0.404943</td>\n",
       "      <td>0.694991</td>\n",
       "      <td>0.303311</td>\n",
       "      <td>0.346835</td>\n",
       "      <td>0.38646</td>\n",
       "      <td>0.664892</td>\n",
       "      <td>0.4342</td>\n",
       "      <td>0.408941</td>\n",
       "      <td>0.357265</td>\n",
       "      <td>0.59028</td>\n",
       "      <td>0.66904</td>\n",
       "      <td>0.465796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-04-30</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>2013-10-31</td>\n",
       "      <td>GB</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>74241</td>\n",
       "      <td>31563</td>\n",
       "      <td>0.496942</td>\n",
       "      <td>0.365079</td>\n",
       "      <td>0.730317</td>\n",
       "      <td>0.0136466</td>\n",
       "      <td>0.0263098</td>\n",
       "      <td>0.381933</td>\n",
       "      <td>0.728289</td>\n",
       "      <td>0.0285986</td>\n",
       "      <td>0.0532126</td>\n",
       "      <td>0.3891</td>\n",
       "      <td>0.721921</td>\n",
       "      <td>0.072861</td>\n",
       "      <td>0.122739</td>\n",
       "      <td>0.404626</td>\n",
       "      <td>0.713937</td>\n",
       "      <td>0.151537</td>\n",
       "      <td>0.220496</td>\n",
       "      <td>0.398923</td>\n",
       "      <td>0.692583</td>\n",
       "      <td>0.298801</td>\n",
       "      <td>0.341679</td>\n",
       "      <td>0.386248</td>\n",
       "      <td>0.664766</td>\n",
       "      <td>0.433962</td>\n",
       "      <td>0.408718</td>\n",
       "      <td>0.355174</td>\n",
       "      <td>0.588189</td>\n",
       "      <td>0.665124</td>\n",
       "      <td>0.46307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-04-30</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>2013-10-31</td>\n",
       "      <td>GB</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>74241</td>\n",
       "      <td>31563</td>\n",
       "      <td>0.499016</td>\n",
       "      <td>0.415873</td>\n",
       "      <td>0.731331</td>\n",
       "      <td>0.0155453</td>\n",
       "      <td>0.0299703</td>\n",
       "      <td>0.421553</td>\n",
       "      <td>0.729874</td>\n",
       "      <td>0.0315652</td>\n",
       "      <td>0.0587326</td>\n",
       "      <td>0.451838</td>\n",
       "      <td>0.728194</td>\n",
       "      <td>0.084609</td>\n",
       "      <td>0.142529</td>\n",
       "      <td>0.442649</td>\n",
       "      <td>0.721541</td>\n",
       "      <td>0.165777</td>\n",
       "      <td>0.241216</td>\n",
       "      <td>0.415241</td>\n",
       "      <td>0.69911</td>\n",
       "      <td>0.311024</td>\n",
       "      <td>0.355655</td>\n",
       "      <td>0.39512</td>\n",
       "      <td>0.670088</td>\n",
       "      <td>0.44393</td>\n",
       "      <td>0.418106</td>\n",
       "      <td>0.361067</td>\n",
       "      <td>0.594082</td>\n",
       "      <td>0.67616</td>\n",
       "      <td>0.470753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-04-30</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>2013-10-31</td>\n",
       "      <td>BG</td>\n",
       "      <td>(LogisticRegression(C=100000.0, class_weight=N...</td>\n",
       "      <td>74241</td>\n",
       "      <td>31563</td>\n",
       "      <td>0.494898</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.731014</td>\n",
       "      <td>0.0149519</td>\n",
       "      <td>0.0288264</td>\n",
       "      <td>0.40412</td>\n",
       "      <td>0.729177</td>\n",
       "      <td>0.0302599</td>\n",
       "      <td>0.0563038</td>\n",
       "      <td>0.405577</td>\n",
       "      <td>0.723569</td>\n",
       "      <td>0.0759464</td>\n",
       "      <td>0.127936</td>\n",
       "      <td>0.396388</td>\n",
       "      <td>0.71229</td>\n",
       "      <td>0.148451</td>\n",
       "      <td>0.216006</td>\n",
       "      <td>0.376109</td>\n",
       "      <td>0.683458</td>\n",
       "      <td>0.281714</td>\n",
       "      <td>0.322139</td>\n",
       "      <td>0.356253</td>\n",
       "      <td>0.64677</td>\n",
       "      <td>0.400261</td>\n",
       "      <td>0.376977</td>\n",
       "      <td>0.330461</td>\n",
       "      <td>0.563476</td>\n",
       "      <td>0.618844</td>\n",
       "      <td>0.430849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-04-30</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>2013-10-31</td>\n",
       "      <td>baseline</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.266990</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>198 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    train_start  train_end test_start   test_end model_type  \\\n",
       "0    2012-01-01 2012-04-30 2012-07-01 2012-10-31         RF   \n",
       "1    2012-01-01 2012-04-30 2012-07-01 2012-10-31         RF   \n",
       "2    2012-01-01 2012-04-30 2012-07-01 2012-10-31         RF   \n",
       "3    2012-01-01 2012-04-30 2012-07-01 2012-10-31         RF   \n",
       "4    2012-01-01 2012-04-30 2012-07-01 2012-10-31         RF   \n",
       "5    2012-01-01 2012-04-30 2012-07-01 2012-10-31         RF   \n",
       "6    2012-01-01 2012-04-30 2012-07-01 2012-10-31         RF   \n",
       "7    2012-01-01 2012-04-30 2012-07-01 2012-10-31         RF   \n",
       "8    2012-01-01 2012-04-30 2012-07-01 2012-10-31         RF   \n",
       "9    2012-01-01 2012-04-30 2012-07-01 2012-10-31         RF   \n",
       "10   2012-01-01 2012-04-30 2012-07-01 2012-10-31         RF   \n",
       "11   2012-01-01 2012-04-30 2012-07-01 2012-10-31         RF   \n",
       "12   2012-01-01 2012-04-30 2012-07-01 2012-10-31         RF   \n",
       "13   2012-01-01 2012-04-30 2012-07-01 2012-10-31         RF   \n",
       "14   2012-01-01 2012-04-30 2012-07-01 2012-10-31         RF   \n",
       "15   2012-01-01 2012-04-30 2012-07-01 2012-10-31         RF   \n",
       "16   2012-01-01 2012-04-30 2012-07-01 2012-10-31         RF   \n",
       "17   2012-01-01 2012-04-30 2012-07-01 2012-10-31         RF   \n",
       "18   2012-01-01 2012-04-30 2012-07-01 2012-10-31         RF   \n",
       "19   2012-01-01 2012-04-30 2012-07-01 2012-10-31         RF   \n",
       "20   2012-01-01 2012-04-30 2012-07-01 2012-10-31         RF   \n",
       "21   2012-01-01 2012-04-30 2012-07-01 2012-10-31         RF   \n",
       "22   2012-01-01 2012-04-30 2012-07-01 2012-10-31         RF   \n",
       "23   2012-01-01 2012-04-30 2012-07-01 2012-10-31         RF   \n",
       "24   2012-01-01 2012-04-30 2012-07-01 2012-10-31         AB   \n",
       "25   2012-01-01 2012-04-30 2012-07-01 2012-10-31         LR   \n",
       "26   2012-01-01 2012-04-30 2012-07-01 2012-10-31         LR   \n",
       "27   2012-01-01 2012-04-30 2012-07-01 2012-10-31         LR   \n",
       "28   2012-01-01 2012-04-30 2012-07-01 2012-10-31         LR   \n",
       "29   2012-01-01 2012-04-30 2012-07-01 2012-10-31         LR   \n",
       "..          ...        ...        ...        ...        ...   \n",
       "168  2012-01-01 2013-04-30 2013-07-01 2013-10-31         DT   \n",
       "169  2012-01-01 2013-04-30 2013-07-01 2013-10-31         DT   \n",
       "170  2012-01-01 2013-04-30 2013-07-01 2013-10-31         DT   \n",
       "171  2012-01-01 2013-04-30 2013-07-01 2013-10-31         DT   \n",
       "172  2012-01-01 2013-04-30 2013-07-01 2013-10-31         DT   \n",
       "173  2012-01-01 2013-04-30 2013-07-01 2013-10-31         DT   \n",
       "174  2012-01-01 2013-04-30 2013-07-01 2013-10-31         DT   \n",
       "175  2012-01-01 2013-04-30 2013-07-01 2013-10-31         DT   \n",
       "176  2012-01-01 2013-04-30 2013-07-01 2013-10-31         DT   \n",
       "177  2012-01-01 2013-04-30 2013-07-01 2013-10-31         DT   \n",
       "178  2012-01-01 2013-04-30 2013-07-01 2013-10-31         DT   \n",
       "179  2012-01-01 2013-04-30 2013-07-01 2013-10-31         DT   \n",
       "180  2012-01-01 2013-04-30 2013-07-01 2013-10-31         DT   \n",
       "181  2012-01-01 2013-04-30 2013-07-01 2013-10-31         DT   \n",
       "182  2012-01-01 2013-04-30 2013-07-01 2013-10-31         DT   \n",
       "183  2012-01-01 2013-04-30 2013-07-01 2013-10-31         DT   \n",
       "184  2012-01-01 2013-04-30 2013-07-01 2013-10-31         DT   \n",
       "185  2012-01-01 2013-04-30 2013-07-01 2013-10-31         DT   \n",
       "186  2012-01-01 2013-04-30 2013-07-01 2013-10-31         DT   \n",
       "187  2012-01-01 2013-04-30 2013-07-01 2013-10-31         DT   \n",
       "188  2012-01-01 2013-04-30 2013-07-01 2013-10-31         DT   \n",
       "189  2012-01-01 2013-04-30 2013-07-01 2013-10-31         DT   \n",
       "190  2012-01-01 2013-04-30 2013-07-01 2013-10-31         DT   \n",
       "191  2012-01-01 2013-04-30 2013-07-01 2013-10-31         DT   \n",
       "192  2012-01-01 2013-04-30 2013-07-01 2013-10-31         GB   \n",
       "193  2012-01-01 2013-04-30 2013-07-01 2013-10-31         GB   \n",
       "194  2012-01-01 2013-04-30 2013-07-01 2013-10-31         GB   \n",
       "195  2012-01-01 2013-04-30 2013-07-01 2013-10-31         GB   \n",
       "196  2012-01-01 2013-04-30 2013-07-01 2013-10-31         BG   \n",
       "197  2012-01-01 2013-04-30 2013-07-01 2013-10-31   baseline   \n",
       "\n",
       "                                            classifier train_size test_size  \\\n",
       "0    (DecisionTreeClassifier(class_weight=None, cri...      21180     23294   \n",
       "1    (DecisionTreeClassifier(class_weight=None, cri...      21180     23294   \n",
       "2    (DecisionTreeClassifier(class_weight=None, cri...      21180     23294   \n",
       "3    (DecisionTreeClassifier(class_weight=None, cri...      21180     23294   \n",
       "4    (DecisionTreeClassifier(class_weight=None, cri...      21180     23294   \n",
       "5    (DecisionTreeClassifier(class_weight=None, cri...      21180     23294   \n",
       "6    (DecisionTreeClassifier(class_weight=None, cri...      21180     23294   \n",
       "7    (DecisionTreeClassifier(class_weight=None, cri...      21180     23294   \n",
       "8    (DecisionTreeClassifier(class_weight=None, cri...      21180     23294   \n",
       "9    (DecisionTreeClassifier(class_weight=None, cri...      21180     23294   \n",
       "10   (DecisionTreeClassifier(class_weight=None, cri...      21180     23294   \n",
       "11   (DecisionTreeClassifier(class_weight=None, cri...      21180     23294   \n",
       "12   (DecisionTreeClassifier(class_weight=None, cri...      21180     23294   \n",
       "13   (DecisionTreeClassifier(class_weight=None, cri...      21180     23294   \n",
       "14   (DecisionTreeClassifier(class_weight=None, cri...      21180     23294   \n",
       "15   (DecisionTreeClassifier(class_weight=None, cri...      21180     23294   \n",
       "16   (DecisionTreeClassifier(class_weight=None, cri...      21180     23294   \n",
       "17   (DecisionTreeClassifier(class_weight=None, cri...      21180     23294   \n",
       "18   (DecisionTreeClassifier(class_weight=None, cri...      21180     23294   \n",
       "19   (DecisionTreeClassifier(class_weight=None, cri...      21180     23294   \n",
       "20   (DecisionTreeClassifier(class_weight=None, cri...      21180     23294   \n",
       "21   (DecisionTreeClassifier(class_weight=None, cri...      21180     23294   \n",
       "22   (DecisionTreeClassifier(class_weight=None, cri...      21180     23294   \n",
       "23   (DecisionTreeClassifier(class_weight=None, cri...      21180     23294   \n",
       "24   (DecisionTreeClassifier(class_weight=None, cri...      21180     23294   \n",
       "25   LogisticRegression(C=10, class_weight=None, du...      21180     23294   \n",
       "26   LogisticRegression(C=10, class_weight=None, du...      21180     23294   \n",
       "27   LogisticRegression(C=10, class_weight=None, du...      21180     23294   \n",
       "28   LogisticRegression(C=10, class_weight=None, du...      21180     23294   \n",
       "29   LogisticRegression(C=10, class_weight=None, du...      21180     23294   \n",
       "..                                                 ...        ...       ...   \n",
       "168  DecisionTreeClassifier(class_weight=None, crit...      74241     31563   \n",
       "169  DecisionTreeClassifier(class_weight=None, crit...      74241     31563   \n",
       "170  DecisionTreeClassifier(class_weight=None, crit...      74241     31563   \n",
       "171  DecisionTreeClassifier(class_weight=None, crit...      74241     31563   \n",
       "172  DecisionTreeClassifier(class_weight=None, crit...      74241     31563   \n",
       "173  DecisionTreeClassifier(class_weight=None, crit...      74241     31563   \n",
       "174  DecisionTreeClassifier(class_weight=None, crit...      74241     31563   \n",
       "175  DecisionTreeClassifier(class_weight=None, crit...      74241     31563   \n",
       "176  DecisionTreeClassifier(class_weight=None, crit...      74241     31563   \n",
       "177  DecisionTreeClassifier(class_weight=None, crit...      74241     31563   \n",
       "178  DecisionTreeClassifier(class_weight=None, crit...      74241     31563   \n",
       "179  DecisionTreeClassifier(class_weight=None, crit...      74241     31563   \n",
       "180  DecisionTreeClassifier(class_weight=None, crit...      74241     31563   \n",
       "181  DecisionTreeClassifier(class_weight=None, crit...      74241     31563   \n",
       "182  DecisionTreeClassifier(class_weight=None, crit...      74241     31563   \n",
       "183  DecisionTreeClassifier(class_weight=None, crit...      74241     31563   \n",
       "184  DecisionTreeClassifier(class_weight=None, crit...      74241     31563   \n",
       "185  DecisionTreeClassifier(class_weight=None, crit...      74241     31563   \n",
       "186  DecisionTreeClassifier(class_weight=None, crit...      74241     31563   \n",
       "187  DecisionTreeClassifier(class_weight=None, crit...      74241     31563   \n",
       "188  DecisionTreeClassifier(class_weight=None, crit...      74241     31563   \n",
       "189  DecisionTreeClassifier(class_weight=None, crit...      74241     31563   \n",
       "190  DecisionTreeClassifier(class_weight=None, crit...      74241     31563   \n",
       "191  DecisionTreeClassifier(class_weight=None, crit...      74241     31563   \n",
       "192  ([DecisionTreeRegressor(criterion='friedman_ms...      74241     31563   \n",
       "193  ([DecisionTreeRegressor(criterion='friedman_ms...      74241     31563   \n",
       "194  ([DecisionTreeRegressor(criterion='friedman_ms...      74241     31563   \n",
       "195  ([DecisionTreeRegressor(criterion='friedman_ms...      74241     31563   \n",
       "196  (LogisticRegression(C=100000.0, class_weight=N...      74241     31563   \n",
       "197                                                                           \n",
       "\n",
       "      auc-roc    p_at_1    a_at_1     r_at_1    f1_at_1    p_at_2    a_at_2  \\\n",
       "0    0.497928  0.387931  0.748862  0.0155226  0.0298507  0.339785  0.744698   \n",
       "1    0.499727  0.392241  0.748948  0.0156951  0.0301824  0.380645   0.74633   \n",
       "2    0.495292  0.344828  0.748004  0.0137979   0.026534  0.348387  0.745042   \n",
       "3    0.509430  0.465517  0.750408  0.0186271  0.0358209  0.421505  0.747961   \n",
       "4    0.508002   0.25431  0.746201  0.0101759  0.0195688  0.337634  0.744612   \n",
       "5    0.499413  0.349138   0.74809  0.0139703  0.0268657  0.365591  0.745729   \n",
       "6    0.495908  0.262931  0.746372  0.0105209  0.0202322  0.277419  0.742208   \n",
       "7    0.500862  0.318966  0.747489   0.012763  0.0245439  0.309677  0.743496   \n",
       "8    0.503076   0.37069  0.748519  0.0148327   0.028524  0.397849  0.747016   \n",
       "9    0.502870  0.340517  0.747918  0.0136254  0.0262023  0.372043  0.745986   \n",
       "10   0.492633   0.37069  0.748519  0.0148327   0.028524   0.35914  0.745471   \n",
       "11   0.502461  0.327586   0.74766   0.013108  0.0252073   0.36129  0.745557   \n",
       "12   0.497806  0.366379  0.748433  0.0146602  0.0281924  0.369892    0.7459   \n",
       "13   0.500940  0.422414  0.749549  0.0169024  0.0325041  0.382796  0.746415   \n",
       "14   0.501001  0.306034  0.747231  0.0122456  0.0235489  0.352688  0.745213   \n",
       "15   0.497550  0.344828  0.748004  0.0137979   0.026534  0.331183  0.744355   \n",
       "16   0.505538  0.383621  0.748777  0.0153501  0.0295191  0.356989  0.745385   \n",
       "17   0.503301  0.336207  0.747832  0.0134529  0.0258706  0.378495  0.746244   \n",
       "18   0.509482   0.37931  0.748691  0.0151776  0.0291874  0.372043  0.745986   \n",
       "19   0.500902  0.362069  0.748347  0.0144878  0.0278607  0.384946  0.746501   \n",
       "20   0.506724  0.366379  0.748433  0.0146602  0.0281924  0.329032  0.744269   \n",
       "21   0.497796  0.366379  0.748433  0.0146602  0.0281924  0.372043  0.745986   \n",
       "22   0.491997   0.37931  0.748691  0.0151776  0.0291874  0.402151  0.747188   \n",
       "23   0.495912     0.375  0.748605  0.0150052  0.0288557  0.387097  0.746587   \n",
       "24   0.501167         1  0.761054  0.0400138  0.0769486         1  0.771057   \n",
       "25   0.500288  0.443966  0.749979  0.0177647  0.0341625  0.365591  0.745729   \n",
       "26   0.501577  0.452586   0.75015  0.0181097  0.0348259  0.408602  0.747446   \n",
       "27   0.502403  0.474138   0.75058  0.0189721  0.0364842  0.464516  0.749678   \n",
       "28   0.502290  0.491379  0.750923   0.019662  0.0378109  0.458065   0.74942   \n",
       "29   0.493619       0.5  0.751095  0.0200069  0.0384743  0.466667  0.749764   \n",
       "..        ...       ...       ...        ...        ...       ...       ...   \n",
       "168  0.497006         1   0.74299  0.0373799  0.0720659         1  0.753002   \n",
       "169  0.497006         1   0.74299  0.0373799  0.0720659         1  0.753002   \n",
       "170  0.497006         1   0.74299  0.0373799  0.0720659         1  0.753002   \n",
       "171  0.496615  0.384127  0.730697  0.0143586  0.0276825  0.440571  0.730634   \n",
       "172  0.500203  0.393651  0.730887  0.0147146  0.0283688  0.438986  0.730571   \n",
       "173  0.498367  0.384127  0.730697  0.0143586  0.0276825  0.437401  0.730507   \n",
       "174  0.497705         1   0.74299  0.0373799  0.0720659         1  0.753002   \n",
       "175  0.501450         1   0.74299  0.0373799  0.0720659         1  0.753002   \n",
       "176  0.495548         1   0.74299  0.0373799  0.0720659  0.857369  0.747299   \n",
       "177  0.500567         1   0.74299  0.0373799  0.0720659         1  0.753002   \n",
       "178  0.500874         1   0.74299  0.0373799  0.0720659         1  0.753002   \n",
       "179  0.497346         1   0.74299  0.0373799  0.0720659         1  0.753002   \n",
       "180  0.499567         1   0.74299  0.0373799  0.0720659         1  0.753002   \n",
       "181  0.499567         1   0.74299  0.0373799  0.0720659         1  0.753002   \n",
       "182  0.499567         1   0.74299  0.0373799  0.0720659         1  0.753002   \n",
       "183  0.499479  0.387302  0.730761  0.0144773  0.0279112  0.353407  0.727149   \n",
       "184  0.496617  0.365079  0.730317  0.0136466  0.0263098  0.354992  0.727212   \n",
       "185  0.496847  0.387302  0.730761  0.0144773  0.0279112  0.353407  0.727149   \n",
       "186  0.502508         1   0.74299  0.0373799  0.0720659  0.767036  0.743687   \n",
       "187  0.500499         1   0.74299  0.0373799  0.0720659  0.743265  0.742737   \n",
       "188  0.500441         1   0.74299  0.0373799  0.0720659  0.564184  0.735576   \n",
       "189  0.500957         1   0.74299  0.0373799  0.0720659         1  0.753002   \n",
       "190  0.498948         1   0.74299  0.0373799  0.0720659         1  0.753002   \n",
       "191  0.494531         1   0.74299  0.0373799  0.0720659         1  0.753002   \n",
       "192  0.496968  0.485714  0.732725  0.0181559  0.0350034  0.432647  0.730317   \n",
       "193  0.497954  0.447619  0.731965  0.0167319  0.0322581  0.458003  0.731331   \n",
       "194  0.496942  0.365079  0.730317  0.0136466  0.0263098  0.381933  0.728289   \n",
       "195  0.499016  0.415873  0.731331  0.0155453  0.0299703  0.421553  0.729874   \n",
       "196  0.494898       0.4  0.731014  0.0149519  0.0288264   0.40412  0.729177   \n",
       "197  0.266990                                                                 \n",
       "\n",
       "        r_at_2    f1_at_2    p_at_5    a_at_5     r_at_5    f1_at_5   p_at_10  \\\n",
       "0    0.0272508  0.0504551  0.402921  0.741393    0.08089   0.134731  0.354229   \n",
       "1    0.0305278  0.0565224  0.364261  0.737529  0.0731287   0.121804  0.373551   \n",
       "2    0.0279407  0.0517324  0.398625  0.740963  0.0800276   0.133295  0.372692   \n",
       "3    0.0338048  0.0625898  0.411512  0.742251  0.0826147   0.137604  0.383856   \n",
       "4    0.0270783  0.0501357  0.341924  0.735297  0.0686444   0.114335  0.349077   \n",
       "5    0.0293205  0.0542871  0.347938  0.735898  0.0698517   0.116346  0.343924   \n",
       "6    0.0222491  0.0411943  0.380584   0.73916  0.0764057   0.127262  0.298411   \n",
       "7    0.0248362  0.0459844  0.300687  0.731175  0.0603656   0.100546  0.300129   \n",
       "8    0.0319076  0.0590771  0.387457  0.739847  0.0777854    0.12956   0.36067   \n",
       "9    0.0298379  0.0552451  0.385739  0.739675  0.0774405   0.128986  0.392872   \n",
       "10    0.028803  0.0533291  0.359107  0.737014  0.0720938    0.12008  0.359382   \n",
       "11   0.0289755  0.0536484  0.384021  0.739504  0.0770956   0.128411  0.383426   \n",
       "12   0.0296654  0.0549258  0.292955  0.730403  0.0588134  0.0979604   0.32632   \n",
       "13   0.0307002  0.0568418  0.344502  0.735554  0.0691618   0.115197  0.335337   \n",
       "14   0.0282856  0.0523711  0.294674  0.730574  0.0591583  0.0985349  0.288536   \n",
       "15   0.0265609  0.0491777  0.340206  0.735125  0.0682994    0.11376  0.344783   \n",
       "16   0.0286306  0.0530097  0.380584   0.73916  0.0764057   0.127262  0.351653   \n",
       "17   0.0303553  0.0562031  0.387457  0.739847  0.0777854    0.12956  0.393302   \n",
       "18   0.0298379  0.0552451  0.384021  0.739504  0.0770956   0.128411  0.362817   \n",
       "19   0.0308727  0.0571611   0.39433  0.740534  0.0791652   0.131859  0.392872   \n",
       "20   0.0263884  0.0488584  0.324742  0.733579  0.0651949   0.108589  0.314298   \n",
       "21   0.0298379  0.0552451  0.351375  0.736241  0.0705416   0.117495  0.351653   \n",
       "22   0.0322525  0.0597158  0.349656  0.736069  0.0701966    0.11692  0.337913   \n",
       "23   0.0310452  0.0574804  0.362543  0.737357  0.0727837    0.12123  0.364964   \n",
       "24   0.0802001   0.148491         1  0.801065   0.200759   0.334387         1   \n",
       "25   0.0293205  0.0542871  0.377148  0.738817  0.0757158   0.126113  0.371833   \n",
       "26   0.0327699  0.0606738  0.416667  0.742766  0.0836495   0.139328  0.408759   \n",
       "27   0.0372542  0.0689765  0.449313  0.746029  0.0902035   0.150244  0.430657   \n",
       "28   0.0367368  0.0680185  0.439003  0.744999  0.0881338   0.146797  0.410906   \n",
       "29   0.0374267  0.0692959  0.420103   0.74311  0.0843394   0.140477  0.397166   \n",
       "..         ...        ...       ...       ...        ...        ...       ...   \n",
       "168  0.0748784   0.139324         1  0.783005   0.187255   0.315442         1   \n",
       "169  0.0748784   0.139324         1  0.783005   0.187255   0.315442         1   \n",
       "170  0.0748784   0.139324         1  0.783005   0.187255   0.315442         1   \n",
       "171  0.0329892  0.0613822  0.581749  0.741184   0.108936   0.183508  0.450887   \n",
       "172  0.0328705  0.0611614  0.591255  0.742135   0.110716   0.186507  0.451521   \n",
       "173  0.0327519  0.0609406  0.590621  0.742071   0.110597   0.186307  0.450887   \n",
       "174  0.0748784   0.139324  0.472117  0.730222  0.0884063   0.148926  0.363118   \n",
       "175  0.0748784   0.139324  0.448669  0.727878  0.0840157   0.141529  0.370089   \n",
       "176  0.0641984   0.119452  0.369455  0.719957  0.0691824   0.116542   0.37199   \n",
       "177  0.0748784   0.139324         1  0.783005   0.187255   0.315442  0.950253   \n",
       "178  0.0748784   0.139324         1  0.783005   0.187255   0.315442  0.834918   \n",
       "179  0.0748784   0.139324         1  0.783005   0.187255   0.315442  0.624842   \n",
       "180  0.0748784   0.139324         1  0.783005   0.187255   0.315442         1   \n",
       "181  0.0748784   0.139324         1  0.783005   0.187255   0.315442         1   \n",
       "182  0.0748784   0.139324         1  0.783005   0.187255   0.315442         1   \n",
       "183  0.0264626  0.0492382   0.54436  0.737446   0.101934   0.171714  0.492712   \n",
       "184  0.0265812   0.049459  0.533587  0.736369  0.0999169   0.168316  0.493029   \n",
       "185  0.0264626  0.0492382  0.541825  0.737192    0.10146   0.170915  0.492395   \n",
       "186  0.0574344   0.106867  0.312421  0.714254  0.0585024  0.0985507  0.382446   \n",
       "187  0.0556544   0.103555  0.329531  0.715965  0.0617064   0.103948  0.375475   \n",
       "188  0.0422452  0.0786045  0.334601  0.716472  0.0626557   0.105547  0.374525   \n",
       "189  0.0748784   0.139324         1  0.783005   0.187255   0.315442  0.970215   \n",
       "190  0.0748784   0.139324         1  0.783005   0.187255   0.315442  0.887516   \n",
       "191  0.0748784   0.139324         1  0.783005   0.187255   0.315442   0.63815   \n",
       "192  0.0323959  0.0602782  0.427757  0.725787  0.0800997   0.134933  0.414132   \n",
       "193  0.0342945   0.063811  0.565906    0.7396   0.105969   0.178511  0.448669   \n",
       "194  0.0285986  0.0532126    0.3891  0.721921   0.072861   0.122739  0.404626   \n",
       "195  0.0315652  0.0587326  0.451838  0.728194   0.084609   0.142529  0.442649   \n",
       "196  0.0302599  0.0563038  0.405577  0.723569  0.0759464   0.127936  0.396388   \n",
       "197                                                                             \n",
       "\n",
       "      a_at_10   r_at_10  f1_at_10   p_at_20   a_at_20   r_at_20  f1_at_20  \\\n",
       "0    0.721946   0.14229  0.203027  0.331473  0.683695  0.266299  0.295333   \n",
       "1    0.725809  0.150052  0.214101  0.364534  0.696918   0.29286   0.32479   \n",
       "2    0.725638  0.149707  0.213609  0.395019   0.70911  0.317351  0.351951   \n",
       "3     0.72787  0.154191  0.220007   0.36754   0.69812  0.295274  0.327467   \n",
       "4    0.720915  0.140221  0.200074  0.336625  0.685756  0.270438  0.299923   \n",
       "5    0.719885  0.138151  0.197121  0.337913  0.686271  0.271473  0.301071   \n",
       "6    0.710784  0.119869  0.171035  0.361314   0.69563  0.290273   0.32192   \n",
       "7    0.711127  0.120559  0.172019  0.314513  0.676913  0.252673  0.280222   \n",
       "8    0.723233  0.144878  0.206718  0.339201  0.686786  0.272508  0.302219   \n",
       "9    0.729673  0.157813  0.225175  0.366681  0.697776  0.294584  0.326702   \n",
       "10   0.722976   0.14436   0.20598  0.352512   0.69211  0.283201  0.314078   \n",
       "11   0.727784  0.154019  0.219761  0.368184  0.698377  0.295792  0.328041   \n",
       "12   0.716365   0.13108  0.187031  0.347359  0.690049  0.279062  0.309487   \n",
       "13   0.718168  0.134702  0.192199  0.335337  0.685241  0.269403  0.298776   \n",
       "14   0.708809  0.115902  0.165375  0.290468  0.667296  0.233356  0.258799   \n",
       "15   0.720057  0.138496  0.197613  0.341348  0.687645  0.274232  0.304132   \n",
       "16    0.72143  0.141256   0.20155  0.342207  0.687988  0.274922  0.304897   \n",
       "17   0.729759  0.157986  0.225421  0.367969  0.698291  0.295619   0.32785   \n",
       "18   0.723663   0.14574  0.207949  0.352082  0.691938  0.282856  0.313695   \n",
       "19   0.729673  0.157813  0.225175   0.37398  0.700695  0.300448  0.333206   \n",
       "20   0.713961   0.12625   0.18014  0.309575  0.674938  0.248706  0.275822   \n",
       "21    0.72143  0.141256   0.20155  0.334908  0.685069  0.269058  0.298393   \n",
       "22   0.718683  0.135736  0.193675  0.330399  0.683266  0.265436  0.294376   \n",
       "23   0.724092  0.146602  0.209179  0.353585  0.692539  0.284063  0.315034   \n",
       "24   0.851078   0.40169  0.573151  0.935809  0.925389  0.751811   0.83378   \n",
       "25   0.725466  0.149362  0.213117  0.340704  0.687387  0.273715  0.303558   \n",
       "26    0.73285  0.164195  0.234281  0.369257  0.698807  0.296654  0.328998   \n",
       "27   0.737228  0.172991  0.246832  0.386861  0.705847  0.310797  0.344682   \n",
       "28   0.733279  0.165057  0.235511  0.374839  0.701039  0.301138  0.333971   \n",
       "29   0.730531  0.159538  0.227636  0.374624  0.700953  0.300966   0.33378   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "168  0.833001  0.374511  0.544937         1  0.932991  0.749021  0.856503   \n",
       "169  0.833001  0.374511  0.544937         1  0.932991  0.749021  0.856503   \n",
       "170  0.833001  0.374511  0.544937         1  0.932991  0.749021  0.856503   \n",
       "171  0.723189  0.168862  0.245705  0.414766   0.69892  0.310668  0.355248   \n",
       "172  0.723315  0.169099   0.24605  0.415082  0.699046  0.310905  0.355519   \n",
       "173  0.723189  0.168862  0.245705  0.414766   0.69892  0.310668  0.355248   \n",
       "174  0.705636  0.135991  0.197876  0.412389  0.697969  0.308888  0.353213   \n",
       "175   0.70703  0.138602  0.201675  0.411914  0.697779  0.308532  0.352805   \n",
       "176  0.707411  0.139314  0.202711  0.402567   0.69404  0.301531    0.3448   \n",
       "177  0.823052   0.35588  0.517828  0.475127  0.723062   0.35588  0.406948   \n",
       "178  0.799987  0.312685  0.454977  0.417459  0.699997  0.312685  0.357555   \n",
       "179  0.757976   0.23401  0.340499  0.378961  0.684599   0.28385  0.324581   \n",
       "180  0.833001  0.374511  0.544937         1  0.932991  0.749021  0.856503   \n",
       "181  0.833001  0.374511  0.544937         1  0.932991  0.749021  0.856503   \n",
       "182  0.833001  0.374511  0.544937         1  0.932991  0.749021  0.856503   \n",
       "183  0.731553  0.184526  0.268497  0.445976  0.711403  0.334045   0.38198   \n",
       "184  0.731616  0.184645   0.26867  0.443599  0.710452  0.332265  0.379944   \n",
       "185  0.731489  0.184407  0.268324  0.440589  0.709248  0.330011  0.377366   \n",
       "186  0.709502   0.14323  0.208409  0.403042  0.694231  0.301887  0.345207   \n",
       "187  0.708108  0.140619   0.20461  0.394487  0.690809  0.295479  0.337879   \n",
       "188  0.707917  0.140263  0.204092  0.400982  0.693407  0.300344  0.343443   \n",
       "189  0.827044  0.363356  0.528706  0.485108  0.727054  0.363356  0.415496   \n",
       "190  0.810506  0.332384   0.48364  0.443758  0.710515  0.332384   0.38008   \n",
       "191  0.760637  0.238994  0.347751  0.370722  0.681304  0.277679  0.317525   \n",
       "192  0.715838  0.155097  0.225676  0.405101  0.695054  0.303429  0.346971   \n",
       "193  0.722745  0.168031  0.244496  0.404943  0.694991  0.303311  0.346835   \n",
       "194  0.713937  0.151537  0.220496  0.398923  0.692583  0.298801  0.341679   \n",
       "195  0.721541  0.165777  0.241216  0.415241   0.69911  0.311024  0.355655   \n",
       "196   0.71229  0.148451  0.216006  0.376109  0.683458  0.281714  0.322139   \n",
       "197                                                                         \n",
       "\n",
       "      p_at_30   a_at_30   r_at_30  f1_at_30   p_at_50   a_at_50   r_at_50  \\\n",
       "0    0.361906  0.668241  0.436185  0.395589  0.339572  0.590667  0.682132   \n",
       "1    0.349027  0.660513  0.420662  0.381511  0.325234  0.576329  0.653329   \n",
       "2    0.379365  0.678716  0.457227  0.414672  0.326093  0.577187  0.655053   \n",
       "3    0.346737   0.65914  0.417903  0.379008  0.319567  0.570662  0.641945   \n",
       "4    0.439325   0.71469  0.529493  0.480213  0.288315  0.539409  0.579165   \n",
       "5    0.331139  0.649781  0.399103  0.361958  0.309865   0.56096  0.622456   \n",
       "6    0.324699  0.645917  0.391342  0.354919  0.364214  0.615309  0.731632   \n",
       "7    0.315684  0.640508  0.380476  0.345065  0.294582  0.545677  0.591756   \n",
       "8    0.326703  0.647119  0.393756  0.357109  0.310981  0.562076  0.624698   \n",
       "9    0.350458  0.661372  0.422387  0.383075  0.329441  0.580536   0.66178   \n",
       "10   0.340298  0.655276  0.410141  0.371969  0.314502  0.565596   0.63177   \n",
       "11   0.353034  0.662917  0.425492  0.385891  0.324805  0.575899  0.652466   \n",
       "12    0.34273  0.656736  0.413073  0.374628  0.316219  0.567313  0.635219   \n",
       "13   0.327275  0.647463  0.394446  0.357735   0.31433  0.565425  0.631425   \n",
       "14   0.294934  0.628059  0.355467  0.322384  0.287198  0.538293  0.576923   \n",
       "15   0.329565  0.648837  0.397206  0.360238  0.306173  0.557268   0.61504   \n",
       "16   0.327991  0.647892  0.395309  0.358517  0.309779  0.560874  0.622284   \n",
       "17   0.350172    0.6612  0.422042  0.382762  0.323431  0.574526  0.649707   \n",
       "18   0.338294  0.654074  0.407727  0.369779  0.310466  0.561561  0.623663   \n",
       "19   0.353749  0.663347  0.426354  0.386673  0.326694  0.577788  0.656261   \n",
       "20   0.303377  0.633124  0.365643  0.331613  0.289087  0.540182  0.580717   \n",
       "21    0.32842   0.64815  0.395826  0.358986  0.314845   0.56594  0.632459   \n",
       "22   0.319118  0.642569  0.384615  0.348819  0.301279  0.552374  0.605209   \n",
       "23   0.347167  0.659397   0.41842  0.379478  0.321113  0.572207   0.64505   \n",
       "24   0.623784  0.825363  0.751811   0.68184  0.374259  0.625354  0.751811   \n",
       "25   0.320406  0.643342  0.386168  0.350227  0.278183  0.529278  0.558813   \n",
       "26   0.349027  0.660513  0.420662  0.381511  0.315017  0.566111  0.632804   \n",
       "27   0.356611  0.665064  0.429803  0.389801  0.315532  0.566627  0.633839   \n",
       "28   0.350458  0.661372  0.422387  0.383075  0.315188  0.566283  0.633149   \n",
       "29   0.345879  0.658625  0.416868   0.37807  0.309007  0.560101  0.620731   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "168  0.745353  0.880208  0.837427  0.788712  0.447183  0.680195  0.837427   \n",
       "169  0.745353  0.880208  0.837427  0.788712  0.447183  0.680195  0.837427   \n",
       "170  0.745353  0.880208  0.837427  0.788712  0.447183  0.680195  0.837427   \n",
       "171  0.399768  0.672876  0.449152  0.423023  0.356188  0.589203  0.667023   \n",
       "172   0.40019   0.67313  0.449626   0.42347  0.356505  0.589519  0.667616   \n",
       "173  0.399662  0.672813  0.449033  0.422911  0.356505  0.589519  0.667616   \n",
       "174  0.389945  0.666983  0.438116  0.412629  0.352196  0.585211  0.659547   \n",
       "175  0.391001  0.667617  0.439302  0.413747  0.358406   0.59142  0.671176   \n",
       "176  0.393642  0.669201  0.442269  0.416541  0.363095  0.596109  0.679957   \n",
       "177  0.343684  0.639229   0.38614  0.363677  0.533997  0.767006         1   \n",
       "178  0.361005  0.649621  0.405601  0.382006  0.533997  0.767006         1   \n",
       "179  0.364913  0.651966  0.409992  0.386141  0.468982  0.701993  0.878248   \n",
       "180  0.770384  0.895225  0.865551    0.8152  0.462201  0.695213  0.865551   \n",
       "181  0.770384  0.895225  0.865551    0.8152  0.462201  0.695213  0.865551   \n",
       "182  0.770384  0.895225  0.865551    0.8152  0.462201  0.695213  0.865551   \n",
       "183  0.410646  0.679403  0.461374  0.434535  0.359673  0.592688  0.673549   \n",
       "184  0.409062  0.678453  0.459594  0.432858  0.358723  0.591737  0.671769   \n",
       "185   0.40695  0.677185  0.457221  0.430623  0.357455   0.59047  0.669396   \n",
       "186   0.38646  0.664892    0.4342  0.408941  0.360624  0.593638  0.675329   \n",
       "187  0.384347  0.663625  0.431826  0.406706  0.358723  0.591737  0.671769   \n",
       "188  0.384242  0.663562  0.431708  0.406594  0.352006   0.58502  0.659191   \n",
       "189  0.368716  0.654247  0.414264  0.390165  0.533997  0.767006         1   \n",
       "190  0.348542  0.642144  0.391598  0.368818  0.533997  0.767006         1   \n",
       "191  0.350127  0.643095  0.393378  0.370495  0.482796  0.715806  0.904118   \n",
       "192  0.383397  0.663055  0.430758    0.4057  0.355237  0.588252  0.665243   \n",
       "193   0.38646  0.664892    0.4342  0.408941  0.357265   0.59028   0.66904   \n",
       "194  0.386248  0.664766  0.433962  0.408718  0.355174  0.588189  0.665124   \n",
       "195   0.39512  0.670088   0.44393  0.418106  0.361067  0.594082   0.67616   \n",
       "196  0.356253   0.64677  0.400261  0.376977  0.330461  0.563476  0.618844   \n",
       "197                                                                         \n",
       "\n",
       "     f1_at_50  \n",
       "0    0.453425  \n",
       "1    0.434279  \n",
       "2    0.435426  \n",
       "3    0.426713  \n",
       "4    0.384981  \n",
       "5    0.413758  \n",
       "6    0.486328  \n",
       "7    0.393351  \n",
       "8    0.415248  \n",
       "9    0.439897  \n",
       "10   0.419948  \n",
       "11   0.433706  \n",
       "12   0.422241  \n",
       "13   0.419719  \n",
       "14   0.383491  \n",
       "15   0.408828  \n",
       "16   0.413643  \n",
       "17   0.431872  \n",
       "18    0.41456  \n",
       "19   0.436228  \n",
       "20   0.386013  \n",
       "21   0.420407  \n",
       "22   0.402293  \n",
       "23   0.428776  \n",
       "24   0.499742  \n",
       "25   0.371453  \n",
       "26   0.420636  \n",
       "27   0.421324  \n",
       "28   0.420866  \n",
       "29   0.412611  \n",
       "..        ...  \n",
       "168   0.58303  \n",
       "169   0.58303  \n",
       "170   0.58303  \n",
       "171  0.464392  \n",
       "172  0.464805  \n",
       "173  0.464805  \n",
       "174  0.459187  \n",
       "175  0.467284  \n",
       "176  0.473397  \n",
       "177  0.696216  \n",
       "178  0.696216  \n",
       "179  0.611451  \n",
       "180  0.602611  \n",
       "181  0.602611  \n",
       "182  0.602611  \n",
       "183  0.468936  \n",
       "184  0.467697  \n",
       "185  0.466044  \n",
       "186  0.470175  \n",
       "187  0.467697  \n",
       "188  0.458939  \n",
       "189  0.696216  \n",
       "190  0.696216  \n",
       "191  0.629461  \n",
       "192  0.463153  \n",
       "193  0.465796  \n",
       "194   0.46307  \n",
       "195  0.470753  \n",
       "196  0.430849  \n",
       "197            \n",
       "\n",
       "[198 rows x 37 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### After producing this grid, I identify the model with the best AUC-ROC score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train_start                                  2012-01-01 00:00:00\n",
       "train_end                                    2012-10-31 00:00:00\n",
       "test_start                                   2013-01-01 00:00:00\n",
       "test_end                                     2013-04-30 00:00:00\n",
       "model_type                                                    LR\n",
       "classifier     LogisticRegression(C=10, class_weight=None, du...\n",
       "train_size                                                 49680\n",
       "test_size                                                  15017\n",
       "auc-roc                                                 0.512807\n",
       "p_at_1                                                      0.52\n",
       "a_at_1                                                  0.702004\n",
       "r_at_1                                                 0.0174068\n",
       "f1_at_1                                                 0.033686\n",
       "p_at_2                                                  0.526667\n",
       "a_at_2                                                   0.70267\n",
       "r_at_2                                                   0.03526\n",
       "f1_at_2                                                 0.066095\n",
       "p_at_5                                                     0.512\n",
       "a_at_5                                                  0.702803\n",
       "r_at_5                                                 0.0856952\n",
       "f1_at_5                                                 0.146817\n",
       "p_at_10                                                 0.487009\n",
       "a_at_10                                                 0.699008\n",
       "r_at_10                                                 0.163133\n",
       "f1_at_10                                                  0.2444\n",
       "p_at_20                                                  0.44622\n",
       "a_at_20                                                 0.680096\n",
       "r_at_20                                                  0.29904\n",
       "f1_at_20                                                0.358097\n",
       "p_at_30                                                 0.423529\n",
       "a_at_30                                                 0.655724\n",
       "r_at_30                                                 0.425798\n",
       "f1_at_30                                                0.424661\n",
       "p_at_50                                                 0.385855\n",
       "a_at_50                                                 0.587468\n",
       "r_at_50                                                 0.646507\n",
       "f1_at_50                                                0.483276\n",
       "Name: 92, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_without_baseline = results_df[results_df['model_type'] != 'baseline']\n",
    "best_model = results_without_baseline.loc[results_without_baseline['auc-roc'].idxmax()]\n",
    "best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here are the parameters for the model with the best AUC/ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.1, 'penalty': 'l1'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params[92]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now, I train this model and produce the precision/recall curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_log, x_test_log, y_train_log, y_test_log = library.temporal_split(donors_df, \"date_posted\" , \"60_days_fullyfunded\", best_model['train_start'], best_model['train_end'], best_model['test_start'], best_model['test_end'], vars_to_drop_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn', n_jobs=-1,\n",
       "          penalty='l2', random_state=None, solver='warn', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_log, x_test_log, features_log = library.pre_process(x_train_log, x_test_log, categorical_list, to_dummy_list, continuous_impute_list, vars_to_drop_all)\n",
    "x_train_log = x_train_log[features_log]\n",
    "x_test_log = x_test_log[features_log]\n",
    "best_logistic = best_model['classifier']\n",
    "best_logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_probs_best = best_logistic.fit(x_train_log, y_train_log).predict_proba(x_test_log)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "library.plot_precision_recall_n(y_test_log, y_pred_probs_best, \"Logistic Regression\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now I compare 5% precision, recall, and auc across models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_compare = results_without_baseline[['model_type', 'auc-roc', 'p_at_5', 'r_at_5']]\n",
    "model_compare[['p_at_5', 'r_at_5']] = model_compare[['p_at_5', 'r_at_5']].apply(pd.to_numeric)\n",
    "model_compare = model_compare.groupby('model_type').mean()\n",
    "model_compare.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a1ff78438>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_compare.plot(x='model_type', y=['auc-roc', 'p_at_5', 'r_at_5'], kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finally, I compare the models over time, across the various evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_type</th>\n",
       "      <th>test_start</th>\n",
       "      <th>auc-roc</th>\n",
       "      <th>p_at_5</th>\n",
       "      <th>r_at_5</th>\n",
       "      <th>p_at_10</th>\n",
       "      <th>r_at_10</th>\n",
       "      <th>p_at_20</th>\n",
       "      <th>r_at_20</th>\n",
       "      <th>p_at_30</th>\n",
       "      <th>r_at_30</th>\n",
       "      <th>p_at_50</th>\n",
       "      <th>r_at_50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AB</td>\n",
       "      <td>2012-07-01</td>\n",
       "      <td>0.501167</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.200759</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.401690</td>\n",
       "      <td>0.935809</td>\n",
       "      <td>0.751811</td>\n",
       "      <td>0.623784</td>\n",
       "      <td>0.751811</td>\n",
       "      <td>0.374259</td>\n",
       "      <td>0.751811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AB</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>0.502712</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.167373</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.334970</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.670163</td>\n",
       "      <td>0.783130</td>\n",
       "      <td>0.787324</td>\n",
       "      <td>0.469899</td>\n",
       "      <td>0.787324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AB</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>0.497006</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.187255</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.374511</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.749021</td>\n",
       "      <td>0.745353</td>\n",
       "      <td>0.837427</td>\n",
       "      <td>0.447183</td>\n",
       "      <td>0.837427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BG</td>\n",
       "      <td>2012-07-01</td>\n",
       "      <td>0.505130</td>\n",
       "      <td>0.373711</td>\n",
       "      <td>0.075026</td>\n",
       "      <td>0.338772</td>\n",
       "      <td>0.136081</td>\n",
       "      <td>0.321383</td>\n",
       "      <td>0.258192</td>\n",
       "      <td>0.317258</td>\n",
       "      <td>0.382373</td>\n",
       "      <td>0.287799</td>\n",
       "      <td>0.578130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BG</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>0.498260</td>\n",
       "      <td>0.434667</td>\n",
       "      <td>0.072752</td>\n",
       "      <td>0.425050</td>\n",
       "      <td>0.142379</td>\n",
       "      <td>0.416250</td>\n",
       "      <td>0.278956</td>\n",
       "      <td>0.398224</td>\n",
       "      <td>0.400357</td>\n",
       "      <td>0.359483</td>\n",
       "      <td>0.602321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BG</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>0.494898</td>\n",
       "      <td>0.405577</td>\n",
       "      <td>0.075946</td>\n",
       "      <td>0.396388</td>\n",
       "      <td>0.148451</td>\n",
       "      <td>0.376109</td>\n",
       "      <td>0.281714</td>\n",
       "      <td>0.356253</td>\n",
       "      <td>0.400261</td>\n",
       "      <td>0.330461</td>\n",
       "      <td>0.618844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DT</td>\n",
       "      <td>2012-07-01</td>\n",
       "      <td>0.498759</td>\n",
       "      <td>0.700745</td>\n",
       "      <td>0.140681</td>\n",
       "      <td>0.672821</td>\n",
       "      <td>0.270266</td>\n",
       "      <td>0.523052</td>\n",
       "      <td>0.420210</td>\n",
       "      <td>0.433887</td>\n",
       "      <td>0.522939</td>\n",
       "      <td>0.388129</td>\n",
       "      <td>0.779673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DT</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>0.501341</td>\n",
       "      <td>0.747333</td>\n",
       "      <td>0.125084</td>\n",
       "      <td>0.722935</td>\n",
       "      <td>0.242161</td>\n",
       "      <td>0.595890</td>\n",
       "      <td>0.399344</td>\n",
       "      <td>0.526998</td>\n",
       "      <td>0.529820</td>\n",
       "      <td>0.458716</td>\n",
       "      <td>0.768588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DT</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>0.498717</td>\n",
       "      <td>0.735425</td>\n",
       "      <td>0.137712</td>\n",
       "      <td>0.665624</td>\n",
       "      <td>0.249283</td>\n",
       "      <td>0.565471</td>\n",
       "      <td>0.423549</td>\n",
       "      <td>0.476671</td>\n",
       "      <td>0.535555</td>\n",
       "      <td>0.421084</td>\n",
       "      <td>0.788552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GB</td>\n",
       "      <td>2012-07-01</td>\n",
       "      <td>0.500191</td>\n",
       "      <td>0.399055</td>\n",
       "      <td>0.080114</td>\n",
       "      <td>0.389438</td>\n",
       "      <td>0.156433</td>\n",
       "      <td>0.365822</td>\n",
       "      <td>0.293894</td>\n",
       "      <td>0.348454</td>\n",
       "      <td>0.419972</td>\n",
       "      <td>0.323689</td>\n",
       "      <td>0.650224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>GB</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>0.502873</td>\n",
       "      <td>0.505667</td>\n",
       "      <td>0.084635</td>\n",
       "      <td>0.493837</td>\n",
       "      <td>0.165421</td>\n",
       "      <td>0.469863</td>\n",
       "      <td>0.314885</td>\n",
       "      <td>0.444839</td>\n",
       "      <td>0.447222</td>\n",
       "      <td>0.406000</td>\n",
       "      <td>0.680261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>GB</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>0.497720</td>\n",
       "      <td>0.458650</td>\n",
       "      <td>0.085885</td>\n",
       "      <td>0.427519</td>\n",
       "      <td>0.160110</td>\n",
       "      <td>0.406052</td>\n",
       "      <td>0.304141</td>\n",
       "      <td>0.387806</td>\n",
       "      <td>0.435713</td>\n",
       "      <td>0.357186</td>\n",
       "      <td>0.668892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>KNN</td>\n",
       "      <td>2012-07-01</td>\n",
       "      <td>0.496304</td>\n",
       "      <td>0.373711</td>\n",
       "      <td>0.075026</td>\n",
       "      <td>0.377201</td>\n",
       "      <td>0.151518</td>\n",
       "      <td>0.358201</td>\n",
       "      <td>0.287772</td>\n",
       "      <td>0.339582</td>\n",
       "      <td>0.409279</td>\n",
       "      <td>0.315747</td>\n",
       "      <td>0.634270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>KNN</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>0.499519</td>\n",
       "      <td>0.496667</td>\n",
       "      <td>0.083129</td>\n",
       "      <td>0.434377</td>\n",
       "      <td>0.145503</td>\n",
       "      <td>0.446553</td>\n",
       "      <td>0.299264</td>\n",
       "      <td>0.419534</td>\n",
       "      <td>0.421781</td>\n",
       "      <td>0.392714</td>\n",
       "      <td>0.658000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>KNN</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>0.501378</td>\n",
       "      <td>0.398289</td>\n",
       "      <td>0.074582</td>\n",
       "      <td>0.419518</td>\n",
       "      <td>0.157114</td>\n",
       "      <td>0.360345</td>\n",
       "      <td>0.269906</td>\n",
       "      <td>0.354299</td>\n",
       "      <td>0.398066</td>\n",
       "      <td>0.336037</td>\n",
       "      <td>0.629287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>LR</td>\n",
       "      <td>2012-07-01</td>\n",
       "      <td>0.500194</td>\n",
       "      <td>0.413123</td>\n",
       "      <td>0.082938</td>\n",
       "      <td>0.389867</td>\n",
       "      <td>0.156606</td>\n",
       "      <td>0.361099</td>\n",
       "      <td>0.290100</td>\n",
       "      <td>0.340190</td>\n",
       "      <td>0.410012</td>\n",
       "      <td>0.304703</td>\n",
       "      <td>0.612086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>LR</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>0.503413</td>\n",
       "      <td>0.509167</td>\n",
       "      <td>0.085221</td>\n",
       "      <td>0.487925</td>\n",
       "      <td>0.163440</td>\n",
       "      <td>0.449842</td>\n",
       "      <td>0.301467</td>\n",
       "      <td>0.425055</td>\n",
       "      <td>0.427332</td>\n",
       "      <td>0.382409</td>\n",
       "      <td>0.640733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>LR</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>0.501205</td>\n",
       "      <td>0.433064</td>\n",
       "      <td>0.081094</td>\n",
       "      <td>0.420588</td>\n",
       "      <td>0.157515</td>\n",
       "      <td>0.401081</td>\n",
       "      <td>0.300418</td>\n",
       "      <td>0.380598</td>\n",
       "      <td>0.427614</td>\n",
       "      <td>0.343704</td>\n",
       "      <td>0.643645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>RF</td>\n",
       "      <td>2012-07-01</td>\n",
       "      <td>0.500690</td>\n",
       "      <td>0.361326</td>\n",
       "      <td>0.072539</td>\n",
       "      <td>0.351528</td>\n",
       "      <td>0.141205</td>\n",
       "      <td>0.346447</td>\n",
       "      <td>0.278329</td>\n",
       "      <td>0.340882</td>\n",
       "      <td>0.410846</td>\n",
       "      <td>0.315324</td>\n",
       "      <td>0.633422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>RF</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>0.501491</td>\n",
       "      <td>0.474111</td>\n",
       "      <td>0.079354</td>\n",
       "      <td>0.465662</td>\n",
       "      <td>0.155983</td>\n",
       "      <td>0.423368</td>\n",
       "      <td>0.283726</td>\n",
       "      <td>0.410701</td>\n",
       "      <td>0.412901</td>\n",
       "      <td>0.384212</td>\n",
       "      <td>0.643755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>RF</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>0.500150</td>\n",
       "      <td>0.446610</td>\n",
       "      <td>0.083630</td>\n",
       "      <td>0.433064</td>\n",
       "      <td>0.162187</td>\n",
       "      <td>0.398355</td>\n",
       "      <td>0.298376</td>\n",
       "      <td>0.376567</td>\n",
       "      <td>0.423085</td>\n",
       "      <td>0.352027</td>\n",
       "      <td>0.659230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>SVM</td>\n",
       "      <td>2012-07-01</td>\n",
       "      <td>0.502430</td>\n",
       "      <td>0.386598</td>\n",
       "      <td>0.077613</td>\n",
       "      <td>0.399313</td>\n",
       "      <td>0.160400</td>\n",
       "      <td>0.383426</td>\n",
       "      <td>0.308037</td>\n",
       "      <td>0.365341</td>\n",
       "      <td>0.440324</td>\n",
       "      <td>0.336138</td>\n",
       "      <td>0.675233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>SVM</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>0.507911</td>\n",
       "      <td>0.489333</td>\n",
       "      <td>0.081901</td>\n",
       "      <td>0.475683</td>\n",
       "      <td>0.159339</td>\n",
       "      <td>0.453879</td>\n",
       "      <td>0.304173</td>\n",
       "      <td>0.433740</td>\n",
       "      <td>0.436063</td>\n",
       "      <td>0.402371</td>\n",
       "      <td>0.674180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>SVM</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>0.510648</td>\n",
       "      <td>0.415082</td>\n",
       "      <td>0.077726</td>\n",
       "      <td>0.426172</td>\n",
       "      <td>0.159606</td>\n",
       "      <td>0.416984</td>\n",
       "      <td>0.312329</td>\n",
       "      <td>0.399451</td>\n",
       "      <td>0.448796</td>\n",
       "      <td>0.358913</td>\n",
       "      <td>0.672125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model_type test_start   auc-roc    p_at_5    r_at_5   p_at_10   r_at_10  \\\n",
       "0          AB 2012-07-01  0.501167  1.000000  0.200759  1.000000  0.401690   \n",
       "1          AB 2013-01-01  0.502712  1.000000  0.167373  1.000000  0.334970   \n",
       "2          AB 2013-07-01  0.497006  1.000000  0.187255  1.000000  0.374511   \n",
       "3          BG 2012-07-01  0.505130  0.373711  0.075026  0.338772  0.136081   \n",
       "4          BG 2013-01-01  0.498260  0.434667  0.072752  0.425050  0.142379   \n",
       "5          BG 2013-07-01  0.494898  0.405577  0.075946  0.396388  0.148451   \n",
       "6          DT 2012-07-01  0.498759  0.700745  0.140681  0.672821  0.270266   \n",
       "7          DT 2013-01-01  0.501341  0.747333  0.125084  0.722935  0.242161   \n",
       "8          DT 2013-07-01  0.498717  0.735425  0.137712  0.665624  0.249283   \n",
       "9          GB 2012-07-01  0.500191  0.399055  0.080114  0.389438  0.156433   \n",
       "10         GB 2013-01-01  0.502873  0.505667  0.084635  0.493837  0.165421   \n",
       "11         GB 2013-07-01  0.497720  0.458650  0.085885  0.427519  0.160110   \n",
       "12        KNN 2012-07-01  0.496304  0.373711  0.075026  0.377201  0.151518   \n",
       "13        KNN 2013-01-01  0.499519  0.496667  0.083129  0.434377  0.145503   \n",
       "14        KNN 2013-07-01  0.501378  0.398289  0.074582  0.419518  0.157114   \n",
       "15         LR 2012-07-01  0.500194  0.413123  0.082938  0.389867  0.156606   \n",
       "16         LR 2013-01-01  0.503413  0.509167  0.085221  0.487925  0.163440   \n",
       "17         LR 2013-07-01  0.501205  0.433064  0.081094  0.420588  0.157515   \n",
       "18         RF 2012-07-01  0.500690  0.361326  0.072539  0.351528  0.141205   \n",
       "19         RF 2013-01-01  0.501491  0.474111  0.079354  0.465662  0.155983   \n",
       "20         RF 2013-07-01  0.500150  0.446610  0.083630  0.433064  0.162187   \n",
       "21        SVM 2012-07-01  0.502430  0.386598  0.077613  0.399313  0.160400   \n",
       "22        SVM 2013-01-01  0.507911  0.489333  0.081901  0.475683  0.159339   \n",
       "23        SVM 2013-07-01  0.510648  0.415082  0.077726  0.426172  0.159606   \n",
       "\n",
       "     p_at_20   r_at_20   p_at_30   r_at_30   p_at_50   r_at_50  \n",
       "0   0.935809  0.751811  0.623784  0.751811  0.374259  0.751811  \n",
       "1   1.000000  0.670163  0.783130  0.787324  0.469899  0.787324  \n",
       "2   1.000000  0.749021  0.745353  0.837427  0.447183  0.837427  \n",
       "3   0.321383  0.258192  0.317258  0.382373  0.287799  0.578130  \n",
       "4   0.416250  0.278956  0.398224  0.400357  0.359483  0.602321  \n",
       "5   0.376109  0.281714  0.356253  0.400261  0.330461  0.618844  \n",
       "6   0.523052  0.420210  0.433887  0.522939  0.388129  0.779673  \n",
       "7   0.595890  0.399344  0.526998  0.529820  0.458716  0.768588  \n",
       "8   0.565471  0.423549  0.476671  0.535555  0.421084  0.788552  \n",
       "9   0.365822  0.293894  0.348454  0.419972  0.323689  0.650224  \n",
       "10  0.469863  0.314885  0.444839  0.447222  0.406000  0.680261  \n",
       "11  0.406052  0.304141  0.387806  0.435713  0.357186  0.668892  \n",
       "12  0.358201  0.287772  0.339582  0.409279  0.315747  0.634270  \n",
       "13  0.446553  0.299264  0.419534  0.421781  0.392714  0.658000  \n",
       "14  0.360345  0.269906  0.354299  0.398066  0.336037  0.629287  \n",
       "15  0.361099  0.290100  0.340190  0.410012  0.304703  0.612086  \n",
       "16  0.449842  0.301467  0.425055  0.427332  0.382409  0.640733  \n",
       "17  0.401081  0.300418  0.380598  0.427614  0.343704  0.643645  \n",
       "18  0.346447  0.278329  0.340882  0.410846  0.315324  0.633422  \n",
       "19  0.423368  0.283726  0.410701  0.412901  0.384212  0.643755  \n",
       "20  0.398355  0.298376  0.376567  0.423085  0.352027  0.659230  \n",
       "21  0.383426  0.308037  0.365341  0.440324  0.336138  0.675233  \n",
       "22  0.453879  0.304173  0.433740  0.436063  0.402371  0.674180  \n",
       "23  0.416984  0.312329  0.399451  0.448796  0.358913  0.672125  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_compare_time = results_without_baseline[['model_type', 'auc-roc', 'p_at_5', 'r_at_5', 'p_at_10', 'r_at_10', 'p_at_20', 'r_at_20', 'p_at_30', 'r_at_30', 'p_at_50', 'r_at_50', 'test_start']]\n",
    "model_compare_time[['p_at_5', 'r_at_5', 'p_at_10', 'r_at_10', 'p_at_20', 'r_at_20', 'p_at_30', 'r_at_30', 'p_at_50', 'r_at_50']] = model_compare_time[['p_at_5', 'r_at_5', 'p_at_10', 'r_at_10', 'p_at_20', 'r_at_20', 'p_at_30', 'r_at_30', 'p_at_50', 'r_at_50']].apply(pd.to_numeric)\n",
    "model_compare_time = model_compare_time.groupby(['model_type', 'test_start']).mean()\n",
    "model_compare_time.reset_index(inplace=True)\n",
    "model_compare_time"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
