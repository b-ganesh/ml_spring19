{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "import assignment3_functions as library\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import (svm, ensemble, tree,\n",
    "                     linear_model, neighbors, naive_bayes, dummy)\n",
    "pd.options.display.max_columns = 999\n",
    "import warnings \n",
    "warnings.simplefilter('ignore')\n",
    "from datetime import date, datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "donors_df = library.file_to_dataframe(\"projects_2012_2013.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>projectid</th>\n",
       "      <th>teacher_acctid</th>\n",
       "      <th>schoolid</th>\n",
       "      <th>school_ncesid</th>\n",
       "      <th>school_latitude</th>\n",
       "      <th>school_longitude</th>\n",
       "      <th>school_city</th>\n",
       "      <th>school_state</th>\n",
       "      <th>school_metro</th>\n",
       "      <th>school_district</th>\n",
       "      <th>school_county</th>\n",
       "      <th>school_charter</th>\n",
       "      <th>school_magnet</th>\n",
       "      <th>teacher_prefix</th>\n",
       "      <th>primary_focus_subject</th>\n",
       "      <th>primary_focus_area</th>\n",
       "      <th>secondary_focus_subject</th>\n",
       "      <th>secondary_focus_area</th>\n",
       "      <th>resource_type</th>\n",
       "      <th>poverty_level</th>\n",
       "      <th>grade_level</th>\n",
       "      <th>total_price_including_optional_support</th>\n",
       "      <th>students_reached</th>\n",
       "      <th>eligible_double_your_impact_match</th>\n",
       "      <th>date_posted</th>\n",
       "      <th>datefullyfunded</th>\n",
       "      <th>60_days_fullyfunded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001ccc0e81598c4bd86bacb94d7acb</td>\n",
       "      <td>96963218e74e10c3764a5cfb153e6fea</td>\n",
       "      <td>9f3f9f2c2da7edda5648ccd10554ed8c</td>\n",
       "      <td>1.709930e+11</td>\n",
       "      <td>41.807654</td>\n",
       "      <td>-87.673257</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>IL</td>\n",
       "      <td>urban</td>\n",
       "      <td>Pershing Elem Network</td>\n",
       "      <td>Cook</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>Mrs.</td>\n",
       "      <td>Mathematics</td>\n",
       "      <td>Math &amp; Science</td>\n",
       "      <td>Visual Arts</td>\n",
       "      <td>Music &amp; The Arts</td>\n",
       "      <td>Supplies</td>\n",
       "      <td>highest poverty</td>\n",
       "      <td>Grades PreK-2</td>\n",
       "      <td>1498.61</td>\n",
       "      <td>31.0</td>\n",
       "      <td>f</td>\n",
       "      <td>2013-04-14</td>\n",
       "      <td>2013-05-02</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000fa3aa8f6649abab23615b546016d</td>\n",
       "      <td>2a578595fe351e7fce057e048c409b18</td>\n",
       "      <td>3432ed3d4466fac2f2ead83ab354e333</td>\n",
       "      <td>6.409801e+10</td>\n",
       "      <td>34.296596</td>\n",
       "      <td>-119.296596</td>\n",
       "      <td>Ventura</td>\n",
       "      <td>CA</td>\n",
       "      <td>urban</td>\n",
       "      <td>Ventura Unif School District</td>\n",
       "      <td>Ventura</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>Mrs.</td>\n",
       "      <td>Civics &amp; Government</td>\n",
       "      <td>History &amp; Civics</td>\n",
       "      <td>Literature &amp; Writing</td>\n",
       "      <td>Literacy &amp; Language</td>\n",
       "      <td>Books</td>\n",
       "      <td>highest poverty</td>\n",
       "      <td>Grades 3-5</td>\n",
       "      <td>282.47</td>\n",
       "      <td>28.0</td>\n",
       "      <td>t</td>\n",
       "      <td>2012-04-07</td>\n",
       "      <td>2012-04-18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000134f07d4b30140d63262c871748ff</td>\n",
       "      <td>26bd60377bdbffb53a644a16c5308e82</td>\n",
       "      <td>dc8dcb501c3b2bb0b10e9c6ee2cd8afd</td>\n",
       "      <td>6.227100e+10</td>\n",
       "      <td>34.078625</td>\n",
       "      <td>-118.257834</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>CA</td>\n",
       "      <td>urban</td>\n",
       "      <td>Los Angeles Unif Sch Dist</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>Ms.</td>\n",
       "      <td>Literacy</td>\n",
       "      <td>Literacy &amp; Language</td>\n",
       "      <td>Social Sciences</td>\n",
       "      <td>History &amp; Civics</td>\n",
       "      <td>Technology</td>\n",
       "      <td>high poverty</td>\n",
       "      <td>Grades 3-5</td>\n",
       "      <td>1012.38</td>\n",
       "      <td>56.0</td>\n",
       "      <td>f</td>\n",
       "      <td>2012-01-30</td>\n",
       "      <td>2012-04-15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001f2d0b3827bba67cdbeaa248b832d</td>\n",
       "      <td>15d900805d9d716c051c671827109f45</td>\n",
       "      <td>8bea7e8c6e4279fca6276128db89292e</td>\n",
       "      <td>3.600090e+11</td>\n",
       "      <td>40.687286</td>\n",
       "      <td>-73.988217</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>NY</td>\n",
       "      <td>urban</td>\n",
       "      <td>New York City Dept Of Ed</td>\n",
       "      <td>Kings (Brooklyn)</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>Ms.</td>\n",
       "      <td>Literacy</td>\n",
       "      <td>Literacy &amp; Language</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Books</td>\n",
       "      <td>high poverty</td>\n",
       "      <td>Grades PreK-2</td>\n",
       "      <td>175.33</td>\n",
       "      <td>23.0</td>\n",
       "      <td>f</td>\n",
       "      <td>2012-10-11</td>\n",
       "      <td>2012-12-05</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0004536db996ba697ca72c9e058bfe69</td>\n",
       "      <td>400f8b82bb0143f6a40b217a517fe311</td>\n",
       "      <td>fbdefab6fe41e12c55886c610c110753</td>\n",
       "      <td>3.606870e+11</td>\n",
       "      <td>40.793018</td>\n",
       "      <td>-73.205635</td>\n",
       "      <td>Central Islip</td>\n",
       "      <td>NY</td>\n",
       "      <td>suburban</td>\n",
       "      <td>Central Islip Union Free SD</td>\n",
       "      <td>Suffolk</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>Mrs.</td>\n",
       "      <td>Literacy</td>\n",
       "      <td>Literacy &amp; Language</td>\n",
       "      <td>Literature &amp; Writing</td>\n",
       "      <td>Literacy &amp; Language</td>\n",
       "      <td>Technology</td>\n",
       "      <td>high poverty</td>\n",
       "      <td>Grades PreK-2</td>\n",
       "      <td>3591.11</td>\n",
       "      <td>150.0</td>\n",
       "      <td>f</td>\n",
       "      <td>2013-01-08</td>\n",
       "      <td>2013-03-25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          projectid                    teacher_acctid  \\\n",
       "0  00001ccc0e81598c4bd86bacb94d7acb  96963218e74e10c3764a5cfb153e6fea   \n",
       "1  0000fa3aa8f6649abab23615b546016d  2a578595fe351e7fce057e048c409b18   \n",
       "2  000134f07d4b30140d63262c871748ff  26bd60377bdbffb53a644a16c5308e82   \n",
       "3  0001f2d0b3827bba67cdbeaa248b832d  15d900805d9d716c051c671827109f45   \n",
       "4  0004536db996ba697ca72c9e058bfe69  400f8b82bb0143f6a40b217a517fe311   \n",
       "\n",
       "                           schoolid  school_ncesid  school_latitude  \\\n",
       "0  9f3f9f2c2da7edda5648ccd10554ed8c   1.709930e+11        41.807654   \n",
       "1  3432ed3d4466fac2f2ead83ab354e333   6.409801e+10        34.296596   \n",
       "2  dc8dcb501c3b2bb0b10e9c6ee2cd8afd   6.227100e+10        34.078625   \n",
       "3  8bea7e8c6e4279fca6276128db89292e   3.600090e+11        40.687286   \n",
       "4  fbdefab6fe41e12c55886c610c110753   3.606870e+11        40.793018   \n",
       "\n",
       "   school_longitude    school_city school_state school_metro  \\\n",
       "0        -87.673257        Chicago           IL        urban   \n",
       "1       -119.296596        Ventura           CA        urban   \n",
       "2       -118.257834    Los Angeles           CA        urban   \n",
       "3        -73.988217       Brooklyn           NY        urban   \n",
       "4        -73.205635  Central Islip           NY     suburban   \n",
       "\n",
       "                school_district     school_county school_charter  \\\n",
       "0         Pershing Elem Network              Cook              f   \n",
       "1  Ventura Unif School District           Ventura              f   \n",
       "2     Los Angeles Unif Sch Dist       Los Angeles              f   \n",
       "3      New York City Dept Of Ed  Kings (Brooklyn)              f   \n",
       "4   Central Islip Union Free SD           Suffolk              f   \n",
       "\n",
       "  school_magnet teacher_prefix primary_focus_subject   primary_focus_area  \\\n",
       "0             f           Mrs.           Mathematics       Math & Science   \n",
       "1             f           Mrs.   Civics & Government     History & Civics   \n",
       "2             f            Ms.              Literacy  Literacy & Language   \n",
       "3             t            Ms.              Literacy  Literacy & Language   \n",
       "4             f           Mrs.              Literacy  Literacy & Language   \n",
       "\n",
       "  secondary_focus_subject secondary_focus_area resource_type    poverty_level  \\\n",
       "0             Visual Arts     Music & The Arts      Supplies  highest poverty   \n",
       "1    Literature & Writing  Literacy & Language         Books  highest poverty   \n",
       "2         Social Sciences     History & Civics    Technology     high poverty   \n",
       "3                     NaN                  NaN         Books     high poverty   \n",
       "4    Literature & Writing  Literacy & Language    Technology     high poverty   \n",
       "\n",
       "     grade_level  total_price_including_optional_support  students_reached  \\\n",
       "0  Grades PreK-2                                 1498.61              31.0   \n",
       "1     Grades 3-5                                  282.47              28.0   \n",
       "2     Grades 3-5                                 1012.38              56.0   \n",
       "3  Grades PreK-2                                  175.33              23.0   \n",
       "4  Grades PreK-2                                 3591.11             150.0   \n",
       "\n",
       "  eligible_double_your_impact_match date_posted datefullyfunded  \\\n",
       "0                                 f  2013-04-14      2013-05-02   \n",
       "1                                 t  2012-04-07      2012-04-18   \n",
       "2                                 f  2012-01-30      2012-04-15   \n",
       "3                                 f  2012-10-11      2012-12-05   \n",
       "4                                 f  2013-01-08      2013-03-25   \n",
       "\n",
       "   60_days_fullyfunded  \n",
       "0                    0  \n",
       "1                    0  \n",
       "2                    1  \n",
       "3                    0  \n",
       "4                    1  "
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "donors_df['date_posted'] = pd.to_datetime(donors_df['date_posted'], format='%m/%d/%y')\n",
    "donors_df['datefullyfunded'] = pd.to_datetime(donors_df['datefullyfunded'], format='%m/%d/%y')\n",
    "donors_df['60_days_fullyfunded'] = np.where(donors_df['datefullyfunded'] - donors_df['date_posted'] <= pd.to_timedelta(60, unit='days'), 0, 1)\n",
    "donors_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inspecting NAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "projectid                                     0\n",
       "teacher_acctid                                0\n",
       "schoolid                                      0\n",
       "school_ncesid                              9233\n",
       "school_latitude                               0\n",
       "school_longitude                              0\n",
       "school_city                                   0\n",
       "school_state                                  0\n",
       "school_metro                              15224\n",
       "school_district                             172\n",
       "school_county                                 0\n",
       "school_charter                                0\n",
       "school_magnet                                 0\n",
       "teacher_prefix                                0\n",
       "primary_focus_subject                        15\n",
       "primary_focus_area                           15\n",
       "secondary_focus_subject                   40556\n",
       "secondary_focus_area                      40556\n",
       "resource_type                                17\n",
       "poverty_level                                 0\n",
       "grade_level                                   3\n",
       "total_price_including_optional_support        0\n",
       "students_reached                             59\n",
       "eligible_double_your_impact_match             0\n",
       "date_posted                                   0\n",
       "datefullyfunded                               0\n",
       "60_days_fullyfunded                           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "library.na_summary(donors_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Strategy for imputing: Looking at the NA summary above, it looks like I will need to impute school_metro, school_district, primary_focus_subject, primary_focus_area, secondary_focus_subject, secondary_focus_area, resource_type, grade_level, and students_reached. This will happen in the pre-processing step, after doing train, test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_dummy_list = ['school_magnet', 'school_charter', 'eligible_double_your_impact_match']\n",
    "categorical_list = ['teacher_prefix', 'primary_focus_subject', 'primary_focus_area', 'resource_type', 'poverty_level', 'grade_level', 'school_district', 'secondary_focus_subject', 'secondary_focus_area', 'school_state', 'school_city', 'school_metro', 'school_county']\n",
    "continuous_impute_list = ['students_reached']\n",
    "vars_to_drop_all = ['projectid', 'teacher_acctid', 'schoolid', 'school_ncesid', 'school_longitude', 'school_latitude']\n",
    "vars_to_drop_dates = ['date_posted', 'datefullyfunded', '60_days_fullyfunded']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fix temporal split function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[datetime.datetime(2012, 1, 1, 0, 0),\n",
       "  datetime.datetime(2012, 4, 30, 0, 0),\n",
       "  datetime.datetime(2012, 7, 1, 0, 0),\n",
       "  datetime.datetime(2012, 10, 31, 0, 0),\n",
       "  6],\n",
       " [datetime.datetime(2012, 1, 1, 0, 0),\n",
       "  datetime.datetime(2012, 10, 31, 0, 0),\n",
       "  datetime.datetime(2013, 1, 1, 0, 0),\n",
       "  datetime.datetime(2013, 4, 30, 0, 0),\n",
       "  6],\n",
       " [datetime.datetime(2012, 1, 1, 0, 0),\n",
       "  datetime.datetime(2013, 4, 30, 0, 0),\n",
       "  datetime.datetime(2013, 7, 1, 0, 0),\n",
       "  datetime.datetime(2013, 10, 31, 0, 0),\n",
       "  6]]"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_time_6mo = '2012-01-01'\n",
    "end_time_6mo = '2013-12-31'\n",
    "prediction_windows = [6]\n",
    "temp_split_6mo = library.temporal_dates(start_time_6mo, end_time_6mo, prediction_windows, 60)\n",
    "temp_split_6mo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_to_run = ['RF', 'AB', 'LR', 'KNN', 'SVM', 'DT', 'GB', 'BG']\n",
    " \n",
    "classifiers = {'RF': ensemble.RandomForestClassifier(n_estimators=50, n_jobs=-1),\n",
    "    'LR': linear_model.LogisticRegression(penalty='l1', C=1e5, n_jobs=-1),\n",
    "    'SVM': svm.LinearSVC(tol= 1e-5, random_state=0),\n",
    "    'AB': ensemble.AdaBoostClassifier(tree.DecisionTreeClassifier(max_depth=1), algorithm=\"SAMME\", n_estimators=200),\n",
    "    'DT': tree.DecisionTreeClassifier(),\n",
    "    'KNN': neighbors.KNeighborsClassifier(n_neighbors=10, n_jobs=-1),\n",
    "    'GB': ensemble.GradientBoostingClassifier(learning_rate=0.05, subsample=0.5, max_depth=6, n_estimators=10),\n",
    "    'BG': ensemble.BaggingClassifier(linear_model.LogisticRegression(penalty='l1', C=1e5, n_jobs=-1))\n",
    "        }\n",
    "\n",
    "parameters = { \n",
    "    'RF':{'n_estimators': [10,100], 'max_depth': [5, 20, 100], 'max_features': ['sqrt','log2'],'min_samples_split': [2,10], 'n_jobs': [-1]},\n",
    "    'LR': { 'penalty': ['l1','l2'], 'C': [0.001,0.1,1,10]},\n",
    "    'AB': { 'algorithm': ['SAMME'], 'n_estimators': [1]},\n",
    "    'DT': {'criterion': ['gini', 'entropy'], 'max_depth': [1,10,20,100],'min_samples_split': [2,5,10]},\n",
    "    'SVM': {'C': [0.01]},\n",
    "    'KNN': {'n_neighbors': [25],'weights': ['uniform','distance'],'algorithm': ['ball_tree']},\n",
    "    'GB': {'n_estimators': [10], 'learning_rate': [0.1,0.5], 'subsample': [0.1,0.5], 'max_depth': [5]},\n",
    "    'BG': {'n_estimators': [10], 'max_samples': [.5]}\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running through model RF...\n",
      "Running through model AB...\n",
      "Running through model LR...\n",
      "Running through model KNN...\n",
      "Running through model SVM...\n",
      "Running through model DT...\n",
      "Running through model GB...\n",
      "Running through model BG...\n",
      "Running through model RF...\n",
      "Running through model AB...\n",
      "Running through model LR...\n",
      "Running through model KNN...\n",
      "Running through model SVM...\n",
      "Running through model DT...\n",
      "Running through model GB...\n",
      "Running through model BG...\n",
      "Running through model RF...\n",
      "Running through model AB...\n",
      "Running through model LR...\n",
      "Running through model KNN...\n",
      "Running through model SVM...\n",
      "Running through model DT...\n",
      "Running through model GB...\n",
      "Running through model BG...\n"
     ]
    }
   ],
   "source": [
    "results_df, params = library.run_models(models_to_run, classifiers, parameters, donors_df, '60_days_fullyfunded', categorical_list, to_dummy_list, continuous_impute_list, vars_to_drop_all, vars_to_drop_dates, \"table_with_KNN.csv\", temp_split_6mo, \"date_posted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_start</th>\n",
       "      <th>train_end</th>\n",
       "      <th>test_start</th>\n",
       "      <th>test_end</th>\n",
       "      <th>model_type</th>\n",
       "      <th>classifier</th>\n",
       "      <th>train_size</th>\n",
       "      <th>test_size</th>\n",
       "      <th>auc-roc</th>\n",
       "      <th>p_at_1</th>\n",
       "      <th>a_at_1</th>\n",
       "      <th>r_at_1</th>\n",
       "      <th>f1_at_1</th>\n",
       "      <th>p_at_2</th>\n",
       "      <th>a_at_2</th>\n",
       "      <th>r_at_2</th>\n",
       "      <th>f1_at_2</th>\n",
       "      <th>p_at_5</th>\n",
       "      <th>a_at_5</th>\n",
       "      <th>r_at_5</th>\n",
       "      <th>f1_at_5</th>\n",
       "      <th>p_at_10</th>\n",
       "      <th>a_at_10</th>\n",
       "      <th>r_at_10</th>\n",
       "      <th>f1_at_10</th>\n",
       "      <th>p_at_20</th>\n",
       "      <th>a_at_20</th>\n",
       "      <th>r_at_20</th>\n",
       "      <th>f1_at_20</th>\n",
       "      <th>p_at_30</th>\n",
       "      <th>a_at_30</th>\n",
       "      <th>r_at_30</th>\n",
       "      <th>f1_at_30</th>\n",
       "      <th>p_at_50</th>\n",
       "      <th>a_at_50</th>\n",
       "      <th>r_at_50</th>\n",
       "      <th>f1_at_50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-04-30</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>2013-10-31</td>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>74241</td>\n",
       "      <td>31563</td>\n",
       "      <td>0.500482</td>\n",
       "      <td>0.438095</td>\n",
       "      <td>0.731775</td>\n",
       "      <td>0.0163759</td>\n",
       "      <td>0.0315717</td>\n",
       "      <td>0.445325</td>\n",
       "      <td>0.730824</td>\n",
       "      <td>0.0333452</td>\n",
       "      <td>0.0620446</td>\n",
       "      <td>0.440431</td>\n",
       "      <td>0.727054</td>\n",
       "      <td>0.082473</td>\n",
       "      <td>0.138931</td>\n",
       "      <td>0.397655</td>\n",
       "      <td>0.712543</td>\n",
       "      <td>0.148926</td>\n",
       "      <td>0.216697</td>\n",
       "      <td>0.366128</td>\n",
       "      <td>0.679466</td>\n",
       "      <td>0.274238</td>\n",
       "      <td>0.31359</td>\n",
       "      <td>0.336396</td>\n",
       "      <td>0.634857</td>\n",
       "      <td>0.377952</td>\n",
       "      <td>0.355965</td>\n",
       "      <td>0.310373</td>\n",
       "      <td>0.543389</td>\n",
       "      <td>0.581227</td>\n",
       "      <td>0.40466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-04-30</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>2013-10-31</td>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>74241</td>\n",
       "      <td>31563</td>\n",
       "      <td>0.500347</td>\n",
       "      <td>0.469841</td>\n",
       "      <td>0.732408</td>\n",
       "      <td>0.0175626</td>\n",
       "      <td>0.0338595</td>\n",
       "      <td>0.462758</td>\n",
       "      <td>0.731521</td>\n",
       "      <td>0.0346505</td>\n",
       "      <td>0.0644734</td>\n",
       "      <td>0.455006</td>\n",
       "      <td>0.728511</td>\n",
       "      <td>0.0852023</td>\n",
       "      <td>0.143528</td>\n",
       "      <td>0.427123</td>\n",
       "      <td>0.718436</td>\n",
       "      <td>0.159962</td>\n",
       "      <td>0.232755</td>\n",
       "      <td>0.402567</td>\n",
       "      <td>0.69404</td>\n",
       "      <td>0.301531</td>\n",
       "      <td>0.3448</td>\n",
       "      <td>0.381496</td>\n",
       "      <td>0.661914</td>\n",
       "      <td>0.428622</td>\n",
       "      <td>0.403688</td>\n",
       "      <td>0.349408</td>\n",
       "      <td>0.582422</td>\n",
       "      <td>0.654325</td>\n",
       "      <td>0.455552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-04-30</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>2013-10-31</td>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>74241</td>\n",
       "      <td>31563</td>\n",
       "      <td>0.496559</td>\n",
       "      <td>0.479365</td>\n",
       "      <td>0.732598</td>\n",
       "      <td>0.0179186</td>\n",
       "      <td>0.0345459</td>\n",
       "      <td>0.537242</td>\n",
       "      <td>0.734499</td>\n",
       "      <td>0.0402278</td>\n",
       "      <td>0.074851</td>\n",
       "      <td>0.431559</td>\n",
       "      <td>0.726167</td>\n",
       "      <td>0.0808117</td>\n",
       "      <td>0.136132</td>\n",
       "      <td>0.434411</td>\n",
       "      <td>0.719894</td>\n",
       "      <td>0.162691</td>\n",
       "      <td>0.236726</td>\n",
       "      <td>0.396863</td>\n",
       "      <td>0.691759</td>\n",
       "      <td>0.297259</td>\n",
       "      <td>0.339915</td>\n",
       "      <td>0.35583</td>\n",
       "      <td>0.646516</td>\n",
       "      <td>0.399786</td>\n",
       "      <td>0.37653</td>\n",
       "      <td>0.335213</td>\n",
       "      <td>0.568229</td>\n",
       "      <td>0.627744</td>\n",
       "      <td>0.437046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-04-30</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>2013-10-31</td>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>74241</td>\n",
       "      <td>31563</td>\n",
       "      <td>0.494507</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.733676</td>\n",
       "      <td>0.0199359</td>\n",
       "      <td>0.0384351</td>\n",
       "      <td>0.51664</td>\n",
       "      <td>0.733676</td>\n",
       "      <td>0.0386852</td>\n",
       "      <td>0.0719806</td>\n",
       "      <td>0.482256</td>\n",
       "      <td>0.731236</td>\n",
       "      <td>0.090305</td>\n",
       "      <td>0.152124</td>\n",
       "      <td>0.449303</td>\n",
       "      <td>0.722872</td>\n",
       "      <td>0.168269</td>\n",
       "      <td>0.244842</td>\n",
       "      <td>0.408428</td>\n",
       "      <td>0.696385</td>\n",
       "      <td>0.305921</td>\n",
       "      <td>0.34982</td>\n",
       "      <td>0.389839</td>\n",
       "      <td>0.66692</td>\n",
       "      <td>0.437997</td>\n",
       "      <td>0.412517</td>\n",
       "      <td>0.356505</td>\n",
       "      <td>0.589519</td>\n",
       "      <td>0.667616</td>\n",
       "      <td>0.464805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-04-30</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>2013-10-31</td>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>74241</td>\n",
       "      <td>31563</td>\n",
       "      <td>0.494826</td>\n",
       "      <td>0.396825</td>\n",
       "      <td>0.730951</td>\n",
       "      <td>0.0148333</td>\n",
       "      <td>0.0285976</td>\n",
       "      <td>0.545166</td>\n",
       "      <td>0.734816</td>\n",
       "      <td>0.0408212</td>\n",
       "      <td>0.075955</td>\n",
       "      <td>0.818124</td>\n",
       "      <td>0.76482</td>\n",
       "      <td>0.153198</td>\n",
       "      <td>0.258071</td>\n",
       "      <td>0.476236</td>\n",
       "      <td>0.728258</td>\n",
       "      <td>0.178355</td>\n",
       "      <td>0.259518</td>\n",
       "      <td>0.325412</td>\n",
       "      <td>0.663182</td>\n",
       "      <td>0.24374</td>\n",
       "      <td>0.278716</td>\n",
       "      <td>0.550275</td>\n",
       "      <td>0.763172</td>\n",
       "      <td>0.618251</td>\n",
       "      <td>0.582286</td>\n",
       "      <td>0.50941</td>\n",
       "      <td>0.74242</td>\n",
       "      <td>0.953958</td>\n",
       "      <td>0.664161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-04-30</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>2013-10-31</td>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>74241</td>\n",
       "      <td>31563</td>\n",
       "      <td>0.502917</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.730634</td>\n",
       "      <td>0.0142399</td>\n",
       "      <td>0.0274537</td>\n",
       "      <td>0.364501</td>\n",
       "      <td>0.727592</td>\n",
       "      <td>0.0272932</td>\n",
       "      <td>0.0507838</td>\n",
       "      <td>0.375792</td>\n",
       "      <td>0.720591</td>\n",
       "      <td>0.0703691</td>\n",
       "      <td>0.118541</td>\n",
       "      <td>0.375158</td>\n",
       "      <td>0.708044</td>\n",
       "      <td>0.140501</td>\n",
       "      <td>0.204438</td>\n",
       "      <td>0.356781</td>\n",
       "      <td>0.675728</td>\n",
       "      <td>0.267236</td>\n",
       "      <td>0.305584</td>\n",
       "      <td>0.351711</td>\n",
       "      <td>0.644045</td>\n",
       "      <td>0.395158</td>\n",
       "      <td>0.372171</td>\n",
       "      <td>0.325201</td>\n",
       "      <td>0.558217</td>\n",
       "      <td>0.608995</td>\n",
       "      <td>0.423992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-04-30</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>2013-10-31</td>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>74241</td>\n",
       "      <td>31563</td>\n",
       "      <td>0.502365</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.730634</td>\n",
       "      <td>0.0142399</td>\n",
       "      <td>0.0274537</td>\n",
       "      <td>0.332805</td>\n",
       "      <td>0.726325</td>\n",
       "      <td>0.0249199</td>\n",
       "      <td>0.0463679</td>\n",
       "      <td>0.418885</td>\n",
       "      <td>0.724899</td>\n",
       "      <td>0.0784384</td>\n",
       "      <td>0.132134</td>\n",
       "      <td>0.5282</td>\n",
       "      <td>0.73865</td>\n",
       "      <td>0.197817</td>\n",
       "      <td>0.287836</td>\n",
       "      <td>0.32161</td>\n",
       "      <td>0.661661</td>\n",
       "      <td>0.240892</td>\n",
       "      <td>0.27546</td>\n",
       "      <td>0.509717</td>\n",
       "      <td>0.73884</td>\n",
       "      <td>0.572683</td>\n",
       "      <td>0.539369</td>\n",
       "      <td>0.522781</td>\n",
       "      <td>0.75579</td>\n",
       "      <td>0.978996</td>\n",
       "      <td>0.681593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-04-30</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>2013-10-31</td>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>74241</td>\n",
       "      <td>31563</td>\n",
       "      <td>0.499254</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.732345</td>\n",
       "      <td>0.0174439</td>\n",
       "      <td>0.0336307</td>\n",
       "      <td>0.44691</td>\n",
       "      <td>0.730887</td>\n",
       "      <td>0.0334639</td>\n",
       "      <td>0.0622654</td>\n",
       "      <td>0.45564</td>\n",
       "      <td>0.728575</td>\n",
       "      <td>0.085321</td>\n",
       "      <td>0.143728</td>\n",
       "      <td>0.425856</td>\n",
       "      <td>0.718183</td>\n",
       "      <td>0.159487</td>\n",
       "      <td>0.232064</td>\n",
       "      <td>0.397972</td>\n",
       "      <td>0.692203</td>\n",
       "      <td>0.298089</td>\n",
       "      <td>0.340864</td>\n",
       "      <td>0.385615</td>\n",
       "      <td>0.664386</td>\n",
       "      <td>0.43325</td>\n",
       "      <td>0.408047</td>\n",
       "      <td>0.353716</td>\n",
       "      <td>0.586731</td>\n",
       "      <td>0.662395</td>\n",
       "      <td>0.46117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-04-30</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>2013-10-31</td>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>74241</td>\n",
       "      <td>31563</td>\n",
       "      <td>0.496487</td>\n",
       "      <td>0.463492</td>\n",
       "      <td>0.732281</td>\n",
       "      <td>0.0173253</td>\n",
       "      <td>0.033402</td>\n",
       "      <td>0.448494</td>\n",
       "      <td>0.730951</td>\n",
       "      <td>0.0335825</td>\n",
       "      <td>0.0624862</td>\n",
       "      <td>0.406844</td>\n",
       "      <td>0.723695</td>\n",
       "      <td>0.0761837</td>\n",
       "      <td>0.128336</td>\n",
       "      <td>0.410013</td>\n",
       "      <td>0.715014</td>\n",
       "      <td>0.153554</td>\n",
       "      <td>0.223431</td>\n",
       "      <td>0.382605</td>\n",
       "      <td>0.686056</td>\n",
       "      <td>0.286579</td>\n",
       "      <td>0.327702</td>\n",
       "      <td>0.367765</td>\n",
       "      <td>0.653677</td>\n",
       "      <td>0.413196</td>\n",
       "      <td>0.389159</td>\n",
       "      <td>0.344528</td>\n",
       "      <td>0.577543</td>\n",
       "      <td>0.645188</td>\n",
       "      <td>0.44919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-04-30</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>2013-10-31</td>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>74241</td>\n",
       "      <td>31563</td>\n",
       "      <td>0.498516</td>\n",
       "      <td>0.536508</td>\n",
       "      <td>0.733739</td>\n",
       "      <td>0.0200546</td>\n",
       "      <td>0.0386639</td>\n",
       "      <td>0.540412</td>\n",
       "      <td>0.734626</td>\n",
       "      <td>0.0404652</td>\n",
       "      <td>0.0752926</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.73301</td>\n",
       "      <td>0.0936276</td>\n",
       "      <td>0.157721</td>\n",
       "      <td>0.454373</td>\n",
       "      <td>0.723886</td>\n",
       "      <td>0.170167</td>\n",
       "      <td>0.247604</td>\n",
       "      <td>0.418885</td>\n",
       "      <td>0.700567</td>\n",
       "      <td>0.313753</td>\n",
       "      <td>0.358776</td>\n",
       "      <td>0.398817</td>\n",
       "      <td>0.672306</td>\n",
       "      <td>0.448084</td>\n",
       "      <td>0.422017</td>\n",
       "      <td>0.3598</td>\n",
       "      <td>0.592814</td>\n",
       "      <td>0.673787</td>\n",
       "      <td>0.469101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-04-30</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>2013-10-31</td>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>74241</td>\n",
       "      <td>31563</td>\n",
       "      <td>0.498968</td>\n",
       "      <td>0.52381</td>\n",
       "      <td>0.733485</td>\n",
       "      <td>0.0195799</td>\n",
       "      <td>0.0377488</td>\n",
       "      <td>0.469097</td>\n",
       "      <td>0.731775</td>\n",
       "      <td>0.0351252</td>\n",
       "      <td>0.0653566</td>\n",
       "      <td>0.465146</td>\n",
       "      <td>0.729525</td>\n",
       "      <td>0.087101</td>\n",
       "      <td>0.146727</td>\n",
       "      <td>0.433143</td>\n",
       "      <td>0.71964</td>\n",
       "      <td>0.162217</td>\n",
       "      <td>0.236036</td>\n",
       "      <td>0.398764</td>\n",
       "      <td>0.69252</td>\n",
       "      <td>0.298683</td>\n",
       "      <td>0.341543</td>\n",
       "      <td>0.383925</td>\n",
       "      <td>0.663372</td>\n",
       "      <td>0.431352</td>\n",
       "      <td>0.406259</td>\n",
       "      <td>0.355554</td>\n",
       "      <td>0.588569</td>\n",
       "      <td>0.665836</td>\n",
       "      <td>0.463566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-04-30</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>2013-10-31</td>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>74241</td>\n",
       "      <td>31563</td>\n",
       "      <td>0.497330</td>\n",
       "      <td>0.520635</td>\n",
       "      <td>0.733422</td>\n",
       "      <td>0.0194613</td>\n",
       "      <td>0.03752</td>\n",
       "      <td>0.534073</td>\n",
       "      <td>0.734373</td>\n",
       "      <td>0.0399905</td>\n",
       "      <td>0.0744094</td>\n",
       "      <td>0.486692</td>\n",
       "      <td>0.731679</td>\n",
       "      <td>0.0911356</td>\n",
       "      <td>0.153523</td>\n",
       "      <td>0.453422</td>\n",
       "      <td>0.723695</td>\n",
       "      <td>0.169811</td>\n",
       "      <td>0.247086</td>\n",
       "      <td>0.413498</td>\n",
       "      <td>0.698413</td>\n",
       "      <td>0.309719</td>\n",
       "      <td>0.354162</td>\n",
       "      <td>0.391318</td>\n",
       "      <td>0.667807</td>\n",
       "      <td>0.439658</td>\n",
       "      <td>0.414082</td>\n",
       "      <td>0.356695</td>\n",
       "      <td>0.589709</td>\n",
       "      <td>0.667972</td>\n",
       "      <td>0.465053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-04-30</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>2013-10-31</td>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>74241</td>\n",
       "      <td>31563</td>\n",
       "      <td>0.500315</td>\n",
       "      <td>0.415873</td>\n",
       "      <td>0.731331</td>\n",
       "      <td>0.0155453</td>\n",
       "      <td>0.0299703</td>\n",
       "      <td>0.388273</td>\n",
       "      <td>0.728543</td>\n",
       "      <td>0.0290732</td>\n",
       "      <td>0.0540958</td>\n",
       "      <td>0.416984</td>\n",
       "      <td>0.724709</td>\n",
       "      <td>0.0780824</td>\n",
       "      <td>0.131534</td>\n",
       "      <td>0.375792</td>\n",
       "      <td>0.708171</td>\n",
       "      <td>0.140738</td>\n",
       "      <td>0.204783</td>\n",
       "      <td>0.380862</td>\n",
       "      <td>0.685359</td>\n",
       "      <td>0.285274</td>\n",
       "      <td>0.326209</td>\n",
       "      <td>0.373257</td>\n",
       "      <td>0.656972</td>\n",
       "      <td>0.419366</td>\n",
       "      <td>0.394971</td>\n",
       "      <td>0.363855</td>\n",
       "      <td>0.59687</td>\n",
       "      <td>0.681381</td>\n",
       "      <td>0.474389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-04-30</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>2013-10-31</td>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>74241</td>\n",
       "      <td>31563</td>\n",
       "      <td>0.498521</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.732345</td>\n",
       "      <td>0.0174439</td>\n",
       "      <td>0.0336307</td>\n",
       "      <td>0.462758</td>\n",
       "      <td>0.731521</td>\n",
       "      <td>0.0346505</td>\n",
       "      <td>0.0644734</td>\n",
       "      <td>0.427757</td>\n",
       "      <td>0.725787</td>\n",
       "      <td>0.0800997</td>\n",
       "      <td>0.134933</td>\n",
       "      <td>0.420469</td>\n",
       "      <td>0.717105</td>\n",
       "      <td>0.15747</td>\n",
       "      <td>0.229129</td>\n",
       "      <td>0.39718</td>\n",
       "      <td>0.691886</td>\n",
       "      <td>0.297496</td>\n",
       "      <td>0.340186</td>\n",
       "      <td>0.372201</td>\n",
       "      <td>0.656338</td>\n",
       "      <td>0.41818</td>\n",
       "      <td>0.393853</td>\n",
       "      <td>0.343451</td>\n",
       "      <td>0.576466</td>\n",
       "      <td>0.643171</td>\n",
       "      <td>0.447786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-04-30</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>2013-10-31</td>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>74241</td>\n",
       "      <td>31563</td>\n",
       "      <td>0.498153</td>\n",
       "      <td>0.339683</td>\n",
       "      <td>0.72981</td>\n",
       "      <td>0.0126973</td>\n",
       "      <td>0.0244795</td>\n",
       "      <td>0.359746</td>\n",
       "      <td>0.727402</td>\n",
       "      <td>0.0269372</td>\n",
       "      <td>0.0501214</td>\n",
       "      <td>0.344106</td>\n",
       "      <td>0.717422</td>\n",
       "      <td>0.0644357</td>\n",
       "      <td>0.108546</td>\n",
       "      <td>0.35488</td>\n",
       "      <td>0.703989</td>\n",
       "      <td>0.132906</td>\n",
       "      <td>0.193387</td>\n",
       "      <td>0.358365</td>\n",
       "      <td>0.676362</td>\n",
       "      <td>0.268423</td>\n",
       "      <td>0.306941</td>\n",
       "      <td>0.352134</td>\n",
       "      <td>0.644299</td>\n",
       "      <td>0.395633</td>\n",
       "      <td>0.372618</td>\n",
       "      <td>0.320322</td>\n",
       "      <td>0.553338</td>\n",
       "      <td>0.599858</td>\n",
       "      <td>0.417631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-04-30</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>2013-10-31</td>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>74241</td>\n",
       "      <td>31563</td>\n",
       "      <td>0.505491</td>\n",
       "      <td>0.514286</td>\n",
       "      <td>0.733295</td>\n",
       "      <td>0.0192239</td>\n",
       "      <td>0.0370625</td>\n",
       "      <td>0.488114</td>\n",
       "      <td>0.732535</td>\n",
       "      <td>0.0365492</td>\n",
       "      <td>0.0680062</td>\n",
       "      <td>0.455006</td>\n",
       "      <td>0.728511</td>\n",
       "      <td>0.0852023</td>\n",
       "      <td>0.143528</td>\n",
       "      <td>0.434094</td>\n",
       "      <td>0.71983</td>\n",
       "      <td>0.162573</td>\n",
       "      <td>0.236554</td>\n",
       "      <td>0.40225</td>\n",
       "      <td>0.693914</td>\n",
       "      <td>0.301293</td>\n",
       "      <td>0.344528</td>\n",
       "      <td>0.386882</td>\n",
       "      <td>0.665146</td>\n",
       "      <td>0.434674</td>\n",
       "      <td>0.409388</td>\n",
       "      <td>0.351689</td>\n",
       "      <td>0.584704</td>\n",
       "      <td>0.658597</td>\n",
       "      <td>0.458526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-04-30</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>2013-10-31</td>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>74241</td>\n",
       "      <td>31563</td>\n",
       "      <td>0.494653</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.731901</td>\n",
       "      <td>0.0166133</td>\n",
       "      <td>0.0320293</td>\n",
       "      <td>0.435816</td>\n",
       "      <td>0.730444</td>\n",
       "      <td>0.0326332</td>\n",
       "      <td>0.0607198</td>\n",
       "      <td>0.417617</td>\n",
       "      <td>0.724773</td>\n",
       "      <td>0.078201</td>\n",
       "      <td>0.131734</td>\n",
       "      <td>0.405577</td>\n",
       "      <td>0.714127</td>\n",
       "      <td>0.151893</td>\n",
       "      <td>0.221014</td>\n",
       "      <td>0.381971</td>\n",
       "      <td>0.685803</td>\n",
       "      <td>0.286104</td>\n",
       "      <td>0.327159</td>\n",
       "      <td>0.372201</td>\n",
       "      <td>0.656338</td>\n",
       "      <td>0.41818</td>\n",
       "      <td>0.393853</td>\n",
       "      <td>0.342627</td>\n",
       "      <td>0.575642</td>\n",
       "      <td>0.641628</td>\n",
       "      <td>0.446712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-04-30</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>2013-10-31</td>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>74241</td>\n",
       "      <td>31563</td>\n",
       "      <td>0.500153</td>\n",
       "      <td>0.492063</td>\n",
       "      <td>0.732852</td>\n",
       "      <td>0.0183933</td>\n",
       "      <td>0.035461</td>\n",
       "      <td>0.488114</td>\n",
       "      <td>0.732535</td>\n",
       "      <td>0.0365492</td>\n",
       "      <td>0.0680062</td>\n",
       "      <td>0.47782</td>\n",
       "      <td>0.730792</td>\n",
       "      <td>0.0894743</td>\n",
       "      <td>0.150725</td>\n",
       "      <td>0.458492</td>\n",
       "      <td>0.724709</td>\n",
       "      <td>0.17171</td>\n",
       "      <td>0.249849</td>\n",
       "      <td>0.426648</td>\n",
       "      <td>0.703672</td>\n",
       "      <td>0.319568</td>\n",
       "      <td>0.365425</td>\n",
       "      <td>0.406422</td>\n",
       "      <td>0.676868</td>\n",
       "      <td>0.456628</td>\n",
       "      <td>0.430064</td>\n",
       "      <td>0.363158</td>\n",
       "      <td>0.596173</td>\n",
       "      <td>0.680076</td>\n",
       "      <td>0.47348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-04-30</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>2013-10-31</td>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>74241</td>\n",
       "      <td>31563</td>\n",
       "      <td>0.503332</td>\n",
       "      <td>0.492063</td>\n",
       "      <td>0.732852</td>\n",
       "      <td>0.0183933</td>\n",
       "      <td>0.035461</td>\n",
       "      <td>0.464342</td>\n",
       "      <td>0.731584</td>\n",
       "      <td>0.0347692</td>\n",
       "      <td>0.0646942</td>\n",
       "      <td>0.442966</td>\n",
       "      <td>0.727307</td>\n",
       "      <td>0.0829477</td>\n",
       "      <td>0.13973</td>\n",
       "      <td>0.42744</td>\n",
       "      <td>0.7185</td>\n",
       "      <td>0.160081</td>\n",
       "      <td>0.232928</td>\n",
       "      <td>0.39924</td>\n",
       "      <td>0.69271</td>\n",
       "      <td>0.299039</td>\n",
       "      <td>0.34195</td>\n",
       "      <td>0.383608</td>\n",
       "      <td>0.663182</td>\n",
       "      <td>0.430996</td>\n",
       "      <td>0.405923</td>\n",
       "      <td>0.353907</td>\n",
       "      <td>0.586921</td>\n",
       "      <td>0.662751</td>\n",
       "      <td>0.461418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-04-30</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>2013-10-31</td>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>74241</td>\n",
       "      <td>31563</td>\n",
       "      <td>0.497888</td>\n",
       "      <td>0.530159</td>\n",
       "      <td>0.733612</td>\n",
       "      <td>0.0198173</td>\n",
       "      <td>0.0382064</td>\n",
       "      <td>0.522979</td>\n",
       "      <td>0.733929</td>\n",
       "      <td>0.0391598</td>\n",
       "      <td>0.0728638</td>\n",
       "      <td>0.501267</td>\n",
       "      <td>0.733137</td>\n",
       "      <td>0.093865</td>\n",
       "      <td>0.158121</td>\n",
       "      <td>0.481622</td>\n",
       "      <td>0.729335</td>\n",
       "      <td>0.180373</td>\n",
       "      <td>0.262454</td>\n",
       "      <td>0.437579</td>\n",
       "      <td>0.708044</td>\n",
       "      <td>0.327756</td>\n",
       "      <td>0.374788</td>\n",
       "      <td>0.410013</td>\n",
       "      <td>0.679023</td>\n",
       "      <td>0.460662</td>\n",
       "      <td>0.433864</td>\n",
       "      <td>0.368481</td>\n",
       "      <td>0.601495</td>\n",
       "      <td>0.690044</td>\n",
       "      <td>0.48042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-04-30</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>2013-10-31</td>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>74241</td>\n",
       "      <td>31563</td>\n",
       "      <td>0.504727</td>\n",
       "      <td>0.453968</td>\n",
       "      <td>0.732091</td>\n",
       "      <td>0.0169693</td>\n",
       "      <td>0.0327156</td>\n",
       "      <td>0.454834</td>\n",
       "      <td>0.731204</td>\n",
       "      <td>0.0340572</td>\n",
       "      <td>0.0633694</td>\n",
       "      <td>0.415082</td>\n",
       "      <td>0.724519</td>\n",
       "      <td>0.0777264</td>\n",
       "      <td>0.130935</td>\n",
       "      <td>0.383714</td>\n",
       "      <td>0.709755</td>\n",
       "      <td>0.143705</td>\n",
       "      <td>0.2091</td>\n",
       "      <td>0.36185</td>\n",
       "      <td>0.677756</td>\n",
       "      <td>0.271034</td>\n",
       "      <td>0.309926</td>\n",
       "      <td>0.352767</td>\n",
       "      <td>0.644679</td>\n",
       "      <td>0.396345</td>\n",
       "      <td>0.373289</td>\n",
       "      <td>0.336037</td>\n",
       "      <td>0.569052</td>\n",
       "      <td>0.629287</td>\n",
       "      <td>0.43812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-04-30</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>2013-10-31</td>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>74241</td>\n",
       "      <td>31563</td>\n",
       "      <td>0.498073</td>\n",
       "      <td>0.457143</td>\n",
       "      <td>0.732155</td>\n",
       "      <td>0.0170879</td>\n",
       "      <td>0.0329444</td>\n",
       "      <td>0.459588</td>\n",
       "      <td>0.731394</td>\n",
       "      <td>0.0344132</td>\n",
       "      <td>0.0640318</td>\n",
       "      <td>0.456907</td>\n",
       "      <td>0.728701</td>\n",
       "      <td>0.0855583</td>\n",
       "      <td>0.144128</td>\n",
       "      <td>0.44455</td>\n",
       "      <td>0.721921</td>\n",
       "      <td>0.166489</td>\n",
       "      <td>0.242252</td>\n",
       "      <td>0.410171</td>\n",
       "      <td>0.697082</td>\n",
       "      <td>0.307227</td>\n",
       "      <td>0.351313</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.66635</td>\n",
       "      <td>0.436929</td>\n",
       "      <td>0.411512</td>\n",
       "      <td>0.35378</td>\n",
       "      <td>0.586795</td>\n",
       "      <td>0.662513</td>\n",
       "      <td>0.461252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-04-30</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>2013-10-31</td>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>74241</td>\n",
       "      <td>31563</td>\n",
       "      <td>0.502783</td>\n",
       "      <td>0.409524</td>\n",
       "      <td>0.731204</td>\n",
       "      <td>0.0153079</td>\n",
       "      <td>0.0295127</td>\n",
       "      <td>0.386688</td>\n",
       "      <td>0.72848</td>\n",
       "      <td>0.0289546</td>\n",
       "      <td>0.053875</td>\n",
       "      <td>0.385298</td>\n",
       "      <td>0.721541</td>\n",
       "      <td>0.072149</td>\n",
       "      <td>0.121539</td>\n",
       "      <td>0.376426</td>\n",
       "      <td>0.708298</td>\n",
       "      <td>0.140975</td>\n",
       "      <td>0.205128</td>\n",
       "      <td>0.355038</td>\n",
       "      <td>0.675031</td>\n",
       "      <td>0.265931</td>\n",
       "      <td>0.304091</td>\n",
       "      <td>0.352978</td>\n",
       "      <td>0.644806</td>\n",
       "      <td>0.396582</td>\n",
       "      <td>0.373512</td>\n",
       "      <td>0.339395</td>\n",
       "      <td>0.572411</td>\n",
       "      <td>0.635576</td>\n",
       "      <td>0.442498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-04-30</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>2013-10-31</td>\n",
       "      <td>RF</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>74241</td>\n",
       "      <td>31563</td>\n",
       "      <td>0.495290</td>\n",
       "      <td>0.495238</td>\n",
       "      <td>0.732915</td>\n",
       "      <td>0.0185119</td>\n",
       "      <td>0.0356898</td>\n",
       "      <td>0.488114</td>\n",
       "      <td>0.732535</td>\n",
       "      <td>0.0365492</td>\n",
       "      <td>0.0680062</td>\n",
       "      <td>0.47275</td>\n",
       "      <td>0.730285</td>\n",
       "      <td>0.088525</td>\n",
       "      <td>0.149125</td>\n",
       "      <td>0.44962</td>\n",
       "      <td>0.722935</td>\n",
       "      <td>0.168387</td>\n",
       "      <td>0.245014</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.69968</td>\n",
       "      <td>0.312092</td>\n",
       "      <td>0.356876</td>\n",
       "      <td>0.391952</td>\n",
       "      <td>0.668187</td>\n",
       "      <td>0.44037</td>\n",
       "      <td>0.414753</td>\n",
       "      <td>0.356124</td>\n",
       "      <td>0.589139</td>\n",
       "      <td>0.666904</td>\n",
       "      <td>0.464309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-04-30</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>2013-10-31</td>\n",
       "      <td>AB</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "      <td>74241</td>\n",
       "      <td>31563</td>\n",
       "      <td>0.497006</td>\n",
       "      <td>1</td>\n",
       "      <td>0.74299</td>\n",
       "      <td>0.0373799</td>\n",
       "      <td>0.0720659</td>\n",
       "      <td>1</td>\n",
       "      <td>0.753002</td>\n",
       "      <td>0.0748784</td>\n",
       "      <td>0.139324</td>\n",
       "      <td>1</td>\n",
       "      <td>0.783005</td>\n",
       "      <td>0.187255</td>\n",
       "      <td>0.315442</td>\n",
       "      <td>1</td>\n",
       "      <td>0.833001</td>\n",
       "      <td>0.374511</td>\n",
       "      <td>0.544937</td>\n",
       "      <td>1</td>\n",
       "      <td>0.932991</td>\n",
       "      <td>0.749021</td>\n",
       "      <td>0.856503</td>\n",
       "      <td>0.745353</td>\n",
       "      <td>0.880208</td>\n",
       "      <td>0.837427</td>\n",
       "      <td>0.788712</td>\n",
       "      <td>0.447183</td>\n",
       "      <td>0.680195</td>\n",
       "      <td>0.837427</td>\n",
       "      <td>0.58303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-04-30</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>2013-10-31</td>\n",
       "      <td>LR</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>74241</td>\n",
       "      <td>31563</td>\n",
       "      <td>0.498834</td>\n",
       "      <td>0.415873</td>\n",
       "      <td>0.731331</td>\n",
       "      <td>0.0155453</td>\n",
       "      <td>0.0299703</td>\n",
       "      <td>0.366086</td>\n",
       "      <td>0.727656</td>\n",
       "      <td>0.0274119</td>\n",
       "      <td>0.0510046</td>\n",
       "      <td>0.332066</td>\n",
       "      <td>0.716218</td>\n",
       "      <td>0.0621811</td>\n",
       "      <td>0.104748</td>\n",
       "      <td>0.367554</td>\n",
       "      <td>0.706523</td>\n",
       "      <td>0.137653</td>\n",
       "      <td>0.200294</td>\n",
       "      <td>0.36993</td>\n",
       "      <td>0.680987</td>\n",
       "      <td>0.277086</td>\n",
       "      <td>0.316846</td>\n",
       "      <td>0.372624</td>\n",
       "      <td>0.656592</td>\n",
       "      <td>0.418654</td>\n",
       "      <td>0.3943</td>\n",
       "      <td>0.337875</td>\n",
       "      <td>0.57089</td>\n",
       "      <td>0.632728</td>\n",
       "      <td>0.440516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-04-30</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>2013-10-31</td>\n",
       "      <td>LR</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>74241</td>\n",
       "      <td>31563</td>\n",
       "      <td>0.507621</td>\n",
       "      <td>0.447619</td>\n",
       "      <td>0.731965</td>\n",
       "      <td>0.0167319</td>\n",
       "      <td>0.0322581</td>\n",
       "      <td>0.41046</td>\n",
       "      <td>0.72943</td>\n",
       "      <td>0.0307345</td>\n",
       "      <td>0.057187</td>\n",
       "      <td>0.440431</td>\n",
       "      <td>0.727054</td>\n",
       "      <td>0.082473</td>\n",
       "      <td>0.138931</td>\n",
       "      <td>0.416984</td>\n",
       "      <td>0.716408</td>\n",
       "      <td>0.156165</td>\n",
       "      <td>0.22723</td>\n",
       "      <td>0.394328</td>\n",
       "      <td>0.690745</td>\n",
       "      <td>0.29536</td>\n",
       "      <td>0.337743</td>\n",
       "      <td>0.381812</td>\n",
       "      <td>0.662104</td>\n",
       "      <td>0.428978</td>\n",
       "      <td>0.404023</td>\n",
       "      <td>0.348774</td>\n",
       "      <td>0.581789</td>\n",
       "      <td>0.653139</td>\n",
       "      <td>0.454726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-04-30</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>2013-10-31</td>\n",
       "      <td>LR</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>74241</td>\n",
       "      <td>31563</td>\n",
       "      <td>0.495309</td>\n",
       "      <td>0.44127</td>\n",
       "      <td>0.731838</td>\n",
       "      <td>0.0164946</td>\n",
       "      <td>0.0318005</td>\n",
       "      <td>0.448494</td>\n",
       "      <td>0.730951</td>\n",
       "      <td>0.0335825</td>\n",
       "      <td>0.0624862</td>\n",
       "      <td>0.456274</td>\n",
       "      <td>0.728638</td>\n",
       "      <td>0.0854397</td>\n",
       "      <td>0.143928</td>\n",
       "      <td>0.43853</td>\n",
       "      <td>0.720717</td>\n",
       "      <td>0.164234</td>\n",
       "      <td>0.238971</td>\n",
       "      <td>0.41334</td>\n",
       "      <td>0.698349</td>\n",
       "      <td>0.3096</td>\n",
       "      <td>0.354027</td>\n",
       "      <td>0.388572</td>\n",
       "      <td>0.66616</td>\n",
       "      <td>0.436573</td>\n",
       "      <td>0.411176</td>\n",
       "      <td>0.352513</td>\n",
       "      <td>0.585527</td>\n",
       "      <td>0.66014</td>\n",
       "      <td>0.4596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-04-30</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>2013-10-31</td>\n",
       "      <td>LR</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>74241</td>\n",
       "      <td>31563</td>\n",
       "      <td>0.498533</td>\n",
       "      <td>0.457143</td>\n",
       "      <td>0.732155</td>\n",
       "      <td>0.0170879</td>\n",
       "      <td>0.0329444</td>\n",
       "      <td>0.500792</td>\n",
       "      <td>0.733042</td>\n",
       "      <td>0.0374985</td>\n",
       "      <td>0.0697726</td>\n",
       "      <td>0.472117</td>\n",
       "      <td>0.730222</td>\n",
       "      <td>0.0884063</td>\n",
       "      <td>0.148926</td>\n",
       "      <td>0.449303</td>\n",
       "      <td>0.722872</td>\n",
       "      <td>0.168269</td>\n",
       "      <td>0.244842</td>\n",
       "      <td>0.42443</td>\n",
       "      <td>0.702785</td>\n",
       "      <td>0.317907</td>\n",
       "      <td>0.363525</td>\n",
       "      <td>0.393959</td>\n",
       "      <td>0.669391</td>\n",
       "      <td>0.442625</td>\n",
       "      <td>0.416876</td>\n",
       "      <td>0.349154</td>\n",
       "      <td>0.582169</td>\n",
       "      <td>0.653851</td>\n",
       "      <td>0.455221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-04-30</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>2013-10-31</td>\n",
       "      <td>LR</td>\n",
       "      <td>LogisticRegression(C=10, class_weight=None, du...</td>\n",
       "      <td>74241</td>\n",
       "      <td>31563</td>\n",
       "      <td>0.494620</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.731901</td>\n",
       "      <td>0.0166133</td>\n",
       "      <td>0.0320293</td>\n",
       "      <td>0.48019</td>\n",
       "      <td>0.732218</td>\n",
       "      <td>0.0359559</td>\n",
       "      <td>0.0669022</td>\n",
       "      <td>0.452471</td>\n",
       "      <td>0.728258</td>\n",
       "      <td>0.0847277</td>\n",
       "      <td>0.142729</td>\n",
       "      <td>0.431559</td>\n",
       "      <td>0.719323</td>\n",
       "      <td>0.161623</td>\n",
       "      <td>0.235172</td>\n",
       "      <td>0.409221</td>\n",
       "      <td>0.696702</td>\n",
       "      <td>0.306515</td>\n",
       "      <td>0.350499</td>\n",
       "      <td>0.384664</td>\n",
       "      <td>0.663815</td>\n",
       "      <td>0.432182</td>\n",
       "      <td>0.407041</td>\n",
       "      <td>0.345479</td>\n",
       "      <td>0.578494</td>\n",
       "      <td>0.646968</td>\n",
       "      <td>0.45043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-04-30</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>2013-10-31</td>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>74241</td>\n",
       "      <td>31563</td>\n",
       "      <td>0.497006</td>\n",
       "      <td>1</td>\n",
       "      <td>0.74299</td>\n",
       "      <td>0.0373799</td>\n",
       "      <td>0.0720659</td>\n",
       "      <td>1</td>\n",
       "      <td>0.753002</td>\n",
       "      <td>0.0748784</td>\n",
       "      <td>0.139324</td>\n",
       "      <td>1</td>\n",
       "      <td>0.783005</td>\n",
       "      <td>0.187255</td>\n",
       "      <td>0.315442</td>\n",
       "      <td>1</td>\n",
       "      <td>0.833001</td>\n",
       "      <td>0.374511</td>\n",
       "      <td>0.544937</td>\n",
       "      <td>1</td>\n",
       "      <td>0.932991</td>\n",
       "      <td>0.749021</td>\n",
       "      <td>0.856503</td>\n",
       "      <td>0.745353</td>\n",
       "      <td>0.880208</td>\n",
       "      <td>0.837427</td>\n",
       "      <td>0.788712</td>\n",
       "      <td>0.447183</td>\n",
       "      <td>0.680195</td>\n",
       "      <td>0.837427</td>\n",
       "      <td>0.58303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-04-30</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>2013-10-31</td>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>74241</td>\n",
       "      <td>31563</td>\n",
       "      <td>0.497006</td>\n",
       "      <td>1</td>\n",
       "      <td>0.74299</td>\n",
       "      <td>0.0373799</td>\n",
       "      <td>0.0720659</td>\n",
       "      <td>1</td>\n",
       "      <td>0.753002</td>\n",
       "      <td>0.0748784</td>\n",
       "      <td>0.139324</td>\n",
       "      <td>1</td>\n",
       "      <td>0.783005</td>\n",
       "      <td>0.187255</td>\n",
       "      <td>0.315442</td>\n",
       "      <td>1</td>\n",
       "      <td>0.833001</td>\n",
       "      <td>0.374511</td>\n",
       "      <td>0.544937</td>\n",
       "      <td>1</td>\n",
       "      <td>0.932991</td>\n",
       "      <td>0.749021</td>\n",
       "      <td>0.856503</td>\n",
       "      <td>0.745353</td>\n",
       "      <td>0.880208</td>\n",
       "      <td>0.837427</td>\n",
       "      <td>0.788712</td>\n",
       "      <td>0.447183</td>\n",
       "      <td>0.680195</td>\n",
       "      <td>0.837427</td>\n",
       "      <td>0.58303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-04-30</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>2013-10-31</td>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>74241</td>\n",
       "      <td>31563</td>\n",
       "      <td>0.497006</td>\n",
       "      <td>1</td>\n",
       "      <td>0.74299</td>\n",
       "      <td>0.0373799</td>\n",
       "      <td>0.0720659</td>\n",
       "      <td>1</td>\n",
       "      <td>0.753002</td>\n",
       "      <td>0.0748784</td>\n",
       "      <td>0.139324</td>\n",
       "      <td>1</td>\n",
       "      <td>0.783005</td>\n",
       "      <td>0.187255</td>\n",
       "      <td>0.315442</td>\n",
       "      <td>1</td>\n",
       "      <td>0.833001</td>\n",
       "      <td>0.374511</td>\n",
       "      <td>0.544937</td>\n",
       "      <td>1</td>\n",
       "      <td>0.932991</td>\n",
       "      <td>0.749021</td>\n",
       "      <td>0.856503</td>\n",
       "      <td>0.745353</td>\n",
       "      <td>0.880208</td>\n",
       "      <td>0.837427</td>\n",
       "      <td>0.788712</td>\n",
       "      <td>0.447183</td>\n",
       "      <td>0.680195</td>\n",
       "      <td>0.837427</td>\n",
       "      <td>0.58303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-04-30</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>2013-10-31</td>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>74241</td>\n",
       "      <td>31563</td>\n",
       "      <td>0.501704</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.731014</td>\n",
       "      <td>0.0149519</td>\n",
       "      <td>0.0288264</td>\n",
       "      <td>0.453249</td>\n",
       "      <td>0.731141</td>\n",
       "      <td>0.0339385</td>\n",
       "      <td>0.0631486</td>\n",
       "      <td>0.593156</td>\n",
       "      <td>0.742325</td>\n",
       "      <td>0.111072</td>\n",
       "      <td>0.187106</td>\n",
       "      <td>0.452788</td>\n",
       "      <td>0.723569</td>\n",
       "      <td>0.169574</td>\n",
       "      <td>0.246741</td>\n",
       "      <td>0.415716</td>\n",
       "      <td>0.6993</td>\n",
       "      <td>0.31138</td>\n",
       "      <td>0.356062</td>\n",
       "      <td>0.40188</td>\n",
       "      <td>0.674144</td>\n",
       "      <td>0.451525</td>\n",
       "      <td>0.425258</td>\n",
       "      <td>0.356441</td>\n",
       "      <td>0.589456</td>\n",
       "      <td>0.667497</td>\n",
       "      <td>0.464722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-04-30</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>2013-10-31</td>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>74241</td>\n",
       "      <td>31563</td>\n",
       "      <td>0.501147</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.731014</td>\n",
       "      <td>0.0149519</td>\n",
       "      <td>0.0288264</td>\n",
       "      <td>0.448494</td>\n",
       "      <td>0.730951</td>\n",
       "      <td>0.0335825</td>\n",
       "      <td>0.0624862</td>\n",
       "      <td>0.591255</td>\n",
       "      <td>0.742135</td>\n",
       "      <td>0.110716</td>\n",
       "      <td>0.186507</td>\n",
       "      <td>0.451838</td>\n",
       "      <td>0.723379</td>\n",
       "      <td>0.169218</td>\n",
       "      <td>0.246223</td>\n",
       "      <td>0.415241</td>\n",
       "      <td>0.69911</td>\n",
       "      <td>0.311024</td>\n",
       "      <td>0.355655</td>\n",
       "      <td>0.401246</td>\n",
       "      <td>0.673764</td>\n",
       "      <td>0.450813</td>\n",
       "      <td>0.424588</td>\n",
       "      <td>0.356124</td>\n",
       "      <td>0.589139</td>\n",
       "      <td>0.666904</td>\n",
       "      <td>0.464309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-04-30</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>2013-10-31</td>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>74241</td>\n",
       "      <td>31563</td>\n",
       "      <td>0.499054</td>\n",
       "      <td>0.377778</td>\n",
       "      <td>0.730571</td>\n",
       "      <td>0.0141213</td>\n",
       "      <td>0.0272249</td>\n",
       "      <td>0.454834</td>\n",
       "      <td>0.731204</td>\n",
       "      <td>0.0340572</td>\n",
       "      <td>0.0633694</td>\n",
       "      <td>0.587452</td>\n",
       "      <td>0.741755</td>\n",
       "      <td>0.110004</td>\n",
       "      <td>0.185307</td>\n",
       "      <td>0.450253</td>\n",
       "      <td>0.723062</td>\n",
       "      <td>0.168625</td>\n",
       "      <td>0.24536</td>\n",
       "      <td>0.414449</td>\n",
       "      <td>0.698793</td>\n",
       "      <td>0.310431</td>\n",
       "      <td>0.354977</td>\n",
       "      <td>0.40019</td>\n",
       "      <td>0.67313</td>\n",
       "      <td>0.449626</td>\n",
       "      <td>0.42347</td>\n",
       "      <td>0.356441</td>\n",
       "      <td>0.589456</td>\n",
       "      <td>0.667497</td>\n",
       "      <td>0.464722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-04-30</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>2013-10-31</td>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>74241</td>\n",
       "      <td>31563</td>\n",
       "      <td>0.497063</td>\n",
       "      <td>1</td>\n",
       "      <td>0.74299</td>\n",
       "      <td>0.0373799</td>\n",
       "      <td>0.0720659</td>\n",
       "      <td>1</td>\n",
       "      <td>0.753002</td>\n",
       "      <td>0.0748784</td>\n",
       "      <td>0.139324</td>\n",
       "      <td>0.484791</td>\n",
       "      <td>0.731489</td>\n",
       "      <td>0.0907796</td>\n",
       "      <td>0.152924</td>\n",
       "      <td>0.366286</td>\n",
       "      <td>0.70627</td>\n",
       "      <td>0.137178</td>\n",
       "      <td>0.199603</td>\n",
       "      <td>0.41635</td>\n",
       "      <td>0.699553</td>\n",
       "      <td>0.311855</td>\n",
       "      <td>0.356605</td>\n",
       "      <td>0.39755</td>\n",
       "      <td>0.671546</td>\n",
       "      <td>0.44666</td>\n",
       "      <td>0.420676</td>\n",
       "      <td>0.351942</td>\n",
       "      <td>0.584957</td>\n",
       "      <td>0.659072</td>\n",
       "      <td>0.458857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-04-30</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>2013-10-31</td>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>74241</td>\n",
       "      <td>31563</td>\n",
       "      <td>0.502419</td>\n",
       "      <td>1</td>\n",
       "      <td>0.74299</td>\n",
       "      <td>0.0373799</td>\n",
       "      <td>0.0720659</td>\n",
       "      <td>1</td>\n",
       "      <td>0.753002</td>\n",
       "      <td>0.0748784</td>\n",
       "      <td>0.139324</td>\n",
       "      <td>0.436629</td>\n",
       "      <td>0.726674</td>\n",
       "      <td>0.081761</td>\n",
       "      <td>0.137731</td>\n",
       "      <td>0.369455</td>\n",
       "      <td>0.706904</td>\n",
       "      <td>0.138365</td>\n",
       "      <td>0.20133</td>\n",
       "      <td>0.409537</td>\n",
       "      <td>0.696829</td>\n",
       "      <td>0.306752</td>\n",
       "      <td>0.35077</td>\n",
       "      <td>0.388466</td>\n",
       "      <td>0.666096</td>\n",
       "      <td>0.436454</td>\n",
       "      <td>0.411065</td>\n",
       "      <td>0.360497</td>\n",
       "      <td>0.593511</td>\n",
       "      <td>0.675092</td>\n",
       "      <td>0.47001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-04-30</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>2013-10-31</td>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>74241</td>\n",
       "      <td>31563</td>\n",
       "      <td>0.495648</td>\n",
       "      <td>1</td>\n",
       "      <td>0.74299</td>\n",
       "      <td>0.0373799</td>\n",
       "      <td>0.0720659</td>\n",
       "      <td>0.838352</td>\n",
       "      <td>0.746539</td>\n",
       "      <td>0.0627744</td>\n",
       "      <td>0.116803</td>\n",
       "      <td>0.363752</td>\n",
       "      <td>0.719387</td>\n",
       "      <td>0.0681144</td>\n",
       "      <td>0.114743</td>\n",
       "      <td>0.362801</td>\n",
       "      <td>0.705573</td>\n",
       "      <td>0.135873</td>\n",
       "      <td>0.197704</td>\n",
       "      <td>0.405101</td>\n",
       "      <td>0.695054</td>\n",
       "      <td>0.303429</td>\n",
       "      <td>0.346971</td>\n",
       "      <td>0.393642</td>\n",
       "      <td>0.669201</td>\n",
       "      <td>0.442269</td>\n",
       "      <td>0.416541</td>\n",
       "      <td>0.361447</td>\n",
       "      <td>0.594462</td>\n",
       "      <td>0.676872</td>\n",
       "      <td>0.471249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-04-30</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>2013-10-31</td>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>74241</td>\n",
       "      <td>31563</td>\n",
       "      <td>0.499099</td>\n",
       "      <td>1</td>\n",
       "      <td>0.74299</td>\n",
       "      <td>0.0373799</td>\n",
       "      <td>0.0720659</td>\n",
       "      <td>1</td>\n",
       "      <td>0.753002</td>\n",
       "      <td>0.0748784</td>\n",
       "      <td>0.139324</td>\n",
       "      <td>1</td>\n",
       "      <td>0.783005</td>\n",
       "      <td>0.187255</td>\n",
       "      <td>0.315442</td>\n",
       "      <td>0.936312</td>\n",
       "      <td>0.820264</td>\n",
       "      <td>0.350659</td>\n",
       "      <td>0.510231</td>\n",
       "      <td>0.468156</td>\n",
       "      <td>0.720274</td>\n",
       "      <td>0.350659</td>\n",
       "      <td>0.400977</td>\n",
       "      <td>0.340727</td>\n",
       "      <td>0.637455</td>\n",
       "      <td>0.382817</td>\n",
       "      <td>0.360548</td>\n",
       "      <td>0.533997</td>\n",
       "      <td>0.767006</td>\n",
       "      <td>1</td>\n",
       "      <td>0.696216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-04-30</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>2013-10-31</td>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>74241</td>\n",
       "      <td>31563</td>\n",
       "      <td>0.499358</td>\n",
       "      <td>1</td>\n",
       "      <td>0.74299</td>\n",
       "      <td>0.0373799</td>\n",
       "      <td>0.0720659</td>\n",
       "      <td>1</td>\n",
       "      <td>0.753002</td>\n",
       "      <td>0.0748784</td>\n",
       "      <td>0.139324</td>\n",
       "      <td>1</td>\n",
       "      <td>0.783005</td>\n",
       "      <td>0.187255</td>\n",
       "      <td>0.315442</td>\n",
       "      <td>0.82858</td>\n",
       "      <td>0.79872</td>\n",
       "      <td>0.310312</td>\n",
       "      <td>0.451524</td>\n",
       "      <td>0.41429</td>\n",
       "      <td>0.69873</td>\n",
       "      <td>0.310312</td>\n",
       "      <td>0.354841</td>\n",
       "      <td>0.348226</td>\n",
       "      <td>0.641954</td>\n",
       "      <td>0.391242</td>\n",
       "      <td>0.368483</td>\n",
       "      <td>0.533997</td>\n",
       "      <td>0.767006</td>\n",
       "      <td>1</td>\n",
       "      <td>0.696216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-04-30</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>2013-10-31</td>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>74241</td>\n",
       "      <td>31563</td>\n",
       "      <td>0.495765</td>\n",
       "      <td>1</td>\n",
       "      <td>0.74299</td>\n",
       "      <td>0.0373799</td>\n",
       "      <td>0.0720659</td>\n",
       "      <td>1</td>\n",
       "      <td>0.753002</td>\n",
       "      <td>0.0748784</td>\n",
       "      <td>0.139324</td>\n",
       "      <td>1</td>\n",
       "      <td>0.783005</td>\n",
       "      <td>0.187255</td>\n",
       "      <td>0.315442</td>\n",
       "      <td>0.630862</td>\n",
       "      <td>0.75918</td>\n",
       "      <td>0.236264</td>\n",
       "      <td>0.34378</td>\n",
       "      <td>0.37706</td>\n",
       "      <td>0.683839</td>\n",
       "      <td>0.282426</td>\n",
       "      <td>0.322953</td>\n",
       "      <td>0.361005</td>\n",
       "      <td>0.649621</td>\n",
       "      <td>0.405601</td>\n",
       "      <td>0.382006</td>\n",
       "      <td>0.419492</td>\n",
       "      <td>0.652505</td>\n",
       "      <td>0.78557</td>\n",
       "      <td>0.546927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-04-30</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>2013-10-31</td>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>74241</td>\n",
       "      <td>31563</td>\n",
       "      <td>0.499567</td>\n",
       "      <td>1</td>\n",
       "      <td>0.74299</td>\n",
       "      <td>0.0373799</td>\n",
       "      <td>0.0720659</td>\n",
       "      <td>1</td>\n",
       "      <td>0.753002</td>\n",
       "      <td>0.0748784</td>\n",
       "      <td>0.139324</td>\n",
       "      <td>1</td>\n",
       "      <td>0.783005</td>\n",
       "      <td>0.187255</td>\n",
       "      <td>0.315442</td>\n",
       "      <td>1</td>\n",
       "      <td>0.833001</td>\n",
       "      <td>0.374511</td>\n",
       "      <td>0.544937</td>\n",
       "      <td>1</td>\n",
       "      <td>0.932991</td>\n",
       "      <td>0.749021</td>\n",
       "      <td>0.856503</td>\n",
       "      <td>0.770384</td>\n",
       "      <td>0.895225</td>\n",
       "      <td>0.865551</td>\n",
       "      <td>0.8152</td>\n",
       "      <td>0.462201</td>\n",
       "      <td>0.695213</td>\n",
       "      <td>0.865551</td>\n",
       "      <td>0.602611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-04-30</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>2013-10-31</td>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>74241</td>\n",
       "      <td>31563</td>\n",
       "      <td>0.499567</td>\n",
       "      <td>1</td>\n",
       "      <td>0.74299</td>\n",
       "      <td>0.0373799</td>\n",
       "      <td>0.0720659</td>\n",
       "      <td>1</td>\n",
       "      <td>0.753002</td>\n",
       "      <td>0.0748784</td>\n",
       "      <td>0.139324</td>\n",
       "      <td>1</td>\n",
       "      <td>0.783005</td>\n",
       "      <td>0.187255</td>\n",
       "      <td>0.315442</td>\n",
       "      <td>1</td>\n",
       "      <td>0.833001</td>\n",
       "      <td>0.374511</td>\n",
       "      <td>0.544937</td>\n",
       "      <td>1</td>\n",
       "      <td>0.932991</td>\n",
       "      <td>0.749021</td>\n",
       "      <td>0.856503</td>\n",
       "      <td>0.770384</td>\n",
       "      <td>0.895225</td>\n",
       "      <td>0.865551</td>\n",
       "      <td>0.8152</td>\n",
       "      <td>0.462201</td>\n",
       "      <td>0.695213</td>\n",
       "      <td>0.865551</td>\n",
       "      <td>0.602611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-04-30</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>2013-10-31</td>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>74241</td>\n",
       "      <td>31563</td>\n",
       "      <td>0.499567</td>\n",
       "      <td>1</td>\n",
       "      <td>0.74299</td>\n",
       "      <td>0.0373799</td>\n",
       "      <td>0.0720659</td>\n",
       "      <td>1</td>\n",
       "      <td>0.753002</td>\n",
       "      <td>0.0748784</td>\n",
       "      <td>0.139324</td>\n",
       "      <td>1</td>\n",
       "      <td>0.783005</td>\n",
       "      <td>0.187255</td>\n",
       "      <td>0.315442</td>\n",
       "      <td>1</td>\n",
       "      <td>0.833001</td>\n",
       "      <td>0.374511</td>\n",
       "      <td>0.544937</td>\n",
       "      <td>1</td>\n",
       "      <td>0.932991</td>\n",
       "      <td>0.749021</td>\n",
       "      <td>0.856503</td>\n",
       "      <td>0.770384</td>\n",
       "      <td>0.895225</td>\n",
       "      <td>0.865551</td>\n",
       "      <td>0.8152</td>\n",
       "      <td>0.462201</td>\n",
       "      <td>0.695213</td>\n",
       "      <td>0.865551</td>\n",
       "      <td>0.602611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-04-30</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>2013-10-31</td>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>74241</td>\n",
       "      <td>31563</td>\n",
       "      <td>0.498207</td>\n",
       "      <td>0.387302</td>\n",
       "      <td>0.730761</td>\n",
       "      <td>0.0144773</td>\n",
       "      <td>0.0279112</td>\n",
       "      <td>0.359746</td>\n",
       "      <td>0.727402</td>\n",
       "      <td>0.0269372</td>\n",
       "      <td>0.0501214</td>\n",
       "      <td>0.538023</td>\n",
       "      <td>0.736812</td>\n",
       "      <td>0.100748</td>\n",
       "      <td>0.169715</td>\n",
       "      <td>0.49398</td>\n",
       "      <td>0.731806</td>\n",
       "      <td>0.185001</td>\n",
       "      <td>0.269188</td>\n",
       "      <td>0.445184</td>\n",
       "      <td>0.711086</td>\n",
       "      <td>0.333452</td>\n",
       "      <td>0.381301</td>\n",
       "      <td>0.410118</td>\n",
       "      <td>0.679086</td>\n",
       "      <td>0.460781</td>\n",
       "      <td>0.433976</td>\n",
       "      <td>0.359356</td>\n",
       "      <td>0.592371</td>\n",
       "      <td>0.672956</td>\n",
       "      <td>0.468523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-04-30</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>2013-10-31</td>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>74241</td>\n",
       "      <td>31563</td>\n",
       "      <td>0.496559</td>\n",
       "      <td>0.387302</td>\n",
       "      <td>0.730761</td>\n",
       "      <td>0.0144773</td>\n",
       "      <td>0.0279112</td>\n",
       "      <td>0.353407</td>\n",
       "      <td>0.727149</td>\n",
       "      <td>0.0264626</td>\n",
       "      <td>0.0492382</td>\n",
       "      <td>0.539924</td>\n",
       "      <td>0.737002</td>\n",
       "      <td>0.101104</td>\n",
       "      <td>0.170315</td>\n",
       "      <td>0.492712</td>\n",
       "      <td>0.731553</td>\n",
       "      <td>0.184526</td>\n",
       "      <td>0.268497</td>\n",
       "      <td>0.441381</td>\n",
       "      <td>0.709565</td>\n",
       "      <td>0.330604</td>\n",
       "      <td>0.378045</td>\n",
       "      <td>0.407583</td>\n",
       "      <td>0.677566</td>\n",
       "      <td>0.457933</td>\n",
       "      <td>0.431294</td>\n",
       "      <td>0.357899</td>\n",
       "      <td>0.590913</td>\n",
       "      <td>0.670227</td>\n",
       "      <td>0.466623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-04-30</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>2013-10-31</td>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>74241</td>\n",
       "      <td>31563</td>\n",
       "      <td>0.494673</td>\n",
       "      <td>0.393651</td>\n",
       "      <td>0.730887</td>\n",
       "      <td>0.0147146</td>\n",
       "      <td>0.0283688</td>\n",
       "      <td>0.356577</td>\n",
       "      <td>0.727276</td>\n",
       "      <td>0.0266999</td>\n",
       "      <td>0.0496798</td>\n",
       "      <td>0.53929</td>\n",
       "      <td>0.736939</td>\n",
       "      <td>0.100985</td>\n",
       "      <td>0.170115</td>\n",
       "      <td>0.493029</td>\n",
       "      <td>0.731616</td>\n",
       "      <td>0.184645</td>\n",
       "      <td>0.26867</td>\n",
       "      <td>0.439956</td>\n",
       "      <td>0.708995</td>\n",
       "      <td>0.329536</td>\n",
       "      <td>0.376823</td>\n",
       "      <td>0.406422</td>\n",
       "      <td>0.676868</td>\n",
       "      <td>0.456628</td>\n",
       "      <td>0.430064</td>\n",
       "      <td>0.357202</td>\n",
       "      <td>0.590216</td>\n",
       "      <td>0.668921</td>\n",
       "      <td>0.465714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-04-30</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>2013-10-31</td>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>74241</td>\n",
       "      <td>31563</td>\n",
       "      <td>0.503517</td>\n",
       "      <td>1</td>\n",
       "      <td>0.74299</td>\n",
       "      <td>0.0373799</td>\n",
       "      <td>0.0720659</td>\n",
       "      <td>0.77813</td>\n",
       "      <td>0.744131</td>\n",
       "      <td>0.0582651</td>\n",
       "      <td>0.108412</td>\n",
       "      <td>0.311153</td>\n",
       "      <td>0.714127</td>\n",
       "      <td>0.0582651</td>\n",
       "      <td>0.0981509</td>\n",
       "      <td>0.381179</td>\n",
       "      <td>0.709248</td>\n",
       "      <td>0.142755</td>\n",
       "      <td>0.207718</td>\n",
       "      <td>0.403992</td>\n",
       "      <td>0.694611</td>\n",
       "      <td>0.302599</td>\n",
       "      <td>0.346021</td>\n",
       "      <td>0.388361</td>\n",
       "      <td>0.666033</td>\n",
       "      <td>0.436336</td>\n",
       "      <td>0.410953</td>\n",
       "      <td>0.360433</td>\n",
       "      <td>0.593448</td>\n",
       "      <td>0.674973</td>\n",
       "      <td>0.469927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-04-30</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>2013-10-31</td>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>74241</td>\n",
       "      <td>31563</td>\n",
       "      <td>0.498055</td>\n",
       "      <td>1</td>\n",
       "      <td>0.74299</td>\n",
       "      <td>0.0373799</td>\n",
       "      <td>0.0720659</td>\n",
       "      <td>0.714739</td>\n",
       "      <td>0.741596</td>\n",
       "      <td>0.0535185</td>\n",
       "      <td>0.0995805</td>\n",
       "      <td>0.328897</td>\n",
       "      <td>0.715902</td>\n",
       "      <td>0.0615878</td>\n",
       "      <td>0.103748</td>\n",
       "      <td>0.374842</td>\n",
       "      <td>0.707981</td>\n",
       "      <td>0.140382</td>\n",
       "      <td>0.204265</td>\n",
       "      <td>0.403359</td>\n",
       "      <td>0.694357</td>\n",
       "      <td>0.302124</td>\n",
       "      <td>0.345478</td>\n",
       "      <td>0.385826</td>\n",
       "      <td>0.664512</td>\n",
       "      <td>0.433488</td>\n",
       "      <td>0.40827</td>\n",
       "      <td>0.352069</td>\n",
       "      <td>0.585084</td>\n",
       "      <td>0.659309</td>\n",
       "      <td>0.459022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-04-30</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>2013-10-31</td>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>74241</td>\n",
       "      <td>31563</td>\n",
       "      <td>0.502579</td>\n",
       "      <td>1</td>\n",
       "      <td>0.74299</td>\n",
       "      <td>0.0373799</td>\n",
       "      <td>0.0720659</td>\n",
       "      <td>0.508716</td>\n",
       "      <td>0.733359</td>\n",
       "      <td>0.0380918</td>\n",
       "      <td>0.0708766</td>\n",
       "      <td>0.320025</td>\n",
       "      <td>0.715014</td>\n",
       "      <td>0.0599264</td>\n",
       "      <td>0.10095</td>\n",
       "      <td>0.373257</td>\n",
       "      <td>0.707664</td>\n",
       "      <td>0.139789</td>\n",
       "      <td>0.203402</td>\n",
       "      <td>0.388308</td>\n",
       "      <td>0.688338</td>\n",
       "      <td>0.290851</td>\n",
       "      <td>0.332587</td>\n",
       "      <td>0.385087</td>\n",
       "      <td>0.664069</td>\n",
       "      <td>0.432657</td>\n",
       "      <td>0.407488</td>\n",
       "      <td>0.351625</td>\n",
       "      <td>0.58464</td>\n",
       "      <td>0.658479</td>\n",
       "      <td>0.458443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-04-30</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>2013-10-31</td>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>74241</td>\n",
       "      <td>31563</td>\n",
       "      <td>0.499076</td>\n",
       "      <td>1</td>\n",
       "      <td>0.74299</td>\n",
       "      <td>0.0373799</td>\n",
       "      <td>0.0720659</td>\n",
       "      <td>1</td>\n",
       "      <td>0.753002</td>\n",
       "      <td>0.0748784</td>\n",
       "      <td>0.139324</td>\n",
       "      <td>1</td>\n",
       "      <td>0.783005</td>\n",
       "      <td>0.187255</td>\n",
       "      <td>0.315442</td>\n",
       "      <td>0.996831</td>\n",
       "      <td>0.832367</td>\n",
       "      <td>0.373324</td>\n",
       "      <td>0.54321</td>\n",
       "      <td>0.498416</td>\n",
       "      <td>0.732377</td>\n",
       "      <td>0.373324</td>\n",
       "      <td>0.426895</td>\n",
       "      <td>0.365019</td>\n",
       "      <td>0.652029</td>\n",
       "      <td>0.41011</td>\n",
       "      <td>0.386253</td>\n",
       "      <td>0.533997</td>\n",
       "      <td>0.767006</td>\n",
       "      <td>1</td>\n",
       "      <td>0.696216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-04-30</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>2013-10-31</td>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>74241</td>\n",
       "      <td>31563</td>\n",
       "      <td>0.496786</td>\n",
       "      <td>1</td>\n",
       "      <td>0.74299</td>\n",
       "      <td>0.0373799</td>\n",
       "      <td>0.0720659</td>\n",
       "      <td>1</td>\n",
       "      <td>0.753002</td>\n",
       "      <td>0.0748784</td>\n",
       "      <td>0.139324</td>\n",
       "      <td>1</td>\n",
       "      <td>0.783005</td>\n",
       "      <td>0.187255</td>\n",
       "      <td>0.315442</td>\n",
       "      <td>0.885298</td>\n",
       "      <td>0.810062</td>\n",
       "      <td>0.331553</td>\n",
       "      <td>0.482431</td>\n",
       "      <td>0.442649</td>\n",
       "      <td>0.710072</td>\n",
       "      <td>0.331553</td>\n",
       "      <td>0.37913</td>\n",
       "      <td>0.346219</td>\n",
       "      <td>0.64075</td>\n",
       "      <td>0.388988</td>\n",
       "      <td>0.366359</td>\n",
       "      <td>0.533997</td>\n",
       "      <td>0.767006</td>\n",
       "      <td>1</td>\n",
       "      <td>0.696216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-04-30</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>2013-10-31</td>\n",
       "      <td>DT</td>\n",
       "      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n",
       "      <td>74241</td>\n",
       "      <td>31563</td>\n",
       "      <td>0.494833</td>\n",
       "      <td>1</td>\n",
       "      <td>0.74299</td>\n",
       "      <td>0.0373799</td>\n",
       "      <td>0.0720659</td>\n",
       "      <td>1</td>\n",
       "      <td>0.753002</td>\n",
       "      <td>0.0748784</td>\n",
       "      <td>0.139324</td>\n",
       "      <td>1</td>\n",
       "      <td>0.783005</td>\n",
       "      <td>0.187255</td>\n",
       "      <td>0.315442</td>\n",
       "      <td>0.610266</td>\n",
       "      <td>0.755061</td>\n",
       "      <td>0.228551</td>\n",
       "      <td>0.332556</td>\n",
       "      <td>0.359632</td>\n",
       "      <td>0.676868</td>\n",
       "      <td>0.269372</td>\n",
       "      <td>0.308026</td>\n",
       "      <td>0.34812</td>\n",
       "      <td>0.641891</td>\n",
       "      <td>0.391124</td>\n",
       "      <td>0.368371</td>\n",
       "      <td>0.479564</td>\n",
       "      <td>0.712575</td>\n",
       "      <td>0.898066</td>\n",
       "      <td>0.625248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-04-30</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>2013-10-31</td>\n",
       "      <td>GB</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>74241</td>\n",
       "      <td>31563</td>\n",
       "      <td>0.503565</td>\n",
       "      <td>0.479365</td>\n",
       "      <td>0.732598</td>\n",
       "      <td>0.0179186</td>\n",
       "      <td>0.0345459</td>\n",
       "      <td>0.518225</td>\n",
       "      <td>0.733739</td>\n",
       "      <td>0.0388038</td>\n",
       "      <td>0.0722014</td>\n",
       "      <td>0.449937</td>\n",
       "      <td>0.728004</td>\n",
       "      <td>0.084253</td>\n",
       "      <td>0.141929</td>\n",
       "      <td>0.424588</td>\n",
       "      <td>0.717929</td>\n",
       "      <td>0.159013</td>\n",
       "      <td>0.231374</td>\n",
       "      <td>0.405577</td>\n",
       "      <td>0.695244</td>\n",
       "      <td>0.303785</td>\n",
       "      <td>0.347378</td>\n",
       "      <td>0.385192</td>\n",
       "      <td>0.664132</td>\n",
       "      <td>0.432776</td>\n",
       "      <td>0.4076</td>\n",
       "      <td>0.354033</td>\n",
       "      <td>0.587048</td>\n",
       "      <td>0.662988</td>\n",
       "      <td>0.461583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-04-30</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>2013-10-31</td>\n",
       "      <td>GB</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>74241</td>\n",
       "      <td>31563</td>\n",
       "      <td>0.496437</td>\n",
       "      <td>0.425397</td>\n",
       "      <td>0.731521</td>\n",
       "      <td>0.0159013</td>\n",
       "      <td>0.0306566</td>\n",
       "      <td>0.399366</td>\n",
       "      <td>0.728986</td>\n",
       "      <td>0.0299039</td>\n",
       "      <td>0.0556414</td>\n",
       "      <td>0.574778</td>\n",
       "      <td>0.740487</td>\n",
       "      <td>0.10763</td>\n",
       "      <td>0.181309</td>\n",
       "      <td>0.506654</td>\n",
       "      <td>0.734341</td>\n",
       "      <td>0.189747</td>\n",
       "      <td>0.276094</td>\n",
       "      <td>0.407003</td>\n",
       "      <td>0.695815</td>\n",
       "      <td>0.304853</td>\n",
       "      <td>0.348599</td>\n",
       "      <td>0.382657</td>\n",
       "      <td>0.662611</td>\n",
       "      <td>0.429928</td>\n",
       "      <td>0.404918</td>\n",
       "      <td>0.357202</td>\n",
       "      <td>0.590216</td>\n",
       "      <td>0.668921</td>\n",
       "      <td>0.465714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-04-30</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>2013-10-31</td>\n",
       "      <td>GB</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>74241</td>\n",
       "      <td>31563</td>\n",
       "      <td>0.499170</td>\n",
       "      <td>0.371429</td>\n",
       "      <td>0.730444</td>\n",
       "      <td>0.0138839</td>\n",
       "      <td>0.0267673</td>\n",
       "      <td>0.37084</td>\n",
       "      <td>0.727846</td>\n",
       "      <td>0.0277679</td>\n",
       "      <td>0.051667</td>\n",
       "      <td>0.392269</td>\n",
       "      <td>0.722238</td>\n",
       "      <td>0.0734544</td>\n",
       "      <td>0.123738</td>\n",
       "      <td>0.414132</td>\n",
       "      <td>0.715838</td>\n",
       "      <td>0.155097</td>\n",
       "      <td>0.225676</td>\n",
       "      <td>0.39924</td>\n",
       "      <td>0.69271</td>\n",
       "      <td>0.299039</td>\n",
       "      <td>0.34195</td>\n",
       "      <td>0.376954</td>\n",
       "      <td>0.65919</td>\n",
       "      <td>0.42352</td>\n",
       "      <td>0.398882</td>\n",
       "      <td>0.351562</td>\n",
       "      <td>0.584577</td>\n",
       "      <td>0.65836</td>\n",
       "      <td>0.458361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-04-30</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>2013-10-31</td>\n",
       "      <td>GB</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>74241</td>\n",
       "      <td>31563</td>\n",
       "      <td>0.493787</td>\n",
       "      <td>0.387302</td>\n",
       "      <td>0.730761</td>\n",
       "      <td>0.0144773</td>\n",
       "      <td>0.0279112</td>\n",
       "      <td>0.432647</td>\n",
       "      <td>0.730317</td>\n",
       "      <td>0.0323959</td>\n",
       "      <td>0.0602782</td>\n",
       "      <td>0.456274</td>\n",
       "      <td>0.728638</td>\n",
       "      <td>0.0854397</td>\n",
       "      <td>0.143928</td>\n",
       "      <td>0.443916</td>\n",
       "      <td>0.721795</td>\n",
       "      <td>0.166251</td>\n",
       "      <td>0.241906</td>\n",
       "      <td>0.423004</td>\n",
       "      <td>0.702215</td>\n",
       "      <td>0.316839</td>\n",
       "      <td>0.362304</td>\n",
       "      <td>0.394487</td>\n",
       "      <td>0.669708</td>\n",
       "      <td>0.443218</td>\n",
       "      <td>0.417435</td>\n",
       "      <td>0.364172</td>\n",
       "      <td>0.597187</td>\n",
       "      <td>0.681975</td>\n",
       "      <td>0.474802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-04-30</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>2013-10-31</td>\n",
       "      <td>BG</td>\n",
       "      <td>(LogisticRegression(C=100000.0, class_weight=N...</td>\n",
       "      <td>74241</td>\n",
       "      <td>31563</td>\n",
       "      <td>0.497440</td>\n",
       "      <td>0.365079</td>\n",
       "      <td>0.730317</td>\n",
       "      <td>0.0136466</td>\n",
       "      <td>0.0263098</td>\n",
       "      <td>0.400951</td>\n",
       "      <td>0.72905</td>\n",
       "      <td>0.0300225</td>\n",
       "      <td>0.0558622</td>\n",
       "      <td>0.39417</td>\n",
       "      <td>0.722428</td>\n",
       "      <td>0.0738104</td>\n",
       "      <td>0.124338</td>\n",
       "      <td>0.395437</td>\n",
       "      <td>0.7121</td>\n",
       "      <td>0.148095</td>\n",
       "      <td>0.215488</td>\n",
       "      <td>0.379911</td>\n",
       "      <td>0.684979</td>\n",
       "      <td>0.284562</td>\n",
       "      <td>0.325395</td>\n",
       "      <td>0.361534</td>\n",
       "      <td>0.649938</td>\n",
       "      <td>0.406194</td>\n",
       "      <td>0.382565</td>\n",
       "      <td>0.330651</td>\n",
       "      <td>0.563666</td>\n",
       "      <td>0.6192</td>\n",
       "      <td>0.431097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>2013-04-30</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>2013-10-31</td>\n",
       "      <td>baseline</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.266990</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_start  train_end test_start   test_end model_type  \\\n",
       "0   2012-01-01 2013-04-30 2013-07-01 2013-10-31         RF   \n",
       "1   2012-01-01 2013-04-30 2013-07-01 2013-10-31         RF   \n",
       "2   2012-01-01 2013-04-30 2013-07-01 2013-10-31         RF   \n",
       "3   2012-01-01 2013-04-30 2013-07-01 2013-10-31         RF   \n",
       "4   2012-01-01 2013-04-30 2013-07-01 2013-10-31         RF   \n",
       "5   2012-01-01 2013-04-30 2013-07-01 2013-10-31         RF   \n",
       "6   2012-01-01 2013-04-30 2013-07-01 2013-10-31         RF   \n",
       "7   2012-01-01 2013-04-30 2013-07-01 2013-10-31         RF   \n",
       "8   2012-01-01 2013-04-30 2013-07-01 2013-10-31         RF   \n",
       "9   2012-01-01 2013-04-30 2013-07-01 2013-10-31         RF   \n",
       "10  2012-01-01 2013-04-30 2013-07-01 2013-10-31         RF   \n",
       "11  2012-01-01 2013-04-30 2013-07-01 2013-10-31         RF   \n",
       "12  2012-01-01 2013-04-30 2013-07-01 2013-10-31         RF   \n",
       "13  2012-01-01 2013-04-30 2013-07-01 2013-10-31         RF   \n",
       "14  2012-01-01 2013-04-30 2013-07-01 2013-10-31         RF   \n",
       "15  2012-01-01 2013-04-30 2013-07-01 2013-10-31         RF   \n",
       "16  2012-01-01 2013-04-30 2013-07-01 2013-10-31         RF   \n",
       "17  2012-01-01 2013-04-30 2013-07-01 2013-10-31         RF   \n",
       "18  2012-01-01 2013-04-30 2013-07-01 2013-10-31         RF   \n",
       "19  2012-01-01 2013-04-30 2013-07-01 2013-10-31         RF   \n",
       "20  2012-01-01 2013-04-30 2013-07-01 2013-10-31         RF   \n",
       "21  2012-01-01 2013-04-30 2013-07-01 2013-10-31         RF   \n",
       "22  2012-01-01 2013-04-30 2013-07-01 2013-10-31         RF   \n",
       "23  2012-01-01 2013-04-30 2013-07-01 2013-10-31         RF   \n",
       "24  2012-01-01 2013-04-30 2013-07-01 2013-10-31         AB   \n",
       "25  2012-01-01 2013-04-30 2013-07-01 2013-10-31         LR   \n",
       "26  2012-01-01 2013-04-30 2013-07-01 2013-10-31         LR   \n",
       "27  2012-01-01 2013-04-30 2013-07-01 2013-10-31         LR   \n",
       "28  2012-01-01 2013-04-30 2013-07-01 2013-10-31         LR   \n",
       "29  2012-01-01 2013-04-30 2013-07-01 2013-10-31         LR   \n",
       "..         ...        ...        ...        ...        ...   \n",
       "36  2012-01-01 2013-04-30 2013-07-01 2013-10-31         DT   \n",
       "37  2012-01-01 2013-04-30 2013-07-01 2013-10-31         DT   \n",
       "38  2012-01-01 2013-04-30 2013-07-01 2013-10-31         DT   \n",
       "39  2012-01-01 2013-04-30 2013-07-01 2013-10-31         DT   \n",
       "40  2012-01-01 2013-04-30 2013-07-01 2013-10-31         DT   \n",
       "41  2012-01-01 2013-04-30 2013-07-01 2013-10-31         DT   \n",
       "42  2012-01-01 2013-04-30 2013-07-01 2013-10-31         DT   \n",
       "43  2012-01-01 2013-04-30 2013-07-01 2013-10-31         DT   \n",
       "44  2012-01-01 2013-04-30 2013-07-01 2013-10-31         DT   \n",
       "45  2012-01-01 2013-04-30 2013-07-01 2013-10-31         DT   \n",
       "46  2012-01-01 2013-04-30 2013-07-01 2013-10-31         DT   \n",
       "47  2012-01-01 2013-04-30 2013-07-01 2013-10-31         DT   \n",
       "48  2012-01-01 2013-04-30 2013-07-01 2013-10-31         DT   \n",
       "49  2012-01-01 2013-04-30 2013-07-01 2013-10-31         DT   \n",
       "50  2012-01-01 2013-04-30 2013-07-01 2013-10-31         DT   \n",
       "51  2012-01-01 2013-04-30 2013-07-01 2013-10-31         DT   \n",
       "52  2012-01-01 2013-04-30 2013-07-01 2013-10-31         DT   \n",
       "53  2012-01-01 2013-04-30 2013-07-01 2013-10-31         DT   \n",
       "54  2012-01-01 2013-04-30 2013-07-01 2013-10-31         DT   \n",
       "55  2012-01-01 2013-04-30 2013-07-01 2013-10-31         DT   \n",
       "56  2012-01-01 2013-04-30 2013-07-01 2013-10-31         DT   \n",
       "57  2012-01-01 2013-04-30 2013-07-01 2013-10-31         DT   \n",
       "58  2012-01-01 2013-04-30 2013-07-01 2013-10-31         DT   \n",
       "59  2012-01-01 2013-04-30 2013-07-01 2013-10-31         DT   \n",
       "60  2012-01-01 2013-04-30 2013-07-01 2013-10-31         GB   \n",
       "61  2012-01-01 2013-04-30 2013-07-01 2013-10-31         GB   \n",
       "62  2012-01-01 2013-04-30 2013-07-01 2013-10-31         GB   \n",
       "63  2012-01-01 2013-04-30 2013-07-01 2013-10-31         GB   \n",
       "64  2012-01-01 2013-04-30 2013-07-01 2013-10-31         BG   \n",
       "65  2012-01-01 2013-04-30 2013-07-01 2013-10-31   baseline   \n",
       "\n",
       "                                           classifier train_size test_size  \\\n",
       "0   (DecisionTreeClassifier(class_weight=None, cri...      74241     31563   \n",
       "1   (DecisionTreeClassifier(class_weight=None, cri...      74241     31563   \n",
       "2   (DecisionTreeClassifier(class_weight=None, cri...      74241     31563   \n",
       "3   (DecisionTreeClassifier(class_weight=None, cri...      74241     31563   \n",
       "4   (DecisionTreeClassifier(class_weight=None, cri...      74241     31563   \n",
       "5   (DecisionTreeClassifier(class_weight=None, cri...      74241     31563   \n",
       "6   (DecisionTreeClassifier(class_weight=None, cri...      74241     31563   \n",
       "7   (DecisionTreeClassifier(class_weight=None, cri...      74241     31563   \n",
       "8   (DecisionTreeClassifier(class_weight=None, cri...      74241     31563   \n",
       "9   (DecisionTreeClassifier(class_weight=None, cri...      74241     31563   \n",
       "10  (DecisionTreeClassifier(class_weight=None, cri...      74241     31563   \n",
       "11  (DecisionTreeClassifier(class_weight=None, cri...      74241     31563   \n",
       "12  (DecisionTreeClassifier(class_weight=None, cri...      74241     31563   \n",
       "13  (DecisionTreeClassifier(class_weight=None, cri...      74241     31563   \n",
       "14  (DecisionTreeClassifier(class_weight=None, cri...      74241     31563   \n",
       "15  (DecisionTreeClassifier(class_weight=None, cri...      74241     31563   \n",
       "16  (DecisionTreeClassifier(class_weight=None, cri...      74241     31563   \n",
       "17  (DecisionTreeClassifier(class_weight=None, cri...      74241     31563   \n",
       "18  (DecisionTreeClassifier(class_weight=None, cri...      74241     31563   \n",
       "19  (DecisionTreeClassifier(class_weight=None, cri...      74241     31563   \n",
       "20  (DecisionTreeClassifier(class_weight=None, cri...      74241     31563   \n",
       "21  (DecisionTreeClassifier(class_weight=None, cri...      74241     31563   \n",
       "22  (DecisionTreeClassifier(class_weight=None, cri...      74241     31563   \n",
       "23  (DecisionTreeClassifier(class_weight=None, cri...      74241     31563   \n",
       "24  (DecisionTreeClassifier(class_weight=None, cri...      74241     31563   \n",
       "25  LogisticRegression(C=10, class_weight=None, du...      74241     31563   \n",
       "26  LogisticRegression(C=10, class_weight=None, du...      74241     31563   \n",
       "27  LogisticRegression(C=10, class_weight=None, du...      74241     31563   \n",
       "28  LogisticRegression(C=10, class_weight=None, du...      74241     31563   \n",
       "29  LogisticRegression(C=10, class_weight=None, du...      74241     31563   \n",
       "..                                                ...        ...       ...   \n",
       "36  DecisionTreeClassifier(class_weight=None, crit...      74241     31563   \n",
       "37  DecisionTreeClassifier(class_weight=None, crit...      74241     31563   \n",
       "38  DecisionTreeClassifier(class_weight=None, crit...      74241     31563   \n",
       "39  DecisionTreeClassifier(class_weight=None, crit...      74241     31563   \n",
       "40  DecisionTreeClassifier(class_weight=None, crit...      74241     31563   \n",
       "41  DecisionTreeClassifier(class_weight=None, crit...      74241     31563   \n",
       "42  DecisionTreeClassifier(class_weight=None, crit...      74241     31563   \n",
       "43  DecisionTreeClassifier(class_weight=None, crit...      74241     31563   \n",
       "44  DecisionTreeClassifier(class_weight=None, crit...      74241     31563   \n",
       "45  DecisionTreeClassifier(class_weight=None, crit...      74241     31563   \n",
       "46  DecisionTreeClassifier(class_weight=None, crit...      74241     31563   \n",
       "47  DecisionTreeClassifier(class_weight=None, crit...      74241     31563   \n",
       "48  DecisionTreeClassifier(class_weight=None, crit...      74241     31563   \n",
       "49  DecisionTreeClassifier(class_weight=None, crit...      74241     31563   \n",
       "50  DecisionTreeClassifier(class_weight=None, crit...      74241     31563   \n",
       "51  DecisionTreeClassifier(class_weight=None, crit...      74241     31563   \n",
       "52  DecisionTreeClassifier(class_weight=None, crit...      74241     31563   \n",
       "53  DecisionTreeClassifier(class_weight=None, crit...      74241     31563   \n",
       "54  DecisionTreeClassifier(class_weight=None, crit...      74241     31563   \n",
       "55  DecisionTreeClassifier(class_weight=None, crit...      74241     31563   \n",
       "56  DecisionTreeClassifier(class_weight=None, crit...      74241     31563   \n",
       "57  DecisionTreeClassifier(class_weight=None, crit...      74241     31563   \n",
       "58  DecisionTreeClassifier(class_weight=None, crit...      74241     31563   \n",
       "59  DecisionTreeClassifier(class_weight=None, crit...      74241     31563   \n",
       "60  ([DecisionTreeRegressor(criterion='friedman_ms...      74241     31563   \n",
       "61  ([DecisionTreeRegressor(criterion='friedman_ms...      74241     31563   \n",
       "62  ([DecisionTreeRegressor(criterion='friedman_ms...      74241     31563   \n",
       "63  ([DecisionTreeRegressor(criterion='friedman_ms...      74241     31563   \n",
       "64  (LogisticRegression(C=100000.0, class_weight=N...      74241     31563   \n",
       "65                                                                           \n",
       "\n",
       "     auc-roc    p_at_1    a_at_1     r_at_1    f1_at_1    p_at_2    a_at_2  \\\n",
       "0   0.500482  0.438095  0.731775  0.0163759  0.0315717  0.445325  0.730824   \n",
       "1   0.500347  0.469841  0.732408  0.0175626  0.0338595  0.462758  0.731521   \n",
       "2   0.496559  0.479365  0.732598  0.0179186  0.0345459  0.537242  0.734499   \n",
       "3   0.494507  0.533333  0.733676  0.0199359  0.0384351   0.51664  0.733676   \n",
       "4   0.494826  0.396825  0.730951  0.0148333  0.0285976  0.545166  0.734816   \n",
       "5   0.502917  0.380952  0.730634  0.0142399  0.0274537  0.364501  0.727592   \n",
       "6   0.502365  0.380952  0.730634  0.0142399  0.0274537  0.332805  0.726325   \n",
       "7   0.499254  0.466667  0.732345  0.0174439  0.0336307   0.44691  0.730887   \n",
       "8   0.496487  0.463492  0.732281  0.0173253   0.033402  0.448494  0.730951   \n",
       "9   0.498516  0.536508  0.733739  0.0200546  0.0386639  0.540412  0.734626   \n",
       "10  0.498968   0.52381  0.733485  0.0195799  0.0377488  0.469097  0.731775   \n",
       "11  0.497330  0.520635  0.733422  0.0194613    0.03752  0.534073  0.734373   \n",
       "12  0.500315  0.415873  0.731331  0.0155453  0.0299703  0.388273  0.728543   \n",
       "13  0.498521  0.466667  0.732345  0.0174439  0.0336307  0.462758  0.731521   \n",
       "14  0.498153  0.339683   0.72981  0.0126973  0.0244795  0.359746  0.727402   \n",
       "15  0.505491  0.514286  0.733295  0.0192239  0.0370625  0.488114  0.732535   \n",
       "16  0.494653  0.444444  0.731901  0.0166133  0.0320293  0.435816  0.730444   \n",
       "17  0.500153  0.492063  0.732852  0.0183933   0.035461  0.488114  0.732535   \n",
       "18  0.503332  0.492063  0.732852  0.0183933   0.035461  0.464342  0.731584   \n",
       "19  0.497888  0.530159  0.733612  0.0198173  0.0382064  0.522979  0.733929   \n",
       "20  0.504727  0.453968  0.732091  0.0169693  0.0327156  0.454834  0.731204   \n",
       "21  0.498073  0.457143  0.732155  0.0170879  0.0329444  0.459588  0.731394   \n",
       "22  0.502783  0.409524  0.731204  0.0153079  0.0295127  0.386688   0.72848   \n",
       "23  0.495290  0.495238  0.732915  0.0185119  0.0356898  0.488114  0.732535   \n",
       "24  0.497006         1   0.74299  0.0373799  0.0720659         1  0.753002   \n",
       "25  0.498834  0.415873  0.731331  0.0155453  0.0299703  0.366086  0.727656   \n",
       "26  0.507621  0.447619  0.731965  0.0167319  0.0322581   0.41046   0.72943   \n",
       "27  0.495309   0.44127  0.731838  0.0164946  0.0318005  0.448494  0.730951   \n",
       "28  0.498533  0.457143  0.732155  0.0170879  0.0329444  0.500792  0.733042   \n",
       "29  0.494620  0.444444  0.731901  0.0166133  0.0320293   0.48019  0.732218   \n",
       "..       ...       ...       ...        ...        ...       ...       ...   \n",
       "36  0.497006         1   0.74299  0.0373799  0.0720659         1  0.753002   \n",
       "37  0.497006         1   0.74299  0.0373799  0.0720659         1  0.753002   \n",
       "38  0.497006         1   0.74299  0.0373799  0.0720659         1  0.753002   \n",
       "39  0.501704       0.4  0.731014  0.0149519  0.0288264  0.453249  0.731141   \n",
       "40  0.501147       0.4  0.731014  0.0149519  0.0288264  0.448494  0.730951   \n",
       "41  0.499054  0.377778  0.730571  0.0141213  0.0272249  0.454834  0.731204   \n",
       "42  0.497063         1   0.74299  0.0373799  0.0720659         1  0.753002   \n",
       "43  0.502419         1   0.74299  0.0373799  0.0720659         1  0.753002   \n",
       "44  0.495648         1   0.74299  0.0373799  0.0720659  0.838352  0.746539   \n",
       "45  0.499099         1   0.74299  0.0373799  0.0720659         1  0.753002   \n",
       "46  0.499358         1   0.74299  0.0373799  0.0720659         1  0.753002   \n",
       "47  0.495765         1   0.74299  0.0373799  0.0720659         1  0.753002   \n",
       "48  0.499567         1   0.74299  0.0373799  0.0720659         1  0.753002   \n",
       "49  0.499567         1   0.74299  0.0373799  0.0720659         1  0.753002   \n",
       "50  0.499567         1   0.74299  0.0373799  0.0720659         1  0.753002   \n",
       "51  0.498207  0.387302  0.730761  0.0144773  0.0279112  0.359746  0.727402   \n",
       "52  0.496559  0.387302  0.730761  0.0144773  0.0279112  0.353407  0.727149   \n",
       "53  0.494673  0.393651  0.730887  0.0147146  0.0283688  0.356577  0.727276   \n",
       "54  0.503517         1   0.74299  0.0373799  0.0720659   0.77813  0.744131   \n",
       "55  0.498055         1   0.74299  0.0373799  0.0720659  0.714739  0.741596   \n",
       "56  0.502579         1   0.74299  0.0373799  0.0720659  0.508716  0.733359   \n",
       "57  0.499076         1   0.74299  0.0373799  0.0720659         1  0.753002   \n",
       "58  0.496786         1   0.74299  0.0373799  0.0720659         1  0.753002   \n",
       "59  0.494833         1   0.74299  0.0373799  0.0720659         1  0.753002   \n",
       "60  0.503565  0.479365  0.732598  0.0179186  0.0345459  0.518225  0.733739   \n",
       "61  0.496437  0.425397  0.731521  0.0159013  0.0306566  0.399366  0.728986   \n",
       "62  0.499170  0.371429  0.730444  0.0138839  0.0267673   0.37084  0.727846   \n",
       "63  0.493787  0.387302  0.730761  0.0144773  0.0279112  0.432647  0.730317   \n",
       "64  0.497440  0.365079  0.730317  0.0136466  0.0263098  0.400951   0.72905   \n",
       "65  0.266990                                                                 \n",
       "\n",
       "       r_at_2    f1_at_2    p_at_5    a_at_5     r_at_5    f1_at_5   p_at_10  \\\n",
       "0   0.0333452  0.0620446  0.440431  0.727054   0.082473   0.138931  0.397655   \n",
       "1   0.0346505  0.0644734  0.455006  0.728511  0.0852023   0.143528  0.427123   \n",
       "2   0.0402278   0.074851  0.431559  0.726167  0.0808117   0.136132  0.434411   \n",
       "3   0.0386852  0.0719806  0.482256  0.731236   0.090305   0.152124  0.449303   \n",
       "4   0.0408212   0.075955  0.818124   0.76482   0.153198   0.258071  0.476236   \n",
       "5   0.0272932  0.0507838  0.375792  0.720591  0.0703691   0.118541  0.375158   \n",
       "6   0.0249199  0.0463679  0.418885  0.724899  0.0784384   0.132134    0.5282   \n",
       "7   0.0334639  0.0622654   0.45564  0.728575   0.085321   0.143728  0.425856   \n",
       "8   0.0335825  0.0624862  0.406844  0.723695  0.0761837   0.128336  0.410013   \n",
       "9   0.0404652  0.0752926       0.5   0.73301  0.0936276   0.157721  0.454373   \n",
       "10  0.0351252  0.0653566  0.465146  0.729525   0.087101   0.146727  0.433143   \n",
       "11  0.0399905  0.0744094  0.486692  0.731679  0.0911356   0.153523  0.453422   \n",
       "12  0.0290732  0.0540958  0.416984  0.724709  0.0780824   0.131534  0.375792   \n",
       "13  0.0346505  0.0644734  0.427757  0.725787  0.0800997   0.134933  0.420469   \n",
       "14  0.0269372  0.0501214  0.344106  0.717422  0.0644357   0.108546   0.35488   \n",
       "15  0.0365492  0.0680062  0.455006  0.728511  0.0852023   0.143528  0.434094   \n",
       "16  0.0326332  0.0607198  0.417617  0.724773   0.078201   0.131734  0.405577   \n",
       "17  0.0365492  0.0680062   0.47782  0.730792  0.0894743   0.150725  0.458492   \n",
       "18  0.0347692  0.0646942  0.442966  0.727307  0.0829477    0.13973   0.42744   \n",
       "19  0.0391598  0.0728638  0.501267  0.733137   0.093865   0.158121  0.481622   \n",
       "20  0.0340572  0.0633694  0.415082  0.724519  0.0777264   0.130935  0.383714   \n",
       "21  0.0344132  0.0640318  0.456907  0.728701  0.0855583   0.144128   0.44455   \n",
       "22  0.0289546   0.053875  0.385298  0.721541   0.072149   0.121539  0.376426   \n",
       "23  0.0365492  0.0680062   0.47275  0.730285   0.088525   0.149125   0.44962   \n",
       "24  0.0748784   0.139324         1  0.783005   0.187255   0.315442         1   \n",
       "25  0.0274119  0.0510046  0.332066  0.716218  0.0621811   0.104748  0.367554   \n",
       "26  0.0307345   0.057187  0.440431  0.727054   0.082473   0.138931  0.416984   \n",
       "27  0.0335825  0.0624862  0.456274  0.728638  0.0854397   0.143928   0.43853   \n",
       "28  0.0374985  0.0697726  0.472117  0.730222  0.0884063   0.148926  0.449303   \n",
       "29  0.0359559  0.0669022  0.452471  0.728258  0.0847277   0.142729  0.431559   \n",
       "..        ...        ...       ...       ...        ...        ...       ...   \n",
       "36  0.0748784   0.139324         1  0.783005   0.187255   0.315442         1   \n",
       "37  0.0748784   0.139324         1  0.783005   0.187255   0.315442         1   \n",
       "38  0.0748784   0.139324         1  0.783005   0.187255   0.315442         1   \n",
       "39  0.0339385  0.0631486  0.593156  0.742325   0.111072   0.187106  0.452788   \n",
       "40  0.0335825  0.0624862  0.591255  0.742135   0.110716   0.186507  0.451838   \n",
       "41  0.0340572  0.0633694  0.587452  0.741755   0.110004   0.185307  0.450253   \n",
       "42  0.0748784   0.139324  0.484791  0.731489  0.0907796   0.152924  0.366286   \n",
       "43  0.0748784   0.139324  0.436629  0.726674   0.081761   0.137731  0.369455   \n",
       "44  0.0627744   0.116803  0.363752  0.719387  0.0681144   0.114743  0.362801   \n",
       "45  0.0748784   0.139324         1  0.783005   0.187255   0.315442  0.936312   \n",
       "46  0.0748784   0.139324         1  0.783005   0.187255   0.315442   0.82858   \n",
       "47  0.0748784   0.139324         1  0.783005   0.187255   0.315442  0.630862   \n",
       "48  0.0748784   0.139324         1  0.783005   0.187255   0.315442         1   \n",
       "49  0.0748784   0.139324         1  0.783005   0.187255   0.315442         1   \n",
       "50  0.0748784   0.139324         1  0.783005   0.187255   0.315442         1   \n",
       "51  0.0269372  0.0501214  0.538023  0.736812   0.100748   0.169715   0.49398   \n",
       "52  0.0264626  0.0492382  0.539924  0.737002   0.101104   0.170315  0.492712   \n",
       "53  0.0266999  0.0496798   0.53929  0.736939   0.100985   0.170115  0.493029   \n",
       "54  0.0582651   0.108412  0.311153  0.714127  0.0582651  0.0981509  0.381179   \n",
       "55  0.0535185  0.0995805  0.328897  0.715902  0.0615878   0.103748  0.374842   \n",
       "56  0.0380918  0.0708766  0.320025  0.715014  0.0599264    0.10095  0.373257   \n",
       "57  0.0748784   0.139324         1  0.783005   0.187255   0.315442  0.996831   \n",
       "58  0.0748784   0.139324         1  0.783005   0.187255   0.315442  0.885298   \n",
       "59  0.0748784   0.139324         1  0.783005   0.187255   0.315442  0.610266   \n",
       "60  0.0388038  0.0722014  0.449937  0.728004   0.084253   0.141929  0.424588   \n",
       "61  0.0299039  0.0556414  0.574778  0.740487    0.10763   0.181309  0.506654   \n",
       "62  0.0277679   0.051667  0.392269  0.722238  0.0734544   0.123738  0.414132   \n",
       "63  0.0323959  0.0602782  0.456274  0.728638  0.0854397   0.143928  0.443916   \n",
       "64  0.0300225  0.0558622   0.39417  0.722428  0.0738104   0.124338  0.395437   \n",
       "65                                                                             \n",
       "\n",
       "     a_at_10   r_at_10  f1_at_10   p_at_20   a_at_20   r_at_20  f1_at_20  \\\n",
       "0   0.712543  0.148926  0.216697  0.366128  0.679466  0.274238   0.31359   \n",
       "1   0.718436  0.159962  0.232755  0.402567   0.69404  0.301531    0.3448   \n",
       "2   0.719894  0.162691  0.236726  0.396863  0.691759  0.297259  0.339915   \n",
       "3   0.722872  0.168269  0.244842  0.408428  0.696385  0.305921   0.34982   \n",
       "4   0.728258  0.178355  0.259518  0.325412  0.663182   0.24374  0.278716   \n",
       "5   0.708044  0.140501  0.204438  0.356781  0.675728  0.267236  0.305584   \n",
       "6    0.73865  0.197817  0.287836   0.32161  0.661661  0.240892   0.27546   \n",
       "7   0.718183  0.159487  0.232064  0.397972  0.692203  0.298089  0.340864   \n",
       "8   0.715014  0.153554  0.223431  0.382605  0.686056  0.286579  0.327702   \n",
       "9   0.723886  0.170167  0.247604  0.418885  0.700567  0.313753  0.358776   \n",
       "10   0.71964  0.162217  0.236036  0.398764   0.69252  0.298683  0.341543   \n",
       "11  0.723695  0.169811  0.247086  0.413498  0.698413  0.309719  0.354162   \n",
       "12  0.708171  0.140738  0.204783  0.380862  0.685359  0.285274  0.326209   \n",
       "13  0.717105   0.15747  0.229129   0.39718  0.691886  0.297496  0.340186   \n",
       "14  0.703989  0.132906  0.193387  0.358365  0.676362  0.268423  0.306941   \n",
       "15   0.71983  0.162573  0.236554   0.40225  0.693914  0.301293  0.344528   \n",
       "16  0.714127  0.151893  0.221014  0.381971  0.685803  0.286104  0.327159   \n",
       "17  0.724709   0.17171  0.249849  0.426648  0.703672  0.319568  0.365425   \n",
       "18    0.7185  0.160081  0.232928   0.39924   0.69271  0.299039   0.34195   \n",
       "19  0.729335  0.180373  0.262454  0.437579  0.708044  0.327756  0.374788   \n",
       "20  0.709755  0.143705    0.2091   0.36185  0.677756  0.271034  0.309926   \n",
       "21  0.721921  0.166489  0.242252  0.410171  0.697082  0.307227  0.351313   \n",
       "22  0.708298  0.140975  0.205128  0.355038  0.675031  0.265931  0.304091   \n",
       "23  0.722935  0.168387  0.245014  0.416667   0.69968  0.312092  0.356876   \n",
       "24  0.833001  0.374511  0.544937         1  0.932991  0.749021  0.856503   \n",
       "25  0.706523  0.137653  0.200294   0.36993  0.680987  0.277086  0.316846   \n",
       "26  0.716408  0.156165   0.22723  0.394328  0.690745   0.29536  0.337743   \n",
       "27  0.720717  0.164234  0.238971   0.41334  0.698349    0.3096  0.354027   \n",
       "28  0.722872  0.168269  0.244842   0.42443  0.702785  0.317907  0.363525   \n",
       "29  0.719323  0.161623  0.235172  0.409221  0.696702  0.306515  0.350499   \n",
       "..       ...       ...       ...       ...       ...       ...       ...   \n",
       "36  0.833001  0.374511  0.544937         1  0.932991  0.749021  0.856503   \n",
       "37  0.833001  0.374511  0.544937         1  0.932991  0.749021  0.856503   \n",
       "38  0.833001  0.374511  0.544937         1  0.932991  0.749021  0.856503   \n",
       "39  0.723569  0.169574  0.246741  0.415716    0.6993   0.31138  0.356062   \n",
       "40  0.723379  0.169218  0.246223  0.415241   0.69911  0.311024  0.355655   \n",
       "41  0.723062  0.168625   0.24536  0.414449  0.698793  0.310431  0.354977   \n",
       "42   0.70627  0.137178  0.199603   0.41635  0.699553  0.311855  0.356605   \n",
       "43  0.706904  0.138365   0.20133  0.409537  0.696829  0.306752   0.35077   \n",
       "44  0.705573  0.135873  0.197704  0.405101  0.695054  0.303429  0.346971   \n",
       "45  0.820264  0.350659  0.510231  0.468156  0.720274  0.350659  0.400977   \n",
       "46   0.79872  0.310312  0.451524   0.41429   0.69873  0.310312  0.354841   \n",
       "47   0.75918  0.236264   0.34378   0.37706  0.683839  0.282426  0.322953   \n",
       "48  0.833001  0.374511  0.544937         1  0.932991  0.749021  0.856503   \n",
       "49  0.833001  0.374511  0.544937         1  0.932991  0.749021  0.856503   \n",
       "50  0.833001  0.374511  0.544937         1  0.932991  0.749021  0.856503   \n",
       "51  0.731806  0.185001  0.269188  0.445184  0.711086  0.333452  0.381301   \n",
       "52  0.731553  0.184526  0.268497  0.441381  0.709565  0.330604  0.378045   \n",
       "53  0.731616  0.184645   0.26867  0.439956  0.708995  0.329536  0.376823   \n",
       "54  0.709248  0.142755  0.207718  0.403992  0.694611  0.302599  0.346021   \n",
       "55  0.707981  0.140382  0.204265  0.403359  0.694357  0.302124  0.345478   \n",
       "56  0.707664  0.139789  0.203402  0.388308  0.688338  0.290851  0.332587   \n",
       "57  0.832367  0.373324   0.54321  0.498416  0.732377  0.373324  0.426895   \n",
       "58  0.810062  0.331553  0.482431  0.442649  0.710072  0.331553   0.37913   \n",
       "59  0.755061  0.228551  0.332556  0.359632  0.676868  0.269372  0.308026   \n",
       "60  0.717929  0.159013  0.231374  0.405577  0.695244  0.303785  0.347378   \n",
       "61  0.734341  0.189747  0.276094  0.407003  0.695815  0.304853  0.348599   \n",
       "62  0.715838  0.155097  0.225676   0.39924   0.69271  0.299039   0.34195   \n",
       "63  0.721795  0.166251  0.241906  0.423004  0.702215  0.316839  0.362304   \n",
       "64    0.7121  0.148095  0.215488  0.379911  0.684979  0.284562  0.325395   \n",
       "65                                                                         \n",
       "\n",
       "     p_at_30   a_at_30   r_at_30  f1_at_30   p_at_50   a_at_50   r_at_50  \\\n",
       "0   0.336396  0.634857  0.377952  0.355965  0.310373  0.543389  0.581227   \n",
       "1   0.381496  0.661914  0.428622  0.403688  0.349408  0.582422  0.654325   \n",
       "2    0.35583  0.646516  0.399786   0.37653  0.335213  0.568229  0.627744   \n",
       "3   0.389839   0.66692  0.437997  0.412517  0.356505  0.589519  0.667616   \n",
       "4   0.550275  0.763172  0.618251  0.582286   0.50941   0.74242  0.953958   \n",
       "5   0.351711  0.644045  0.395158  0.372171  0.325201  0.558217  0.608995   \n",
       "6   0.509717   0.73884  0.572683  0.539369  0.522781   0.75579  0.978996   \n",
       "7   0.385615  0.664386   0.43325  0.408047  0.353716  0.586731  0.662395   \n",
       "8   0.367765  0.653677  0.413196  0.389159  0.344528  0.577543  0.645188   \n",
       "9   0.398817  0.672306  0.448084  0.422017    0.3598  0.592814  0.673787   \n",
       "10  0.383925  0.663372  0.431352  0.406259  0.355554  0.588569  0.665836   \n",
       "11  0.391318  0.667807  0.439658  0.414082  0.356695  0.589709  0.667972   \n",
       "12  0.373257  0.656972  0.419366  0.394971  0.363855   0.59687  0.681381   \n",
       "13  0.372201  0.656338   0.41818  0.393853  0.343451  0.576466  0.643171   \n",
       "14  0.352134  0.644299  0.395633  0.372618  0.320322  0.553338  0.599858   \n",
       "15  0.386882  0.665146  0.434674  0.409388  0.351689  0.584704  0.658597   \n",
       "16  0.372201  0.656338   0.41818  0.393853  0.342627  0.575642  0.641628   \n",
       "17  0.406422  0.676868  0.456628  0.430064  0.363158  0.596173  0.680076   \n",
       "18  0.383608  0.663182  0.430996  0.405923  0.353907  0.586921  0.662751   \n",
       "19  0.410013  0.679023  0.460662  0.433864  0.368481  0.601495  0.690044   \n",
       "20  0.352767  0.644679  0.396345  0.373289  0.336037  0.569052  0.629287   \n",
       "21  0.388889   0.66635  0.436929  0.411512   0.35378  0.586795  0.662513   \n",
       "22  0.352978  0.644806  0.396582  0.373512  0.339395  0.572411  0.635576   \n",
       "23  0.391952  0.668187   0.44037  0.414753  0.356124  0.589139  0.666904   \n",
       "24  0.745353  0.880208  0.837427  0.788712  0.447183  0.680195  0.837427   \n",
       "25  0.372624  0.656592  0.418654    0.3943  0.337875   0.57089  0.632728   \n",
       "26  0.381812  0.662104  0.428978  0.404023  0.348774  0.581789  0.653139   \n",
       "27  0.388572   0.66616  0.436573  0.411176  0.352513  0.585527   0.66014   \n",
       "28  0.393959  0.669391  0.442625  0.416876  0.349154  0.582169  0.653851   \n",
       "29  0.384664  0.663815  0.432182  0.407041  0.345479  0.578494  0.646968   \n",
       "..       ...       ...       ...       ...       ...       ...       ...   \n",
       "36  0.745353  0.880208  0.837427  0.788712  0.447183  0.680195  0.837427   \n",
       "37  0.745353  0.880208  0.837427  0.788712  0.447183  0.680195  0.837427   \n",
       "38  0.745353  0.880208  0.837427  0.788712  0.447183  0.680195  0.837427   \n",
       "39   0.40188  0.674144  0.451525  0.425258  0.356441  0.589456  0.667497   \n",
       "40  0.401246  0.673764  0.450813  0.424588  0.356124  0.589139  0.666904   \n",
       "41   0.40019   0.67313  0.449626   0.42347  0.356441  0.589456  0.667497   \n",
       "42   0.39755  0.671546   0.44666  0.420676  0.351942  0.584957  0.659072   \n",
       "43  0.388466  0.666096  0.436454  0.411065  0.360497  0.593511  0.675092   \n",
       "44  0.393642  0.669201  0.442269  0.416541  0.361447  0.594462  0.676872   \n",
       "45  0.340727  0.637455  0.382817  0.360548  0.533997  0.767006         1   \n",
       "46  0.348226  0.641954  0.391242  0.368483  0.533997  0.767006         1   \n",
       "47  0.361005  0.649621  0.405601  0.382006  0.419492  0.652505   0.78557   \n",
       "48  0.770384  0.895225  0.865551    0.8152  0.462201  0.695213  0.865551   \n",
       "49  0.770384  0.895225  0.865551    0.8152  0.462201  0.695213  0.865551   \n",
       "50  0.770384  0.895225  0.865551    0.8152  0.462201  0.695213  0.865551   \n",
       "51  0.410118  0.679086  0.460781  0.433976  0.359356  0.592371  0.672956   \n",
       "52  0.407583  0.677566  0.457933  0.431294  0.357899  0.590913  0.670227   \n",
       "53  0.406422  0.676868  0.456628  0.430064  0.357202  0.590216  0.668921   \n",
       "54  0.388361  0.666033  0.436336  0.410953  0.360433  0.593448  0.674973   \n",
       "55  0.385826  0.664512  0.433488   0.40827  0.352069  0.585084  0.659309   \n",
       "56  0.385087  0.664069  0.432657  0.407488  0.351625   0.58464  0.658479   \n",
       "57  0.365019  0.652029   0.41011  0.386253  0.533997  0.767006         1   \n",
       "58  0.346219   0.64075  0.388988  0.366359  0.533997  0.767006         1   \n",
       "59   0.34812  0.641891  0.391124  0.368371  0.479564  0.712575  0.898066   \n",
       "60  0.385192  0.664132  0.432776    0.4076  0.354033  0.587048  0.662988   \n",
       "61  0.382657  0.662611  0.429928  0.404918  0.357202  0.590216  0.668921   \n",
       "62  0.376954   0.65919   0.42352  0.398882  0.351562  0.584577   0.65836   \n",
       "63  0.394487  0.669708  0.443218  0.417435  0.364172  0.597187  0.681975   \n",
       "64  0.361534  0.649938  0.406194  0.382565  0.330651  0.563666    0.6192   \n",
       "65                                                                         \n",
       "\n",
       "    f1_at_50  \n",
       "0    0.40466  \n",
       "1   0.455552  \n",
       "2   0.437046  \n",
       "3   0.464805  \n",
       "4   0.664161  \n",
       "5   0.423992  \n",
       "6   0.681593  \n",
       "7    0.46117  \n",
       "8    0.44919  \n",
       "9   0.469101  \n",
       "10  0.463566  \n",
       "11  0.465053  \n",
       "12  0.474389  \n",
       "13  0.447786  \n",
       "14  0.417631  \n",
       "15  0.458526  \n",
       "16  0.446712  \n",
       "17   0.47348  \n",
       "18  0.461418  \n",
       "19   0.48042  \n",
       "20   0.43812  \n",
       "21  0.461252  \n",
       "22  0.442498  \n",
       "23  0.464309  \n",
       "24   0.58303  \n",
       "25  0.440516  \n",
       "26  0.454726  \n",
       "27    0.4596  \n",
       "28  0.455221  \n",
       "29   0.45043  \n",
       "..       ...  \n",
       "36   0.58303  \n",
       "37   0.58303  \n",
       "38   0.58303  \n",
       "39  0.464722  \n",
       "40  0.464309  \n",
       "41  0.464722  \n",
       "42  0.458857  \n",
       "43   0.47001  \n",
       "44  0.471249  \n",
       "45  0.696216  \n",
       "46  0.696216  \n",
       "47  0.546927  \n",
       "48  0.602611  \n",
       "49  0.602611  \n",
       "50  0.602611  \n",
       "51  0.468523  \n",
       "52  0.466623  \n",
       "53  0.465714  \n",
       "54  0.469927  \n",
       "55  0.459022  \n",
       "56  0.458443  \n",
       "57  0.696216  \n",
       "58  0.696216  \n",
       "59  0.625248  \n",
       "60  0.461583  \n",
       "61  0.465714  \n",
       "62  0.458361  \n",
       "63  0.474802  \n",
       "64  0.431097  \n",
       "65            \n",
       "\n",
       "[66 rows x 37 columns]"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next, I identify the model with the best AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train_start                                  2012-01-01 00:00:00\n",
       "train_end                                    2013-04-30 00:00:00\n",
       "test_start                                   2013-07-01 00:00:00\n",
       "test_end                                     2013-10-31 00:00:00\n",
       "model_type                                                   SVM\n",
       "classifier     LinearSVC(C=0.01, class_weight=None, dual=True...\n",
       "train_size                                                 74241\n",
       "test_size                                                  31563\n",
       "auc-roc                                                 0.510648\n",
       "p_at_1                                                  0.460317\n",
       "a_at_1                                                  0.732218\n",
       "r_at_1                                                 0.0172066\n",
       "f1_at_1                                                0.0331732\n",
       "p_at_2                                                  0.402536\n",
       "a_at_2                                                  0.729113\n",
       "r_at_2                                                 0.0301412\n",
       "f1_at_2                                                 0.056083\n",
       "p_at_5                                                  0.415082\n",
       "a_at_5                                                  0.724519\n",
       "r_at_5                                                 0.0777264\n",
       "f1_at_5                                                 0.130935\n",
       "p_at_10                                                 0.426172\n",
       "a_at_10                                                 0.718246\n",
       "r_at_10                                                 0.159606\n",
       "f1_at_10                                                0.232237\n",
       "p_at_20                                                 0.416984\n",
       "a_at_20                                                 0.699807\n",
       "r_at_20                                                 0.312329\n",
       "f1_at_20                                                0.357148\n",
       "p_at_30                                                 0.399451\n",
       "a_at_30                                                 0.672686\n",
       "r_at_30                                                 0.448796\n",
       "f1_at_30                                                0.422688\n",
       "p_at_50                                                 0.358913\n",
       "a_at_50                                                 0.591927\n",
       "r_at_50                                                 0.672125\n",
       "f1_at_50                                                0.467944\n",
       "Name: 35, dtype: object"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_without_baseline = results_df[results_df['model_type'] != 'baseline']\n",
    "best_model = results_without_baseline.loc[results_without_baseline['auc-roc'].idxmax()]\n",
    "best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here are the parameters for the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.01}"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params[35]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_best, x_test_best, y_train_best, y_test_best = library.temporal_split(donors_df, \"date_posted\" , \"60_days_fullyfunded\", best_model['train_start'], best_model['train_end'], best_model['test_start'], best_model['test_end'], vars_to_drop_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_best, x_test_best, features_best = library.pre_process(x_train_best, x_test_best, categorical_list, to_dummy_list, continuous_impute_list, vars_to_drop_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_best = x_train_best[features_best]\n",
    "x_test_best = x_test_best[features_best]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=0.01, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=0, tol=1e-05, verbose=0)"
      ]
     },
     "execution_count": 418,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_svm = best_model['classifier']\n",
    "best_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_probs_best = best_svm.fit(x_train_best, y_train_best).decision_function(x_test_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "library.plot_precision_recall_n(y_test_best, y_pred_probs_best, \"SVM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_compare = results_without_baseline[['model_type', 'auc-roc', 'p_at_5', 'r_at_5']]\n",
    "model_compare[['p_at_5', 'r_at_5']] = model_compare[['p_at_5', 'r_at_5']].apply(pd.to_numeric)\n",
    "model_compare = model_compare.groupby('model_type').mean()\n",
    "model_compare.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a24680668>"
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_compare.plot(x='model_type', y=['auc-roc', 'p_at_5', 'r_at_5'], kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_type</th>\n",
       "      <th>test_start</th>\n",
       "      <th>auc-roc</th>\n",
       "      <th>p_at_5</th>\n",
       "      <th>r_at_5</th>\n",
       "      <th>p_at_10</th>\n",
       "      <th>r_at_10</th>\n",
       "      <th>p_at_20</th>\n",
       "      <th>r_at_20</th>\n",
       "      <th>p_at_30</th>\n",
       "      <th>r_at_30</th>\n",
       "      <th>p_at_50</th>\n",
       "      <th>r_at_50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AB</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>0.497006</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.187255</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.374511</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.749021</td>\n",
       "      <td>0.745353</td>\n",
       "      <td>0.837427</td>\n",
       "      <td>0.447183</td>\n",
       "      <td>0.837427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BG</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>0.497440</td>\n",
       "      <td>0.394170</td>\n",
       "      <td>0.073810</td>\n",
       "      <td>0.395437</td>\n",
       "      <td>0.148095</td>\n",
       "      <td>0.379911</td>\n",
       "      <td>0.284562</td>\n",
       "      <td>0.361534</td>\n",
       "      <td>0.406194</td>\n",
       "      <td>0.330651</td>\n",
       "      <td>0.619200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DT</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>0.498552</td>\n",
       "      <td>0.734764</td>\n",
       "      <td>0.137589</td>\n",
       "      <td>0.664607</td>\n",
       "      <td>0.248902</td>\n",
       "      <td>0.564949</td>\n",
       "      <td>0.423159</td>\n",
       "      <td>0.475954</td>\n",
       "      <td>0.534749</td>\n",
       "      <td>0.418528</td>\n",
       "      <td>0.783765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GB</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>0.498240</td>\n",
       "      <td>0.468314</td>\n",
       "      <td>0.087694</td>\n",
       "      <td>0.447323</td>\n",
       "      <td>0.167527</td>\n",
       "      <td>0.408706</td>\n",
       "      <td>0.306129</td>\n",
       "      <td>0.384823</td>\n",
       "      <td>0.432360</td>\n",
       "      <td>0.356742</td>\n",
       "      <td>0.668061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KNN</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>0.499795</td>\n",
       "      <td>0.398289</td>\n",
       "      <td>0.074582</td>\n",
       "      <td>0.419518</td>\n",
       "      <td>0.157114</td>\n",
       "      <td>0.360345</td>\n",
       "      <td>0.269906</td>\n",
       "      <td>0.354246</td>\n",
       "      <td>0.398006</td>\n",
       "      <td>0.335974</td>\n",
       "      <td>0.629168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LR</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>0.500063</td>\n",
       "      <td>0.432589</td>\n",
       "      <td>0.081005</td>\n",
       "      <td>0.419677</td>\n",
       "      <td>0.157173</td>\n",
       "      <td>0.400190</td>\n",
       "      <td>0.299751</td>\n",
       "      <td>0.380241</td>\n",
       "      <td>0.427213</td>\n",
       "      <td>0.343728</td>\n",
       "      <td>0.643690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RF</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>0.499247</td>\n",
       "      <td>0.456247</td>\n",
       "      <td>0.085435</td>\n",
       "      <td>0.428232</td>\n",
       "      <td>0.160377</td>\n",
       "      <td>0.388222</td>\n",
       "      <td>0.290787</td>\n",
       "      <td>0.389417</td>\n",
       "      <td>0.437522</td>\n",
       "      <td>0.361334</td>\n",
       "      <td>0.676659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SVM</td>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>0.510648</td>\n",
       "      <td>0.415082</td>\n",
       "      <td>0.077726</td>\n",
       "      <td>0.426172</td>\n",
       "      <td>0.159606</td>\n",
       "      <td>0.416984</td>\n",
       "      <td>0.312329</td>\n",
       "      <td>0.399451</td>\n",
       "      <td>0.448796</td>\n",
       "      <td>0.358913</td>\n",
       "      <td>0.672125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model_type test_start   auc-roc    p_at_5    r_at_5   p_at_10   r_at_10  \\\n",
       "0         AB 2013-07-01  0.497006  1.000000  0.187255  1.000000  0.374511   \n",
       "1         BG 2013-07-01  0.497440  0.394170  0.073810  0.395437  0.148095   \n",
       "2         DT 2013-07-01  0.498552  0.734764  0.137589  0.664607  0.248902   \n",
       "3         GB 2013-07-01  0.498240  0.468314  0.087694  0.447323  0.167527   \n",
       "4        KNN 2013-07-01  0.499795  0.398289  0.074582  0.419518  0.157114   \n",
       "5         LR 2013-07-01  0.500063  0.432589  0.081005  0.419677  0.157173   \n",
       "6         RF 2013-07-01  0.499247  0.456247  0.085435  0.428232  0.160377   \n",
       "7        SVM 2013-07-01  0.510648  0.415082  0.077726  0.426172  0.159606   \n",
       "\n",
       "    p_at_20   r_at_20   p_at_30   r_at_30   p_at_50   r_at_50  \n",
       "0  1.000000  0.749021  0.745353  0.837427  0.447183  0.837427  \n",
       "1  0.379911  0.284562  0.361534  0.406194  0.330651  0.619200  \n",
       "2  0.564949  0.423159  0.475954  0.534749  0.418528  0.783765  \n",
       "3  0.408706  0.306129  0.384823  0.432360  0.356742  0.668061  \n",
       "4  0.360345  0.269906  0.354246  0.398006  0.335974  0.629168  \n",
       "5  0.400190  0.299751  0.380241  0.427213  0.343728  0.643690  \n",
       "6  0.388222  0.290787  0.389417  0.437522  0.361334  0.676659  \n",
       "7  0.416984  0.312329  0.399451  0.448796  0.358913  0.672125  "
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_compare_time = results_without_baseline[['model_type', 'auc-roc', 'p_at_5', 'r_at_5', 'p_at_10', 'r_at_10', 'p_at_20', 'r_at_20', 'p_at_30', 'r_at_30', 'p_at_50', 'r_at_50', 'test_start']]\n",
    "model_compare_time[['p_at_5', 'r_at_5', 'p_at_10', 'r_at_10', 'p_at_20', 'r_at_20', 'p_at_30', 'r_at_30', 'p_at_50', 'r_at_50']] = model_compare_time[['p_at_5', 'r_at_5', 'p_at_10', 'r_at_10', 'p_at_20', 'r_at_20', 'p_at_30', 'r_at_30', 'p_at_50', 'r_at_50']].apply(pd.to_numeric)\n",
    "model_compare_time = model_compare_time.groupby(['model_type', 'test_start']).mean()\n",
    "model_compare_time.reset_index(inplace=True)\n",
    "model_compare_time"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
